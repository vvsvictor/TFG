Pet
Módulo:  features.0  Porcentaje de pruning:  0.0023148148148148147
Módulo:  features.2  Porcentaje de pruning:  0.014431423611111112
Módulo:  features.5  Porcentaje de pruning:  0.016289605034722224
Módulo:  features.7  Porcentaje de pruning:  0.01727294921875
Módulo:  features.10  Porcentaje de pruning:  0.020175509982638888
Módulo:  features.12  Porcentaje de pruning:  0.024615817599826388
Módulo:  features.14  Porcentaje de pruning:  0.024281819661458332
Módulo:  features.17  Porcentaje de pruning:  0.028626335991753474
Módulo:  features.19  Porcentaje de pruning:  0.03570599026150174
Módulo:  features.21  Porcentaje de pruning:  0.03570387098524305
Módulo:  features.24  Porcentaje de pruning:  0.03359222412109375
Módulo:  features.26  Porcentaje de pruning:  0.03325102064344618
Módulo:  features.28  Porcentaje de pruning:  0.03762520684136285
Módulo:  classifier.0  Porcentaje de pruning:  0.11663449540430186
Módulo:  classifier.3  Porcentaje de pruning:  0.05722403526306152
Módulo:  classifier.6  Porcentaje de pruning:  0.04422244510135135
[0.0023148148148148147, 0.014431423611111112, 0.016289605034722224, 0.01727294921875, 0.020175509982638888, 0.024615817599826388, 0.024281819661458332, 0.028626335991753474, 0.03570599026150174, 0.03570387098524305, 0.03359222412109375, 0.03325102064344618, 0.03762520684136285, 0.11663449540430186, 0.05722403526306152, 0.04422244510135135]
Epoch 0/24
----------
train Loss: 1.4519 Acc: 0.5875 Balanced Acc: 0.5876
val Loss: 0.8634 Acc: 0.7378 Balanced Acc: 0.7374

Epoch 1/24
----------
train Loss: 0.7304 Acc: 0.7652 Balanced Acc: 0.7653
val Loss: 0.6737 Acc: 0.8019 Balanced Acc: 0.8015

Epoch 2/24
----------
train Loss: 0.6604 Acc: 0.7959 Balanced Acc: 0.7959
val Loss: 0.7090 Acc: 0.7806 Balanced Acc: 0.7807

Epoch 3/24
----------
train Loss: 0.6139 Acc: 0.8092 Balanced Acc: 0.8092
val Loss: 0.6579 Acc: 0.7964 Balanced Acc: 0.7960

Epoch 4/24
----------
train Loss: 0.5542 Acc: 0.8272 Balanced Acc: 0.8273
val Loss: 0.8085 Acc: 0.7648 Balanced Acc: 0.7642

Epoch 5/24
----------
train Loss: 0.5174 Acc: 0.8364 Balanced Acc: 0.8366
val Loss: 0.8372 Acc: 0.7517 Balanced Acc: 0.7522

Epoch 6/24
----------
train Loss: 0.5087 Acc: 0.8340 Balanced Acc: 0.8340
val Loss: 0.6305 Acc: 0.8196 Balanced Acc: 0.8192

Epoch 7/24
----------
train Loss: 0.3964 Acc: 0.8761 Balanced Acc: 0.8762
val Loss: 0.5918 Acc: 0.8258 Balanced Acc: 0.8253

Epoch 8/24
----------
train Loss: 0.3643 Acc: 0.8815 Balanced Acc: 0.8817
val Loss: 0.6248 Acc: 0.8098 Balanced Acc: 0.8093

Epoch 9/24
----------
train Loss: 0.3667 Acc: 0.8821 Balanced Acc: 0.8822
val Loss: 0.6070 Acc: 0.8190 Balanced Acc: 0.8185

Epoch 10/24
----------
train Loss: 0.3459 Acc: 0.8883 Balanced Acc: 0.8884
val Loss: 0.5816 Acc: 0.8294 Balanced Acc: 0.8288

Epoch 11/24
----------
train Loss: 0.3368 Acc: 0.8921 Balanced Acc: 0.8923
val Loss: 0.5777 Acc: 0.8231 Balanced Acc: 0.8227

Epoch 12/24
----------
train Loss: 0.3436 Acc: 0.8864 Balanced Acc: 0.8866
val Loss: 0.5691 Acc: 0.8307 Balanced Acc: 0.8303

Epoch 13/24
----------
train Loss: 0.3279 Acc: 0.8967 Balanced Acc: 0.8968
val Loss: 0.5428 Acc: 0.8384 Balanced Acc: 0.8380

Epoch 14/24
----------
train Loss: 0.3408 Acc: 0.8878 Balanced Acc: 0.8878
val Loss: 0.5477 Acc: 0.8378 Balanced Acc: 0.8375

Epoch 15/24
----------
train Loss: 0.3187 Acc: 0.9003 Balanced Acc: 0.9004
val Loss: 0.5481 Acc: 0.8343 Balanced Acc: 0.8339

Epoch 16/24
----------
train Loss: 0.3320 Acc: 0.8965 Balanced Acc: 0.8964
val Loss: 0.5601 Acc: 0.8359 Balanced Acc: 0.8355

Epoch 17/24
----------
train Loss: 0.3302 Acc: 0.8946 Balanced Acc: 0.8946
val Loss: 0.5582 Acc: 0.8324 Balanced Acc: 0.8320

Epoch 18/24
----------
train Loss: 0.3200 Acc: 0.9019 Balanced Acc: 0.9021
val Loss: 0.6015 Acc: 0.8228 Balanced Acc: 0.8220

Epoch 19/24
----------
train Loss: 0.3065 Acc: 0.9049 Balanced Acc: 0.9050
val Loss: 0.6012 Acc: 0.8234 Balanced Acc: 0.8228

Epoch 20/24
----------
train Loss: 0.3246 Acc: 0.8929 Balanced Acc: 0.8931
val Loss: 0.5561 Acc: 0.8378 Balanced Acc: 0.8373

Epoch 21/24
----------
train Loss: 0.3284 Acc: 0.8943 Balanced Acc: 0.8943
val Loss: 0.5628 Acc: 0.8286 Balanced Acc: 0.8284

Epoch 22/24
----------
train Loss: 0.3248 Acc: 0.8984 Balanced Acc: 0.8984
val Loss: 0.5499 Acc: 0.8340 Balanced Acc: 0.8334

Epoch 23/24
----------
train Loss: 0.3283 Acc: 0.8981 Balanced Acc: 0.8982
val Loss: 0.5500 Acc: 0.8359 Balanced Acc: 0.8354

Epoch 24/24
----------
train Loss: 0.2938 Acc: 0.9076 Balanced Acc: 0.9077
val Loss: 0.5658 Acc: 0.8362 Balanced Acc: 0.8359

Training complete in 32m 29s
Best val Balanced Acc: 0.838027
Validation:
Val_bal_acc: [0.7374004843976383, 0.8015173403052966, 0.7807044657179522, 0.7960488363785512, 0.7642183405905671, 0.7521985919520298, 0.8192209413202779, 0.8253188165289571, 0.8092885696247382, 0.8184864712158653, 0.8288326313084302, 0.8227139237924266, 0.8303366241503125, 0.8380273586018984, 0.837530853355761, 0.8339033290613606, 0.8354598677198006, 0.8320407081666205, 0.8220135597871364, 0.822795674256183, 0.8373252013989385, 0.8283824677258511, 0.8334155850486875, 0.8354007654423833, 0.8358626562742829]
Val_acc: [tensor(0.7378, device='cuda:0', dtype=torch.float64), tensor(0.8019, device='cuda:0', dtype=torch.float64), tensor(0.7806, device='cuda:0', dtype=torch.float64), tensor(0.7964, device='cuda:0', dtype=torch.float64), tensor(0.7648, device='cuda:0', dtype=torch.float64), tensor(0.7517, device='cuda:0', dtype=torch.float64), tensor(0.8196, device='cuda:0', dtype=torch.float64), tensor(0.8258, device='cuda:0', dtype=torch.float64), tensor(0.8098, device='cuda:0', dtype=torch.float64), tensor(0.8190, device='cuda:0', dtype=torch.float64), tensor(0.8294, device='cuda:0', dtype=torch.float64), tensor(0.8231, device='cuda:0', dtype=torch.float64), tensor(0.8307, device='cuda:0', dtype=torch.float64), tensor(0.8384, device='cuda:0', dtype=torch.float64), tensor(0.8378, device='cuda:0', dtype=torch.float64), tensor(0.8343, device='cuda:0', dtype=torch.float64), tensor(0.8359, device='cuda:0', dtype=torch.float64), tensor(0.8324, device='cuda:0', dtype=torch.float64), tensor(0.8228, device='cuda:0', dtype=torch.float64), tensor(0.8234, device='cuda:0', dtype=torch.float64), tensor(0.8378, device='cuda:0', dtype=torch.float64), tensor(0.8286, device='cuda:0', dtype=torch.float64), tensor(0.8340, device='cuda:0', dtype=torch.float64), tensor(0.8359, device='cuda:0', dtype=torch.float64), tensor(0.8362, device='cuda:0', dtype=torch.float64)]
Val_loss: [0.8633532090354726, 0.673680854870403, 0.7089892652694976, 0.6578718987073974, 0.8084513451015634, 0.8372280871260552, 0.6305473898592031, 0.5917550399229357, 0.6247770989435055, 0.6069710692972083, 0.5815865579077709, 0.5776816465348436, 0.5690816991187533, 0.542767090826991, 0.547718279601833, 0.5480857742607642, 0.5600856950105, 0.5582228831014766, 0.6014741935743627, 0.601215151723187, 0.5561117716245282, 0.5628495608779058, 0.5499406322922165, 0.5500333083523947, 0.5657831680128119]
Training:
Train_bal_acc: [0.5875727743872905, 0.7653313210571273, 0.7958702874428679, 0.8092230170052749, 0.8273135342086956, 0.8366340717550396, 0.8340285263269135, 0.8761522592974205, 0.8816651805764706, 0.8821684477732866, 0.8883821651563587, 0.8923284611591066, 0.8866023354733032, 0.8967872161017325, 0.8878421530034434, 0.9003539646684807, 0.8963965395013784, 0.8946058118235538, 0.9020533363275299, 0.9050239205481142, 0.8931053340730759, 0.8942710452387872, 0.8983895956073379, 0.8982255862901025, 0.9077028678238356]
Train_acc: [tensor(0.5875, device='cuda:0', dtype=torch.float64), tensor(0.7652, device='cuda:0', dtype=torch.float64), tensor(0.7959, device='cuda:0', dtype=torch.float64), tensor(0.8092, device='cuda:0', dtype=torch.float64), tensor(0.8272, device='cuda:0', dtype=torch.float64), tensor(0.8364, device='cuda:0', dtype=torch.float64), tensor(0.8340, device='cuda:0', dtype=torch.float64), tensor(0.8761, device='cuda:0', dtype=torch.float64), tensor(0.8815, device='cuda:0', dtype=torch.float64), tensor(0.8821, device='cuda:0', dtype=torch.float64), tensor(0.8883, device='cuda:0', dtype=torch.float64), tensor(0.8921, device='cuda:0', dtype=torch.float64), tensor(0.8864, device='cuda:0', dtype=torch.float64), tensor(0.8967, device='cuda:0', dtype=torch.float64), tensor(0.8878, device='cuda:0', dtype=torch.float64), tensor(0.9003, device='cuda:0', dtype=torch.float64), tensor(0.8965, device='cuda:0', dtype=torch.float64), tensor(0.8946, device='cuda:0', dtype=torch.float64), tensor(0.9019, device='cuda:0', dtype=torch.float64), tensor(0.9049, device='cuda:0', dtype=torch.float64), tensor(0.8929, device='cuda:0', dtype=torch.float64), tensor(0.8943, device='cuda:0', dtype=torch.float64), tensor(0.8984, device='cuda:0', dtype=torch.float64), tensor(0.8981, device='cuda:0', dtype=torch.float64), tensor(0.9076, device='cuda:0', dtype=torch.float64)]
Train_loss: [1.4519471362881038, 0.730357205349466, 0.660359727818033, 0.6139042491498201, 0.5542194521945456, 0.5173620891311894, 0.5086794099082117, 0.39638878120028453, 0.36432300346053165, 0.3667452739632648, 0.34591364442654277, 0.33683428657443626, 0.34364986646434537, 0.32791373376613075, 0.3407770245619442, 0.31870526538594907, 0.33197785415079284, 0.33017501954151235, 0.3199582523949768, 0.30654912208733354, 0.3246269001908924, 0.3284186888648116, 0.3248008721872516, 0.328349964061509, 0.2937595962182335]
Dtd
Módulo:  features.0  Porcentaje de pruning:  0.004050925925925926
Módulo:  features.2  Porcentaje de pruning:  0.029947916666666668
Módulo:  features.5  Porcentaje de pruning:  0.030843098958333332
Módulo:  features.7  Porcentaje de pruning:  0.03508165147569445
Módulo:  features.10  Porcentaje de pruning:  0.040720621744791664
Módulo:  features.12  Porcentaje de pruning:  0.049936930338541664
Módulo:  features.14  Porcentaje de pruning:  0.04866366916232639
Módulo:  features.17  Porcentaje de pruning:  0.05792066786024305
Módulo:  features.19  Porcentaje de pruning:  0.07232115003797743
Módulo:  features.21  Porcentaje de pruning:  0.07234276665581597
Módulo:  features.24  Porcentaje de pruning:  0.0678147210015191
Módulo:  features.26  Porcentaje de pruning:  0.0675167507595486
Módulo:  features.28  Porcentaje de pruning:  0.07584381103515625
Módulo:  classifier.0  Porcentaje de pruning:  0.23305978580397002
Módulo:  classifier.3  Porcentaje de pruning:  0.11532777547836304
Módulo:  classifier.6  Porcentaje de pruning:  0.09007750166223404
[0.004050925925925926, 0.029947916666666668, 0.030843098958333332, 0.03508165147569445, 0.040720621744791664, 0.049936930338541664, 0.04866366916232639, 0.05792066786024305, 0.07232115003797743, 0.07234276665581597, 0.0678147210015191, 0.0675167507595486, 0.07584381103515625, 0.23305978580397002, 0.11532777547836304, 0.09007750166223404]
Epoch 0/24
----------
train Loss: 3.3030 Acc: 0.1840 Balanced Acc: 0.1840
val Loss: 2.0372 Acc: 0.4734 Balanced Acc: 0.4734

Epoch 1/24
----------
train Loss: 1.8631 Acc: 0.5005 Balanced Acc: 0.5005
val Loss: 1.6719 Acc: 0.5346 Balanced Acc: 0.5346

Epoch 2/24
----------
train Loss: 1.3714 Acc: 0.6090 Balanced Acc: 0.6090
val Loss: 1.6220 Acc: 0.5601 Balanced Acc: 0.5601

Epoch 3/24
----------
train Loss: 1.2311 Acc: 0.6287 Balanced Acc: 0.6287
val Loss: 1.6045 Acc: 0.5644 Balanced Acc: 0.5644

Epoch 4/24
----------
train Loss: 1.0641 Acc: 0.6862 Balanced Acc: 0.6862
val Loss: 1.6328 Acc: 0.5660 Balanced Acc: 0.5660

Epoch 5/24
----------
train Loss: 0.9363 Acc: 0.7250 Balanced Acc: 0.7250
val Loss: 1.6010 Acc: 0.5793 Balanced Acc: 0.5793

Epoch 6/24
----------
train Loss: 0.7741 Acc: 0.7622 Balanced Acc: 0.7622
val Loss: 1.5458 Acc: 0.5931 Balanced Acc: 0.5931

Epoch 7/24
----------
train Loss: 0.5676 Acc: 0.8223 Balanced Acc: 0.8223
val Loss: 1.4834 Acc: 0.5973 Balanced Acc: 0.5973

Epoch 8/24
----------
train Loss: 0.5302 Acc: 0.8282 Balanced Acc: 0.8282
val Loss: 1.5052 Acc: 0.6144 Balanced Acc: 0.6144

Epoch 9/24
----------
train Loss: 0.4447 Acc: 0.8569 Balanced Acc: 0.8569
val Loss: 1.5005 Acc: 0.6271 Balanced Acc: 0.6271

Epoch 10/24
----------
train Loss: 0.4261 Acc: 0.8638 Balanced Acc: 0.8638
val Loss: 1.6123 Acc: 0.6085 Balanced Acc: 0.6085

Epoch 11/24
----------
train Loss: 0.4161 Acc: 0.8670 Balanced Acc: 0.8670
val Loss: 1.5497 Acc: 0.6186 Balanced Acc: 0.6186

Epoch 12/24
----------
train Loss: 0.3748 Acc: 0.8867 Balanced Acc: 0.8867
val Loss: 1.5763 Acc: 0.6245 Balanced Acc: 0.6245

Epoch 13/24
----------
train Loss: 0.3899 Acc: 0.8830 Balanced Acc: 0.8830
val Loss: 1.5924 Acc: 0.6218 Balanced Acc: 0.6218

Epoch 14/24
----------
train Loss: 0.3511 Acc: 0.8910 Balanced Acc: 0.8910
val Loss: 1.5597 Acc: 0.6309 Balanced Acc: 0.6309

Epoch 15/24
----------
train Loss: 0.3377 Acc: 0.8899 Balanced Acc: 0.8899
val Loss: 1.5831 Acc: 0.6239 Balanced Acc: 0.6239

Epoch 16/24
----------
train Loss: 0.3446 Acc: 0.8941 Balanced Acc: 0.8941
val Loss: 1.5906 Acc: 0.6218 Balanced Acc: 0.6218

Epoch 17/24
----------
train Loss: 0.3255 Acc: 0.8947 Balanced Acc: 0.8947
val Loss: 1.5390 Acc: 0.6197 Balanced Acc: 0.6197

Epoch 18/24
----------
train Loss: 0.3423 Acc: 0.8872 Balanced Acc: 0.8872
val Loss: 1.5864 Acc: 0.6181 Balanced Acc: 0.6181

Epoch 19/24
----------
train Loss: 0.3280 Acc: 0.8989 Balanced Acc: 0.8989
val Loss: 1.5972 Acc: 0.6266 Balanced Acc: 0.6266

Epoch 20/24
----------
train Loss: 0.3179 Acc: 0.8984 Balanced Acc: 0.8984
val Loss: 1.6214 Acc: 0.6207 Balanced Acc: 0.6207

Epoch 21/24
----------
train Loss: 0.3563 Acc: 0.8883 Balanced Acc: 0.8883
val Loss: 1.6154 Acc: 0.6213 Balanced Acc: 0.6213

Epoch 22/24
----------
train Loss: 0.3410 Acc: 0.8904 Balanced Acc: 0.8904
val Loss: 1.6048 Acc: 0.6176 Balanced Acc: 0.6176

Epoch 23/24
----------
train Loss: 0.3028 Acc: 0.9085 Balanced Acc: 0.9085
val Loss: 1.6266 Acc: 0.6122 Balanced Acc: 0.6122

Epoch 24/24
----------
train Loss: 0.3269 Acc: 0.9005 Balanced Acc: 0.9005
val Loss: 1.5953 Acc: 0.6181 Balanced Acc: 0.6181

Training complete in 17m 50s
Best val Balanced Acc: 0.630851
Validation:
Val_bal_acc: [0.47340425531914904, 0.5345744680851063, 0.5601063829787235, 0.5643617021276597, 0.5659574468085106, 0.5792553191489362, 0.5930851063829788, 0.5973404255319147, 0.6143617021276596, 0.6271276595744683, 0.6085106382978721, 0.6186170212765955, 0.6244680851063829, 0.6218085106382979, 0.6308510638297873, 0.623936170212766, 0.621808510638298, 0.6196808510638298, 0.6180851063829788, 0.626595744680851, 0.6207446808510639, 0.6212765957446807, 0.6175531914893618, 0.6122340425531916, 0.6180851063829789]
Val_acc: [tensor(0.4734, device='cuda:0', dtype=torch.float64), tensor(0.5346, device='cuda:0', dtype=torch.float64), tensor(0.5601, device='cuda:0', dtype=torch.float64), tensor(0.5644, device='cuda:0', dtype=torch.float64), tensor(0.5660, device='cuda:0', dtype=torch.float64), tensor(0.5793, device='cuda:0', dtype=torch.float64), tensor(0.5931, device='cuda:0', dtype=torch.float64), tensor(0.5973, device='cuda:0', dtype=torch.float64), tensor(0.6144, device='cuda:0', dtype=torch.float64), tensor(0.6271, device='cuda:0', dtype=torch.float64), tensor(0.6085, device='cuda:0', dtype=torch.float64), tensor(0.6186, device='cuda:0', dtype=torch.float64), tensor(0.6245, device='cuda:0', dtype=torch.float64), tensor(0.6218, device='cuda:0', dtype=torch.float64), tensor(0.6309, device='cuda:0', dtype=torch.float64), tensor(0.6239, device='cuda:0', dtype=torch.float64), tensor(0.6218, device='cuda:0', dtype=torch.float64), tensor(0.6197, device='cuda:0', dtype=torch.float64), tensor(0.6181, device='cuda:0', dtype=torch.float64), tensor(0.6266, device='cuda:0', dtype=torch.float64), tensor(0.6207, device='cuda:0', dtype=torch.float64), tensor(0.6213, device='cuda:0', dtype=torch.float64), tensor(0.6176, device='cuda:0', dtype=torch.float64), tensor(0.6122, device='cuda:0', dtype=torch.float64), tensor(0.6181, device='cuda:0', dtype=torch.float64)]
Val_loss: [2.0372326896545734, 1.6718516740393132, 1.6220249165879919, 1.6044713213088664, 1.6327537085147614, 1.6010354894272825, 1.5457542087169405, 1.4834332669034918, 1.5052265562909715, 1.5004880221600227, 1.6122863434730692, 1.549683502379884, 1.576336052189482, 1.5924389397844356, 1.5596995925649684, 1.5831321018807432, 1.5905787125546882, 1.5390331993711757, 1.5863572230998506, 1.5971993894019025, 1.6213723740679153, 1.6154019619556184, 1.604815328374822, 1.62655268197364, 1.5953254298960908]
Training:
Train_bal_acc: [0.1840425531914894, 0.500531914893617, 0.6090425531914893, 0.6287234042553191, 0.6861702127659575, 0.7249999999999999, 0.7622340425531913, 0.8223404255319149, 0.8281914893617022, 0.8569148936170216, 0.8638297872340422, 0.8670212765957447, 0.8867021276595745, 0.8829787234042554, 0.8909574468085103, 0.8898936170212765, 0.8941489361702131, 0.8946808510638299, 0.8872340425531914, 0.8989361702127658, 0.8984042553191488, 0.8882978723404258, 0.8904255319148936, 0.9085106382978727, 0.9005319148936174]
Train_acc: [tensor(0.1840, device='cuda:0', dtype=torch.float64), tensor(0.5005, device='cuda:0', dtype=torch.float64), tensor(0.6090, device='cuda:0', dtype=torch.float64), tensor(0.6287, device='cuda:0', dtype=torch.float64), tensor(0.6862, device='cuda:0', dtype=torch.float64), tensor(0.7250, device='cuda:0', dtype=torch.float64), tensor(0.7622, device='cuda:0', dtype=torch.float64), tensor(0.8223, device='cuda:0', dtype=torch.float64), tensor(0.8282, device='cuda:0', dtype=torch.float64), tensor(0.8569, device='cuda:0', dtype=torch.float64), tensor(0.8638, device='cuda:0', dtype=torch.float64), tensor(0.8670, device='cuda:0', dtype=torch.float64), tensor(0.8867, device='cuda:0', dtype=torch.float64), tensor(0.8830, device='cuda:0', dtype=torch.float64), tensor(0.8910, device='cuda:0', dtype=torch.float64), tensor(0.8899, device='cuda:0', dtype=torch.float64), tensor(0.8941, device='cuda:0', dtype=torch.float64), tensor(0.8947, device='cuda:0', dtype=torch.float64), tensor(0.8872, device='cuda:0', dtype=torch.float64), tensor(0.8989, device='cuda:0', dtype=torch.float64), tensor(0.8984, device='cuda:0', dtype=torch.float64), tensor(0.8883, device='cuda:0', dtype=torch.float64), tensor(0.8904, device='cuda:0', dtype=torch.float64), tensor(0.9085, device='cuda:0', dtype=torch.float64), tensor(0.9005, device='cuda:0', dtype=torch.float64)]
Train_loss: [3.3029757509840296, 1.8631410375554511, 1.3713543029541666, 1.2310558537219434, 1.064122361325203, 0.9363350523279068, 0.7740846192583125, 0.5675809606592706, 0.5301663298556145, 0.4447103325356828, 0.42614504910529927, 0.41614248045581453, 0.37483085178314374, 0.3899046878865425, 0.3510973478885407, 0.33773719452797096, 0.3445913627109629, 0.32550864473302316, 0.34233299430380476, 0.3280402839817899, 0.3179472654423815, 0.3563256878802117, 0.34095669230248066, 0.3027586930609764, 0.32685855614378095]

VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=47, bias=True)
  )
)

