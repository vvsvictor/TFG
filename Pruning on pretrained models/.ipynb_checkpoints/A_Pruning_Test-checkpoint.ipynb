{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuEle44wlEQS"
   },
   "source": [
    "L1 pruning: torch.nn.utils.prune.l1_unstructured(module, name, amount, importance_scores=None)\n",
    "\n",
    "Ln pruning: torch.nn.utils.prune.ln_structured(module, name, amount, n, dim, importance_scores=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxTh8wWUk-9f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import Dataset\n",
    "from torch import autograd\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vgg16\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.utils.prune as prune\n",
    "from heapq import nsmallest\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7FTqZFo1p0a-"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w8vmJ2cfp91y"
   },
   "outputs": [],
   "source": [
    "class Cub2011(Dataset):\n",
    "    base_folder = 'CUB_200_2011/images'\n",
    "    url = 'https://data.caltech.edu/records/65de6-vp158/files/CUB_200_2011.tgz?download=1'\n",
    "    filename = 'CUB_200_2011.tgz'\n",
    "    tgz_md5 = '97eceeb196236b17998738112f37df78'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, loader=default_loader, download=True):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.loader = default_loader\n",
    "        self.train = train\n",
    "\n",
    "        if download:\n",
    "            self._download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        images = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'images.txt'), sep=' ',\n",
    "                             names=['img_id', 'filepath'])\n",
    "        image_class_labels = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'image_class_labels.txt'),\n",
    "                                         sep=' ', names=['img_id', 'target'])\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'train_test_split.txt'),\n",
    "                                       sep=' ', names=['img_id', 'is_training_img'])\n",
    "\n",
    "        data = images.merge(image_class_labels, on='img_id')\n",
    "        self.data = data.merge(train_test_split, on='img_id')\n",
    "\n",
    "        if self.train:\n",
    "            self.data = self.data[self.data.is_training_img == 1]\n",
    "        else:\n",
    "            self.data = self.data[self.data.is_training_img == 0]\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        try:\n",
    "            self._load_metadata()\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "        for index, row in self.data.iterrows():\n",
    "            filepath = os.path.join(self.root, self.base_folder, row.filepath)\n",
    "            if not os.path.isfile(filepath):\n",
    "                print(filepath)\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        download_url(self.url, self.root, self.filename, self.tgz_md5)\n",
    "\n",
    "        with tarfile.open(os.path.join(self.root, self.filename), \"r:gz\") as tar:\n",
    "            tar.extractall(path=self.root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        path = os.path.join(self.root, self.base_folder, sample.filepath)\n",
    "        target = sample.target - 1 \n",
    "        img = self.loader(path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0fqG-5uorkzH"
   },
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X24oSlPZqFQN",
    "outputId": "e3ed0749-ae41-499a-b1cd-9f8d0a556aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_ds = Cub2011('.', train=True, transform = transform)\n",
    "val_ds = Cub2011('.s', train=False, transform = transform)\n",
    "\n",
    "ds = {'train': DataLoader(train_ds, batch_size = 32, shuffle=True),\n",
    "      'val': DataLoader(val_ds, batch_size = 32, shuffle=False)}\n",
    "\n",
    "\n",
    "ds_sizes = {'train': len(train_ds),\n",
    "      'val': len(val_ds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UqSMjeE3wDWw"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes,nclas, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_bal_acc = 0.0\n",
    "\n",
    "    val_bal_acc = []\n",
    "    val_acc = []\n",
    "    val_loss = []\n",
    "\n",
    "    train_bal_acc = []\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            CF = np.zeros((nclas,nclas)) # Confusion matrix\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                for i in range(len(labels.data)):\n",
    "                    CF[labels.data[i]][preds[i]] +=1\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            recalli = 0\n",
    "            for i in range(nclas):\n",
    "                TP = CF[i][i]\n",
    "                FN = 0\n",
    "                for j in range(nclas):\n",
    "                    if i!=j:\n",
    "                        FN+=CF[i][j]\n",
    "                if (TP+FN) !=0:\n",
    "                    recalli+= TP/(TP+FN)\n",
    "            epoch_bal_acc = recalli/nclas\n",
    "\n",
    "            if phase == 'val':\n",
    "                val_bal_acc.append(epoch_bal_acc)\n",
    "                val_acc.append(epoch_acc)\n",
    "                val_loss.append(epoch_loss)\n",
    "            else:\n",
    "                train_bal_acc.append(epoch_bal_acc)\n",
    "                train_acc.append(epoch_acc)\n",
    "                train_loss.append(epoch_loss)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Balanced Acc: {epoch_bal_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_bal_acc > best_bal_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_bal_acc = epoch_bal_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    #print(f'Best val Acc: {best_acc:4f}')\n",
    "    print(f'Best val Balanced Acc: {best_bal_acc:4f}')\n",
    "\n",
    "    print('Validation:')\n",
    "    print('Val_bal_acc:', val_bal_acc)\n",
    "    print('Val_acc:', val_acc)\n",
    "    print('Val_loss:', val_loss)\n",
    "\n",
    "    print('Training:')\n",
    "    print('Train_bal_acc:', train_bal_acc)\n",
    "    print('Train_acc:', train_acc)\n",
    "    print('Train_loss:', train_loss)\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCKJQp1d98Cc"
   },
   "source": [
    "Pruning % of each layer (L1-Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "k3kWLztr6uhA"
   },
   "outputs": [],
   "source": [
    "#If finetuning == False -> Feature extraction\n",
    "def imageNetPruningCUBL1(pruningAmount, epochs, finetuning): \n",
    "  model = vgg16(weights='IMAGENET1K_V1')\n",
    "  model.classifier[6] = nn.Linear(4096, 200) \n",
    "\n",
    "  features = []\n",
    "  classifier = []\n",
    "\n",
    "  for n,p in model.named_parameters():\n",
    "    if n.split('.')[0] == 'features' and n.split('.')[2] == 'weight':\n",
    "      features.append(int(n.split('.')[1]))\n",
    "    elif n.split('.')[0] == 'classifier' and n.split('.')[2] == 'weight':\n",
    "      classifier.append(int(n.split('.')[1]))\n",
    "\n",
    "  for x in features:\n",
    "    prune.l1_unstructured(model.features[x], 'weight', amount=pruningAmount)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  for x in classifier:\n",
    "    prune.l1_unstructured(model.classifier[x], 'weight', amount=pruningAmount)\n",
    "\n",
    "  if(finetuning):\n",
    "    optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "  else:\n",
    "    optimizer_ft = optim.SGD(model.classifier[6].parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "  model = model.to(device)\n",
    "\n",
    "  model_conv = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, ds, ds_sizes, 200, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "sdUal0HO7CIC",
    "outputId": "e6fd5a1e-9d3d-4061-b94f-c8f34a7230aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 10% ... with Fine Tuning\n",
      "Before:\n",
      "Parameter containing:\n",
      "tensor([[[[-5.5373e-01,  1.4270e-01,  5.2896e-01],\n",
      "          [-5.8312e-01,  3.5655e-01,  7.6566e-01],\n",
      "          [-6.9022e-01, -4.8019e-02,  4.8409e-01]],\n",
      "\n",
      "         [[ 1.7548e-01,  9.8630e-03, -8.1413e-02],\n",
      "          [ 4.4089e-02, -7.0323e-02, -2.6035e-01],\n",
      "          [ 1.3239e-01, -1.7279e-01, -1.3226e-01]],\n",
      "\n",
      "         [[ 3.1303e-01, -1.6591e-01, -4.2752e-01],\n",
      "          [ 4.7519e-01, -8.2677e-02, -4.8700e-01],\n",
      "          [ 6.3203e-01,  1.9308e-02, -2.7753e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3254e-01,  1.2666e-01,  1.8605e-01],\n",
      "          [-4.2805e-01, -2.4349e-01,  2.4628e-01],\n",
      "          [-2.5066e-01,  1.4177e-01, -5.4864e-03]],\n",
      "\n",
      "         [[-1.4076e-01, -2.1903e-01,  1.5041e-01],\n",
      "          [-8.4127e-01, -3.5176e-01,  5.6398e-01],\n",
      "          [-2.4194e-01,  5.1928e-01,  5.3915e-01]],\n",
      "\n",
      "         [[-3.1432e-01, -3.7048e-01, -1.3094e-01],\n",
      "          [-4.7144e-01, -1.5503e-01,  3.4589e-01],\n",
      "          [ 5.4384e-02,  5.8683e-01,  4.9580e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7715e-01,  5.2149e-01,  9.8740e-03],\n",
      "          [-2.7185e-01, -7.1709e-01,  3.1292e-01],\n",
      "          [-7.5753e-02, -2.2079e-01,  3.3455e-01]],\n",
      "\n",
      "         [[ 3.0924e-01,  6.7071e-01,  2.0546e-02],\n",
      "          [-4.6607e-01, -1.0697e+00,  3.3501e-01],\n",
      "          [-8.0284e-02, -3.0522e-01,  5.4460e-01]],\n",
      "\n",
      "         [[ 3.1572e-01,  4.2335e-01, -3.4976e-01],\n",
      "          [ 8.6354e-02, -4.6457e-01,  1.1803e-02],\n",
      "          [ 1.0483e-01, -1.4584e-01, -1.5765e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.7599e-02,  1.2692e-01,  3.2305e-02],\n",
      "          [ 2.2131e-01,  2.4681e-01, -4.6637e-02],\n",
      "          [ 4.6407e-02,  2.8246e-02,  1.7528e-02]],\n",
      "\n",
      "         [[-1.8327e-01, -6.7425e-02, -7.2120e-03],\n",
      "          [-4.8855e-02,  7.0427e-03, -1.2883e-01],\n",
      "          [-6.4601e-02, -6.4566e-02,  4.4235e-02]],\n",
      "\n",
      "         [[-2.2547e-01, -1.1931e-01, -2.3425e-02],\n",
      "          [-9.9171e-02, -1.5143e-02,  9.5385e-04],\n",
      "          [-2.6137e-02,  1.3567e-03,  1.4282e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6520e-02, -3.2225e-02, -3.8450e-03],\n",
      "          [-6.8206e-02, -1.9445e-01, -1.4166e-01],\n",
      "          [-6.9528e-02, -1.8340e-01, -1.7422e-01]],\n",
      "\n",
      "         [[ 4.2781e-02, -6.7529e-02, -7.0309e-03],\n",
      "          [ 1.1765e-02, -1.4958e-01, -1.2361e-01],\n",
      "          [ 1.0205e-02, -1.0393e-01, -1.1742e-01]],\n",
      "\n",
      "         [[ 1.2661e-01,  8.5046e-02,  1.3066e-01],\n",
      "          [ 1.7585e-01,  1.1288e-01,  1.1937e-01],\n",
      "          [ 1.4656e-01,  9.8892e-02,  1.0348e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2176e-02, -1.0766e-01, -2.6388e-01],\n",
      "          [ 2.7957e-01, -3.7416e-02, -2.5471e-01],\n",
      "          [ 3.4872e-01,  3.0041e-02, -5.5898e-02]],\n",
      "\n",
      "         [[ 2.5063e-01,  1.5543e-01, -1.7432e-01],\n",
      "          [ 3.9255e-01,  3.2306e-02, -3.5191e-01],\n",
      "          [ 1.9299e-01, -1.9898e-01, -2.9713e-01]],\n",
      "\n",
      "         [[ 4.6032e-01,  4.3399e-01,  2.8352e-01],\n",
      "          [ 1.6341e-01, -5.8165e-02, -1.9196e-01],\n",
      "          [-1.9521e-01, -4.5630e-01, -4.2732e-01]]]], requires_grad=True)\n",
      "After\n",
      "tensor([[[[-0., 0., 0.],\n",
      "          [-0., 0., 0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [0., -0., -0.],\n",
      "          [0., -0., -0.]],\n",
      "\n",
      "         [[0., -0., -0.],\n",
      "          [0., -0., -0.],\n",
      "          [0., 0., -0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., 0., -0.]],\n",
      "\n",
      "         [[-0., -0., 0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [0., -0., 0.],\n",
      "          [0., -0., -0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., -0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [-0., 0., -0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., -0., -0.],\n",
      "          [-0., -0., -0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         [[0., -0., -0.],\n",
      "          [0., -0., -0.],\n",
      "          [0., -0., -0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., -0., -0.],\n",
      "          [0., -0., -0.],\n",
      "          [0., 0., -0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [0., 0., -0.],\n",
      "          [0., -0., -0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., -0., -0.],\n",
      "          [-0., -0., -0.]]]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for x in range(1, 7):\n",
    "  pruningAmount = x/10\n",
    "  print(\"Pruning \"+ str(x*10)+'% ... with Fine Tuning')\n",
    "  imageNetPruningCUBL1(0.9999, 25, True)\n",
    "  break\n",
    "  print(\"Pruning \"+ str(x*10)+'% ... with Feature Extraction')\n",
    "  imageNetPruningCUBL1(pruningAmount, 25, False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsXkGunMEIp6"
   },
   "source": [
    "Pruning % of entire model (L1-Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHkd29yaD_Bw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwJJhST581Eq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
