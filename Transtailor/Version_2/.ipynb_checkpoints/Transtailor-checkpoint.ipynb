{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gW7H6FygFyzr"
   },
   "source": [
    "Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l5NI0wgQFkRD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vgg16\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yihMHI_GBUX"
   },
   "source": [
    "Activar acceleración por hardware -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WaQVjQOFya-",
    "outputId": "d72a12d8-584d-4566-fb85-ebe14e707f97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhYfK8f5F5aM",
    "outputId": "6466241f-85ec-4e65-cb2a-54461ab6b238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 31 22:05:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 522.06       Driver Version: 522.06       CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 45%   33C    P8    13W /  95W |    737MiB /  2048MiB |      7%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla M40 24GB     TCC   | 00000000:2B:00.0 Off |           1488973049 |\n",
      "| N/A   75C    P8    19W / 250W |     10MiB / 23040MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1888    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A      3044    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5964    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A      7508    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      8948    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9960    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11292    C+G   ...s\\LibreWolf\\librewolf.exe    N/A      |\n",
      "|    0   N/A  N/A     12124    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     13944    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bhWM4ImbF7MQ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF0S6lUiGZYH"
   },
   "source": [
    "Función de carga del dataset CUB (El dataset se descarga automáticamente al ejecutar las siguientes celdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ux5xbkoEGEIJ"
   },
   "outputs": [],
   "source": [
    "class Cub2011(Dataset):\n",
    "    base_folder = 'CUB_200_2011/images'\n",
    "    url = 'https://data.caltech.edu/records/65de6-vp158/files/CUB_200_2011.tgz?download=1'\n",
    "    filename = 'CUB_200_2011.tgz'\n",
    "    tgz_md5 = '97eceeb196236b17998738112f37df78'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, loader=default_loader, download=True):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.loader = default_loader\n",
    "        self.train = train\n",
    "\n",
    "        if download:\n",
    "            self._download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        images = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'images.txt'), sep=' ',\n",
    "                             names=['img_id', 'filepath'])\n",
    "        image_class_labels = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'image_class_labels.txt'),\n",
    "                                         sep=' ', names=['img_id', 'target'])\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'train_test_split.txt'),\n",
    "                                       sep=' ', names=['img_id', 'is_training_img'])\n",
    "\n",
    "        data = images.merge(image_class_labels, on='img_id')\n",
    "        self.data = data.merge(train_test_split, on='img_id')\n",
    "\n",
    "        if self.train:\n",
    "            self.data = self.data[self.data.is_training_img == 1]\n",
    "        else:\n",
    "            self.data = self.data[self.data.is_training_img == 0]\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        try:\n",
    "            self._load_metadata()\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "        for index, row in self.data.iterrows():\n",
    "            filepath = os.path.join(self.root, self.base_folder, row.filepath)\n",
    "            if not os.path.isfile(filepath):\n",
    "                print(filepath)\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        download_url(self.url, self.root, self.filename, self.tgz_md5)\n",
    "\n",
    "        with tarfile.open(os.path.join(self.root, self.filename), \"r:gz\") as tar:\n",
    "            tar.extractall(path=self.root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        path = os.path.join(self.root, self.base_folder, sample.filepath)\n",
    "        target = sample.target - 1 \n",
    "        img = self.loader(path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23qqQFV1GjWS"
   },
   "source": [
    "Preprocesado de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "15JoU_PQGjAO"
   },
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxz6ldGoG0bE"
   },
   "source": [
    "Carga del dataset (Colab no soporta un batch_size muy alto así que lo dejo en 64 para la prueba)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xb6IhrWfGtih",
    "outputId": "d6dced00-85f3-49b8-a68f-300439360fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_ds = Cub2011('.', train=True, transform = transform)\n",
    "val_ds = Cub2011('.s', train=False, transform = transform)\n",
    "\n",
    "ds = {'train': DataLoader(train_ds, batch_size = 64, shuffle=True),\n",
    "      'val': DataLoader(val_ds, batch_size = 64, shuffle=False)}\n",
    "\n",
    "\n",
    "ds_sizes = {'train': len(train_ds),\n",
    "      'val': len(val_ds)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8At2Z94CHCPL"
   },
   "source": [
    "Función de entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uD5xkrWCG_op"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=40, nclas=200):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    #best_acc = 0.0\n",
    "    best_bal_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            CF = np.zeros((nclas,nclas)) # Confusion matrix\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in ds[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                for i in range(len(labels.data)):\n",
    "                    CF[labels.data[i]][preds[i]] +=1\n",
    "                \n",
    "            #if phase == 'train':\n",
    "            #    scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / ds_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / ds_sizes[phase]\n",
    "            recalli = 0\n",
    "            for i in range(nclas):\n",
    "                TP = CF[i][i]\n",
    "                FN = 0\n",
    "                for j in range(nclas):\n",
    "                    if i!=j:\n",
    "                        FN+=CF[i][j]\n",
    "                if (TP+FN) !=0:\n",
    "                    recalli+= TP/(TP+FN)\n",
    "            epoch_bal_acc = recalli/nclas\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Balanced Acc: {epoch_bal_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_bal_acc > best_bal_acc:\n",
    "                best_bal_acc = epoch_bal_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Balanced Acc: {best_bal_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    return model, best_bal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2jOfrDdgHtT3"
   },
   "outputs": [],
   "source": [
    "class AlphaConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(AlphaConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
    "        #One alpha per filter\n",
    "        #self.alpha = nn.Parameter(torch.ones(out_channels, 1, 1, 1))\n",
    "        self.alpha = nn.Parameter(torch.ones(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #return super(AlphaConv2d, self).forward(x) * self.alpha\n",
    "        return super(AlphaConv2d, self).forward(x) * self.alpha.unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zGK0VmaH9pF"
   },
   "source": [
    "Función para mostrar los parámetros de la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D9zPfuPHIJwO"
   },
   "outputs": [],
   "source": [
    "def check_weights(m):\n",
    "    if type(m) == AlphaConv2d:\n",
    "        for module in m.named_parameters():\n",
    "            print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FCSNfOOIT-K"
   },
   "source": [
    "Carga el modelo preentrenado (He utilizado una VGG16 para simplificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f1WkQ3ujHP9y"
   },
   "outputs": [],
   "source": [
    "model = vgg16(weights='IMAGENET1K_V1')\n",
    "model.classifier[6] = nn.Linear(4096, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2CcrU51nm7sK"
   },
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "  if type(module) == nn.Conv2d:\n",
    "    new_module = AlphaConv2d(module.in_channels, module.out_channels, module.kernel_size, module.stride, module.padding, module.dilation, module.groups, True)\n",
    "    new_module.weight = module.weight\n",
    "    new_module.bias = module.bias\n",
    "    model.features[int(name.split('.')[1])] = new_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "V2uu3kh6tXXH"
   },
   "outputs": [],
   "source": [
    "conv = [] #Conv layers\n",
    "fc = [] #FC layers\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if type(module) == AlphaConv2d:\n",
    "        conv.append(module.alpha)\n",
    "    elif type(module) == nn.Linear:\n",
    "        fc.append(module.weight)\n",
    "        fc.append(module.bias)\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "                {'params': conv},\n",
    "                {'params': fc, 'lr': 0.005}\n",
    "          ], weight_decay  = 0.005, momentum = 0.9, lr = 0.0005, dampening = 0.3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQtMDUeOWmsG",
    "outputId": "a8babb51-005f-452e-b5d4-af8f9f6d49fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 4.0794 Acc: 0.1513 Balanced Acc: 0.1513\n",
      "val Loss: 2.8963 Acc: 0.3407 Balanced Acc: 0.3435\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 2.7261 Acc: 0.3475 Balanced Acc: 0.3475\n",
      "val Loss: 2.4461 Acc: 0.4215 Balanced Acc: 0.4254\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 2.4396 Acc: 0.4017 Balanced Acc: 0.4017\n",
      "val Loss: 2.2932 Acc: 0.4363 Balanced Acc: 0.4408\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 2.2420 Acc: 0.4351 Balanced Acc: 0.4351\n",
      "val Loss: 2.1903 Acc: 0.4484 Balanced Acc: 0.4530\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 2.1374 Acc: 0.4543 Balanced Acc: 0.4542\n",
      "val Loss: 2.1285 Acc: 0.4613 Balanced Acc: 0.4659\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 2.0379 Acc: 0.4778 Balanced Acc: 0.4778\n",
      "val Loss: 2.1046 Acc: 0.4646 Balanced Acc: 0.4671\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 2.0261 Acc: 0.4786 Balanced Acc: 0.4786\n",
      "val Loss: 2.0457 Acc: 0.4720 Balanced Acc: 0.4761\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.9793 Acc: 0.4867 Balanced Acc: 0.4867\n",
      "val Loss: 2.0364 Acc: 0.4836 Balanced Acc: 0.4863\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.9462 Acc: 0.4968 Balanced Acc: 0.4968\n",
      "val Loss: 2.0257 Acc: 0.4808 Balanced Acc: 0.4851\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.8911 Acc: 0.5072 Balanced Acc: 0.5072\n",
      "val Loss: 2.0259 Acc: 0.4848 Balanced Acc: 0.4873\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.8773 Acc: 0.5108 Balanced Acc: 0.5108\n",
      "val Loss: 1.9879 Acc: 0.4826 Balanced Acc: 0.4875\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.8675 Acc: 0.5170 Balanced Acc: 0.5170\n",
      "val Loss: 1.9600 Acc: 0.4993 Balanced Acc: 0.5036\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.8319 Acc: 0.5265 Balanced Acc: 0.5265\n",
      "val Loss: 1.9811 Acc: 0.4909 Balanced Acc: 0.4936\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.7531 Acc: 0.5429 Balanced Acc: 0.5429\n",
      "val Loss: 1.9833 Acc: 0.4862 Balanced Acc: 0.4895\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.8102 Acc: 0.5340 Balanced Acc: 0.5340\n",
      "val Loss: 1.9647 Acc: 0.4964 Balanced Acc: 0.5015\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.7875 Acc: 0.5349 Balanced Acc: 0.5348\n",
      "val Loss: 1.9585 Acc: 0.5026 Balanced Acc: 0.5061\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.7675 Acc: 0.5392 Balanced Acc: 0.5392\n",
      "val Loss: 1.9609 Acc: 0.4919 Balanced Acc: 0.4958\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.7455 Acc: 0.5434 Balanced Acc: 0.5434\n",
      "val Loss: 1.9652 Acc: 0.4910 Balanced Acc: 0.4956\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.7533 Acc: 0.5382 Balanced Acc: 0.5382\n",
      "val Loss: 1.9708 Acc: 0.4902 Balanced Acc: 0.4945\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.7531 Acc: 0.5389 Balanced Acc: 0.5389\n",
      "val Loss: 1.9251 Acc: 0.5048 Balanced Acc: 0.5099\n",
      "\n",
      "Training complete in 91m 35s\n",
      "Best val Balanced Acc: 0.509911\n"
     ]
    }
   ],
   "source": [
    "optimizer_last = torch.optim.SGD(model.classifier[6].parameters(), lr=0.005, momentum=0.9, weight_decay=0.005)\n",
    "model = model.to(device)\n",
    "model, _ = train_model(model, criterion, optimizer_last, num_epochs=20, nclas=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQi_lUyJtJPF",
    "outputId": "575340b0-381c-477e-9081-2e0f41878c64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.6629 Acc: 0.5622 Balanced Acc: 0.5622\n",
      "val Loss: 1.9384 Acc: 0.4986 Balanced Acc: 0.5036\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.6254 Acc: 0.5691 Balanced Acc: 0.5691\n",
      "val Loss: 1.9414 Acc: 0.5000 Balanced Acc: 0.5028\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.5859 Acc: 0.5776 Balanced Acc: 0.5776\n",
      "val Loss: 1.8887 Acc: 0.5095 Balanced Acc: 0.5130\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.4922 Acc: 0.6029 Balanced Acc: 0.6030\n",
      "val Loss: 1.8980 Acc: 0.5105 Balanced Acc: 0.5150\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.4833 Acc: 0.6011 Balanced Acc: 0.6011\n",
      "val Loss: 1.8904 Acc: 0.5136 Balanced Acc: 0.5173\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.4291 Acc: 0.6158 Balanced Acc: 0.6158\n",
      "val Loss: 1.8548 Acc: 0.5231 Balanced Acc: 0.5272\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.3756 Acc: 0.6355 Balanced Acc: 0.6354\n",
      "val Loss: 1.8502 Acc: 0.5249 Balanced Acc: 0.5285\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.3423 Acc: 0.6380 Balanced Acc: 0.6380\n",
      "val Loss: 1.8219 Acc: 0.5255 Balanced Acc: 0.5307\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.2957 Acc: 0.6528 Balanced Acc: 0.6528\n",
      "val Loss: 1.8454 Acc: 0.5231 Balanced Acc: 0.5268\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.2680 Acc: 0.6610 Balanced Acc: 0.6610\n",
      "val Loss: 1.7756 Acc: 0.5342 Balanced Acc: 0.5356\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.2653 Acc: 0.6570 Balanced Acc: 0.6570\n",
      "val Loss: 1.8254 Acc: 0.5259 Balanced Acc: 0.5301\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.2174 Acc: 0.6732 Balanced Acc: 0.6732\n",
      "val Loss: 1.8224 Acc: 0.5319 Balanced Acc: 0.5350\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.2385 Acc: 0.6690 Balanced Acc: 0.6690\n",
      "val Loss: 1.8024 Acc: 0.5297 Balanced Acc: 0.5319\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.1952 Acc: 0.6718 Balanced Acc: 0.6718\n",
      "val Loss: 1.8344 Acc: 0.5307 Balanced Acc: 0.5354\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.1622 Acc: 0.6810 Balanced Acc: 0.6810\n",
      "val Loss: 1.7968 Acc: 0.5323 Balanced Acc: 0.5358\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.1396 Acc: 0.6935 Balanced Acc: 0.6935\n",
      "val Loss: 1.8079 Acc: 0.5342 Balanced Acc: 0.5377\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.1422 Acc: 0.6905 Balanced Acc: 0.6905\n",
      "val Loss: 1.7673 Acc: 0.5411 Balanced Acc: 0.5445\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.1318 Acc: 0.6957 Balanced Acc: 0.6957\n",
      "val Loss: 1.7716 Acc: 0.5400 Balanced Acc: 0.5434\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.1127 Acc: 0.6975 Balanced Acc: 0.6976\n",
      "val Loss: 1.7414 Acc: 0.5483 Balanced Acc: 0.5517\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.0798 Acc: 0.7160 Balanced Acc: 0.7160\n",
      "val Loss: 1.7514 Acc: 0.5419 Balanced Acc: 0.5451\n",
      "\n",
      "Training complete in 73m 15s\n",
      "Best val Balanced Acc: 0.551743\n",
      "Pruned 3 filters\n",
      "tensor([0.9886, 0.9857, 0.9788, 0.9595, 0.9931, 0.9624, 1.0014, 0.9542, 0.9673,\n",
      "        0.9357, 0.9722, 0.9682, 0.9710, 0.9739, 0.9792, 0.9733, 0.9965, 0.9548,\n",
      "        0.9692, 0.9805, 0.9854, 0.9783, 0.9718, 0.9916, 0.9709, 0.9800, 0.9607,\n",
      "        0.9710, 0.9695, 0.9793, 0.9789, 0.9838, 0.9773, 0.9670, 0.9870, 0.9700,\n",
      "        0.9400, 0.9745, 0.9785, 0.9738, 0.9843, 0.9616, 0.9756, 0.9656, 0.9754,\n",
      "        0.9717, 0.9497, 1.0256, 0.9758, 0.9649, 0.9642, 1.0004, 0.9582, 0.9762,\n",
      "        0.9651, 0.9812, 0.9808, 0.9795, 1.0086, 0.9893, 0.9831, 0.9928, 0.9718,\n",
      "        0.9828])\n",
      "Pruned 4 filters\n",
      "tensor([0.9875, 0.9704, 0.9904, 0.9567, 0.9786, 0.9784, 0.9909, 0.9664, 0.9505,\n",
      "        1.0058, 1.0047, 0.9501, 0.9793, 0.9424, 0.9851, 0.9641, 0.9863, 0.9716,\n",
      "        0.9612, 0.9770, 1.0112, 0.9728, 0.9975, 0.9594, 0.9861, 0.9662, 0.9659,\n",
      "        0.9786, 0.9949, 0.9784, 0.9878, 0.9630, 0.9936, 0.9780, 1.0049, 0.9688,\n",
      "        1.0245, 0.9495, 0.9946, 0.9551, 0.9875, 0.9682, 0.9690, 0.9794, 0.9753,\n",
      "        0.9804, 0.9929, 0.9542, 1.0044, 0.9900, 0.9566, 0.9759, 0.9831, 0.9628,\n",
      "        0.9582, 0.9827, 1.0176, 0.9838, 0.9739, 0.9454, 1.0171, 0.9535, 0.9235,\n",
      "        0.9554])\n",
      "Pruned 2 filters\n",
      "tensor([0.9731, 0.9626, 1.0077, 0.9803, 0.9928, 0.9726, 0.9740, 0.9405, 0.9810,\n",
      "        0.9684, 0.9776, 0.9732, 0.9678, 0.9668, 0.9630, 0.9613, 0.9706, 0.9869,\n",
      "        0.9734, 0.9819, 0.9845, 0.9719, 0.9674, 0.9735, 0.9776, 0.9693, 0.9608,\n",
      "        0.9669, 0.9658, 0.9724, 0.9513, 0.9716, 0.9883, 0.9721, 0.9803, 0.9766,\n",
      "        0.9658, 0.9684, 0.9795, 0.9850, 0.9726, 0.9657, 0.9686, 0.9671, 0.9586,\n",
      "        0.9713, 0.9757, 0.9818, 0.9720, 0.9850, 0.9778, 0.9719, 0.9634, 0.9799,\n",
      "        0.9673, 0.9702, 0.9608, 0.9838, 0.9685, 0.9774, 0.9785, 0.9773, 0.9713,\n",
      "        0.9786, 0.9810, 0.9670, 0.9634, 0.9647, 0.9633, 0.9645, 0.9663, 0.9788,\n",
      "        0.9668, 0.9702, 0.9757, 0.9550, 0.9835, 0.9924, 0.9705, 0.9797, 0.9565,\n",
      "        0.9756, 0.9667, 0.9700, 0.9341, 0.9735, 0.9575, 0.9768, 0.9692, 0.9709,\n",
      "        0.9693, 0.9689, 0.9784, 0.9992, 0.9835, 0.9790, 0.9725, 0.9689, 0.9608,\n",
      "        0.9631, 0.9698, 0.9849, 0.9674, 0.9608, 0.9779, 0.9612, 0.9713, 0.9956,\n",
      "        0.9764, 0.9679, 0.9733, 0.9646, 0.9677, 0.9782, 0.9745, 0.9630, 0.9875,\n",
      "        0.9830, 0.9675, 0.9815, 0.9847, 0.9730, 0.9857, 0.9740, 0.9763, 0.9759,\n",
      "        0.9612, 0.9663])\n",
      "Pruned 10 filters\n",
      "tensor([0.9616, 1.0037, 0.9796, 0.9390, 0.9753, 0.9662, 0.9798, 1.0139, 1.0025,\n",
      "        0.9777, 0.9733, 0.9494, 0.9640, 0.9731, 0.9685, 0.9726, 0.9739, 0.9534,\n",
      "        0.9622, 0.9835, 0.9743, 0.9566, 0.9657, 0.9831, 1.0244, 0.9671, 0.9724,\n",
      "        0.9801, 0.9802, 0.9857, 0.9416, 0.9770, 0.9594, 1.0117, 0.9694, 0.9861,\n",
      "        0.9675, 0.9567, 1.0246, 0.9687, 0.9606, 0.9649, 0.9663, 0.9492, 1.0026,\n",
      "        0.9445, 0.9520, 0.9712, 0.9859, 0.9322, 0.9662, 0.9445, 0.9714, 0.9754,\n",
      "        0.9626, 0.9641, 0.9899, 0.9715, 0.9801, 0.9809, 0.9810, 0.9711, 0.9559,\n",
      "        0.9608, 0.9738, 0.9985, 0.9582, 0.9733, 0.9718, 0.9522, 0.9315, 0.9701,\n",
      "        0.9779, 0.9713, 0.9763, 0.9958, 0.9794, 0.9910, 0.9673, 0.9813, 0.9792,\n",
      "        0.9866, 0.9667, 0.9721, 0.9770, 0.9689, 0.9681, 0.9624, 0.9524, 0.9602,\n",
      "        0.9748, 0.9781, 0.9694, 0.9774, 0.9960, 0.9790, 0.9565, 0.9743, 0.9790,\n",
      "        0.9801, 0.9506, 0.9684, 0.9515, 0.9728, 0.9822, 0.9639, 0.9809, 0.9828,\n",
      "        0.9788, 0.9479, 1.0258, 1.0063, 0.9524, 0.9760, 0.9701, 0.9759, 0.9838,\n",
      "        0.9651, 0.9650, 0.9627, 0.9687, 0.9388, 0.9580, 0.9885, 0.9656, 0.9596,\n",
      "        0.9718, 1.0193])\n",
      "Pruned 1 filters\n",
      "tensor([0.9623, 0.9702, 0.9605, 0.9719, 0.9623, 0.9792, 0.9741, 0.9695, 0.9582,\n",
      "        0.9763, 0.9623, 0.9733, 0.9774, 0.9711, 0.9620, 0.9712, 0.9760, 0.9692,\n",
      "        0.9714, 0.9951, 0.9616, 0.9657, 0.9779, 0.9638, 0.9609, 0.9719, 0.9830,\n",
      "        0.9708, 0.9653, 0.9654, 0.9993, 0.9555, 0.9680, 0.9713, 0.9679, 0.9658,\n",
      "        0.9703, 0.9725, 0.9688, 0.9887, 0.9811, 0.9791, 0.9732, 0.9697, 0.9643,\n",
      "        0.9678, 0.9747, 0.9724, 0.9628, 0.9798, 1.0044, 0.9733, 0.9669, 0.9642,\n",
      "        0.9698, 0.9785, 0.9619, 0.9665, 0.9673, 0.9663, 0.9718, 0.9676, 0.9790,\n",
      "        0.9659, 0.9616, 0.9644, 0.9717, 0.9673, 0.9627, 0.9729, 0.9637, 0.9626,\n",
      "        0.9710, 0.9638, 0.9661, 0.9763, 0.9689, 0.9712, 0.9640, 0.9700, 0.9689,\n",
      "        0.9635, 0.9717, 0.9669, 0.9724, 0.9620, 0.9823, 0.9670, 0.9694, 0.9721,\n",
      "        0.9699, 0.9682, 0.9799, 0.9661, 0.9699, 0.9660, 0.9652, 0.9802, 0.9695,\n",
      "        0.9731, 0.9671, 0.9759, 0.9701, 0.9560, 0.9935, 0.9621, 0.9665, 0.9872,\n",
      "        0.9631, 0.9581, 0.9775, 0.9770, 0.9610, 0.9701, 0.9527, 0.9882, 0.9771,\n",
      "        0.9630, 0.9618, 0.9791, 0.9644, 0.9700, 0.9706, 0.9635, 0.9601, 0.9738,\n",
      "        0.9625, 0.9653, 0.9704, 0.9852, 0.9683, 0.9717, 0.9641, 0.9756, 0.9829,\n",
      "        0.9727, 0.9674, 0.9580, 0.9729, 0.9656, 0.9688, 0.9675, 0.9641, 0.9677,\n",
      "        0.9738, 0.9688, 0.9738, 0.9750, 0.9681, 0.9655, 0.9658, 0.9647, 0.9677,\n",
      "        0.9599, 0.9618, 0.9764, 0.9631, 0.9592, 0.9681, 0.9582, 0.9719, 0.9597,\n",
      "        0.9829, 0.9638, 0.9610, 0.9766, 0.9652, 0.9704, 0.9692, 0.9632, 0.9680,\n",
      "        0.9719, 0.9554, 0.9826, 0.9629, 0.9615, 0.9712, 0.9723, 0.9731, 0.9702,\n",
      "        0.9686, 0.9807, 0.9745, 1.0105, 0.9659, 0.9713, 0.9668, 1.0055, 0.9687,\n",
      "        0.9660, 0.9678, 0.9595, 0.9586, 0.9670, 0.9689, 0.9579, 0.9756, 0.9713,\n",
      "        0.9848, 0.9666, 0.9704, 0.9706, 0.9854, 0.9725, 0.9642, 0.9493, 0.9744,\n",
      "        0.9704, 0.9766, 0.9740, 1.0086, 0.9541, 0.9707, 0.9706, 0.9670, 0.9782,\n",
      "        0.9647, 0.9729, 0.9843, 0.9708, 0.9717, 0.9571, 0.9659, 0.9722, 0.9742,\n",
      "        0.9726, 0.9558, 0.9598, 0.9765, 0.9662, 0.9785, 0.9811, 0.9865, 0.9719,\n",
      "        0.9677, 0.9705, 0.9679, 0.9661, 0.9561, 0.9798, 0.9679, 0.9520, 0.9995,\n",
      "        0.9732, 0.9738, 0.9820, 0.9791, 0.9686, 0.9594, 0.9601, 0.9609, 0.9750,\n",
      "        0.9707, 0.9777, 0.9677, 0.9708])\n",
      "Pruned 1 filters\n",
      "tensor([0.9714, 0.9704, 0.9710, 0.9709, 0.9676, 0.9573, 0.9644, 0.9722, 0.9639,\n",
      "        0.9753, 0.9671, 0.9895, 0.9645, 0.9667, 0.9602, 0.9625, 0.9624, 0.9744,\n",
      "        0.9778, 0.9765, 0.9756, 0.9686, 0.9757, 0.9646, 0.9706, 0.9794, 0.9734,\n",
      "        0.9787, 0.9774, 0.9593, 0.9602, 0.9735, 0.9658, 0.9597, 0.9592, 0.9796,\n",
      "        0.9690, 0.9682, 0.9720, 0.9703, 0.9694, 0.9678, 0.9661, 0.9861, 0.9692,\n",
      "        0.9754, 0.9777, 0.9686, 0.9701, 0.9758, 0.9595, 0.9667, 0.9712, 0.9611,\n",
      "        0.9741, 0.9666, 0.9835, 0.9712, 0.9759, 0.9575, 0.9628, 0.9888, 0.9636,\n",
      "        0.9716, 0.9767, 0.9502, 0.9544, 0.9732, 0.9737, 0.9685, 0.9795, 1.0000,\n",
      "        0.9783, 0.9755, 0.9652, 0.9709, 0.9652, 0.9685, 0.9597, 0.9551, 0.9672,\n",
      "        0.9721, 0.9608, 0.9624, 0.9856, 0.9722, 0.9665, 0.9720, 0.9700, 0.9750,\n",
      "        0.9633, 0.9812, 0.9813, 0.9584, 0.9704, 0.9695, 0.9688, 0.9729, 0.9808,\n",
      "        0.9696, 0.9683, 0.9703, 0.9698, 0.9659, 0.9709, 0.9728, 0.9739, 0.9639,\n",
      "        0.9649, 0.9685, 0.9610, 0.9696, 0.9771, 0.9792, 0.9678, 0.9694, 0.9710,\n",
      "        0.9680, 0.9695, 0.9767, 0.9666, 0.9949, 0.9769, 0.9721, 0.9658, 0.9581,\n",
      "        0.9660, 0.9595, 0.9572, 0.9696, 0.9799, 0.9653, 0.9814, 0.9436, 0.9749,\n",
      "        0.9743, 0.9674, 0.9678, 0.9778, 0.9648, 0.9789, 0.9718, 1.0127, 0.9746,\n",
      "        0.9807, 0.9716, 0.9693, 0.9783, 0.9662, 0.9520, 0.9644, 0.9708, 0.9605,\n",
      "        0.9707, 0.9697, 0.9681, 0.9604, 0.9692, 0.9618, 0.9680, 0.9819, 0.9592,\n",
      "        0.9566, 0.9660, 0.9755, 0.9577, 0.9642, 0.9624, 0.9925, 0.9821, 0.9834,\n",
      "        0.9540, 0.9785, 0.9671, 0.9684, 0.9755, 0.9648, 0.9794, 0.9627, 0.9696,\n",
      "        0.9724, 0.9632, 0.9845, 0.9633, 0.9783, 0.9860, 0.9683, 0.9610, 0.9686,\n",
      "        0.9629, 0.9759, 0.9695, 0.9737, 0.9656, 0.9724, 0.9787, 0.9704, 0.9687,\n",
      "        0.9680, 0.9794, 0.9734, 0.9582, 0.9696, 0.9506, 0.9904, 0.9684, 0.9691,\n",
      "        0.9800, 0.9852, 0.9659, 0.9704, 0.9764, 0.9676, 0.9637, 0.9743, 0.9636,\n",
      "        0.9767, 0.9691, 0.9758, 0.9646, 0.9748, 0.9821, 0.9736, 0.9631, 0.9681,\n",
      "        0.9669, 0.9773, 0.9643, 0.9652, 0.9771, 0.9619, 0.9705, 0.9683, 0.9634,\n",
      "        0.9813, 0.9608, 0.9617, 0.9644, 0.9666, 0.9718, 0.9692, 0.9616, 0.9660,\n",
      "        0.9684, 0.9627, 0.9566, 0.9664, 0.9699, 0.9650, 0.9654, 0.9768, 0.9725,\n",
      "        1.0133, 0.9736, 0.9719, 0.9795])\n",
      "Pruned 6 filters\n",
      "tensor([0.9659, 0.9592, 1.0003, 0.9501, 0.9612, 0.9593, 0.9685, 0.9738, 0.9627,\n",
      "        0.9723, 0.9610, 0.9625, 0.9644, 0.9552, 1.0679, 0.9754, 0.9673, 0.9376,\n",
      "        0.9679, 1.0125, 0.9962, 0.9560, 0.9706, 0.9612, 0.9554, 0.9782, 0.9705,\n",
      "        0.9629, 0.9834, 0.9729, 0.9735, 0.9691, 0.9689, 0.9889, 0.9577, 0.9718,\n",
      "        0.9696, 0.9750, 0.9692, 0.9707, 0.9679, 0.9632, 0.9699, 0.9664, 0.9743,\n",
      "        0.9748, 0.9723, 0.9582, 0.9560, 0.9606, 1.0006, 0.9573, 0.9681, 0.9766,\n",
      "        0.9734, 0.9638, 0.9431, 0.9581, 0.9692, 0.9739, 0.9526, 0.9746, 0.9749,\n",
      "        0.9728, 0.9642, 0.9745, 0.9503, 0.9575, 0.9735, 0.9542, 0.9718, 0.9711,\n",
      "        0.9804, 0.9706, 0.9618, 0.9755, 0.9718, 0.9577, 0.9658, 0.9632, 0.9597,\n",
      "        0.9629, 0.9539, 0.9627, 0.9840, 0.9538, 0.9713, 0.9434, 0.9738, 0.9735,\n",
      "        0.9585, 0.9858, 0.9619, 0.9509, 0.9517, 0.9550, 0.9939, 0.9706, 0.9787,\n",
      "        0.9737, 0.9591, 0.9704, 0.9504, 0.9864, 0.9704, 0.9607, 0.9762, 0.9837,\n",
      "        0.9657, 0.9671, 0.9766, 0.9946, 0.9744, 0.9654, 0.9739, 0.9717, 0.9817,\n",
      "        0.9509, 0.9665, 0.9842, 0.9881, 0.9690, 0.9675, 0.9641, 0.9767, 0.9697,\n",
      "        0.9526, 1.0584, 0.9538, 0.9780, 0.9823, 0.9718, 0.9748, 0.9830, 0.9471,\n",
      "        0.9628, 0.9682, 0.9786, 0.9773, 0.9603, 0.9868, 0.9671, 0.9761, 0.9710,\n",
      "        0.9765, 0.9736, 0.9738, 0.9729, 0.9924, 0.9776, 0.9759, 0.9690, 0.9769,\n",
      "        0.9683, 0.9668, 0.9674, 0.9688, 0.9678, 0.9852, 0.9726, 0.9810, 0.9534,\n",
      "        0.9675, 0.9705, 0.9748, 0.9810, 0.9711, 0.9739, 0.9756, 0.9776, 0.9628,\n",
      "        0.9744, 0.9653, 0.9762, 0.9656, 0.9631, 0.9639, 0.9715, 0.9509, 0.9561,\n",
      "        0.9699, 0.9765, 0.9714, 0.9708, 0.9672, 0.9681, 0.9771, 0.9843, 0.9819,\n",
      "        0.9714, 0.9797, 0.9726, 0.9665, 0.9566, 0.9569, 0.9861, 0.9647, 0.9860,\n",
      "        0.9635, 0.9611, 0.9641, 0.9650, 0.9634, 0.9669, 0.9718, 0.9810, 0.9735,\n",
      "        0.9735, 0.9646, 0.9702, 0.9638, 0.9779, 0.9920, 0.9691, 0.9664, 0.9795,\n",
      "        0.9600, 0.9684, 0.9632, 0.9779, 0.9639, 0.9629, 0.9723, 0.9707, 0.9664,\n",
      "        0.9627, 0.9685, 0.9737, 0.9798, 0.9705, 0.9708, 0.9702, 0.9746, 0.9826,\n",
      "        0.9584, 0.9744, 0.9569, 0.9755, 0.9704, 0.9667, 0.9698, 0.9736, 0.9604,\n",
      "        0.9713, 0.9666, 0.9617, 0.9669, 0.9783, 0.9649, 0.9779, 0.9596, 0.9664,\n",
      "        0.9642, 0.9659, 0.9885, 0.9616])\n",
      "Pruned 4 filters\n",
      "tensor([0.9638, 0.9698, 0.9634, 0.9713, 0.9700, 0.9751, 0.9724, 0.9706, 0.9708,\n",
      "        0.9610, 0.9702, 0.9720, 0.9593, 0.9749, 0.9616, 0.9765, 1.0017, 0.9687,\n",
      "        0.9702, 0.9702, 0.9714, 0.9781, 0.9707, 0.9639, 0.9669, 0.9643, 0.9674,\n",
      "        0.9676, 0.9701, 0.9465, 0.9650, 0.9753, 0.9572, 0.9707, 0.9619, 0.9750,\n",
      "        0.9661, 0.9719, 0.9670, 0.9697, 0.9775, 0.9680, 0.9566, 0.9708, 0.9671,\n",
      "        0.9709, 0.9694, 0.9688, 0.9676, 0.9702, 0.9655, 0.9729, 0.9636, 0.9674,\n",
      "        0.9671, 0.9622, 0.9659, 0.9603, 0.9667, 0.9857, 0.9710, 0.9757, 0.9545,\n",
      "        0.9673, 0.9761, 0.9646, 0.9646, 0.9689, 0.9686, 0.9737, 0.9745, 0.9574,\n",
      "        0.9643, 0.9603, 0.9711, 0.9703, 0.9703, 0.9702, 0.9848, 0.9672, 0.9677,\n",
      "        0.9685, 0.9731, 0.9648, 0.9704, 0.9682, 0.9627, 0.9667, 0.9728, 0.9752,\n",
      "        0.9675, 0.9698, 0.9626, 0.9727, 0.9649, 0.9747, 0.9680, 0.9646, 0.9632,\n",
      "        0.9521, 0.9673, 0.9767, 0.9636, 0.9652, 0.9644, 0.9708, 0.9687, 0.9698,\n",
      "        0.9692, 0.9694, 0.9700, 0.9596, 0.9719, 0.9701, 0.9653, 0.9704, 0.9716,\n",
      "        0.9670, 0.9686, 0.9714, 0.9602, 0.9665, 0.9708, 0.9672, 0.9706, 0.9628,\n",
      "        0.9609, 0.9619, 0.9680, 0.9728, 0.9689, 0.9779, 0.9696, 0.9686, 0.9751,\n",
      "        0.9656, 0.9701, 0.9706, 0.9668, 0.9721, 0.9569, 0.9947, 0.9651, 0.9562,\n",
      "        0.9724, 0.9610, 0.9719, 0.9670, 0.9624, 0.9748, 0.9963, 0.9680, 0.9661,\n",
      "        0.9744, 0.9770, 0.9780, 0.9690, 0.9640, 0.9718, 0.9685, 0.9649, 0.9696,\n",
      "        0.9587, 0.9681, 0.9683, 0.9674, 0.9633, 0.9620, 0.9742, 0.9604, 0.9666,\n",
      "        0.9636, 0.9705, 0.9593, 0.9655, 0.9691, 0.9617, 0.9702, 0.9576, 0.9662,\n",
      "        0.9751, 0.9733, 0.9701, 0.9681, 0.9718, 0.9699, 0.9668, 0.9670, 0.9701,\n",
      "        0.9750, 0.9711, 0.9672, 0.9809, 0.9668, 0.9679, 0.9667, 0.9671, 0.9726,\n",
      "        0.9705, 0.9686, 0.9702, 0.9797, 0.9644, 0.9655, 0.9715, 0.9654, 0.9672,\n",
      "        0.9696, 0.9666, 0.9667, 0.9661, 0.9648, 0.9726, 0.9733, 0.9641, 0.9841,\n",
      "        0.9705, 0.9615, 0.9750, 0.9614, 0.9639, 0.9733, 0.9629, 0.9653, 0.9688,\n",
      "        0.9704, 0.9600, 0.9722, 0.9721, 0.9644, 0.9593, 0.9689, 0.9688, 0.9579,\n",
      "        0.9665, 0.9939, 0.9699, 0.9691, 0.9681, 0.9720, 0.9707, 0.9686, 0.9635,\n",
      "        0.9745, 0.9689, 0.9709, 0.9655, 0.9695, 0.9726, 0.9663, 0.9700, 0.9702,\n",
      "        0.9668, 0.9595, 0.9714, 0.9644, 0.9611, 0.9700, 0.9681, 0.9662, 0.9720,\n",
      "        0.9706, 0.9566, 0.9713, 0.9636, 0.9690, 0.9683, 0.9701, 0.9669, 0.9642,\n",
      "        0.9647, 0.9698, 0.9733, 0.9642, 0.9722, 0.9668, 0.9579, 0.9664, 0.9643,\n",
      "        0.9711, 0.9775, 0.9821, 0.9691, 0.9655, 0.9664, 0.9610, 0.9722, 0.9659,\n",
      "        0.9701, 0.9679, 0.9633, 0.9752, 0.9660, 0.9584, 0.9616, 0.9819, 0.9727,\n",
      "        0.9746, 0.9696, 0.9630, 0.9660, 0.9675, 0.9681, 0.9645, 1.0889, 0.9745,\n",
      "        0.9723, 0.9721, 0.9641, 0.9595, 0.9653, 0.9740, 0.9726, 0.9659, 0.9693,\n",
      "        0.9618, 0.9859, 0.9757, 0.9661, 0.9637, 0.9649, 0.9684, 0.9666, 0.9659,\n",
      "        0.9723, 0.9701, 0.9733, 0.9661, 0.9750, 0.9620, 0.9703, 0.9649, 0.9697,\n",
      "        0.9656, 0.9758, 0.9652, 0.9663, 0.9732, 0.9648, 0.9713, 0.9681, 0.9697,\n",
      "        0.9651, 0.9592, 0.9773, 0.9703, 0.9704, 0.9679, 0.9692, 0.9768, 0.9767,\n",
      "        0.9683, 0.9698, 0.9688, 0.9632, 0.9617, 0.9880, 0.9612, 0.9614, 0.9706,\n",
      "        0.9662, 0.9642, 0.9622, 0.9688, 0.9685, 0.9671, 0.9741, 0.9639, 0.9689,\n",
      "        0.9625, 0.9755, 0.9742, 0.9773, 0.9686, 0.9662, 0.9694, 0.9702, 0.9717,\n",
      "        0.9658, 0.9724, 0.9632, 0.9573, 0.9657, 0.9778, 0.9692, 0.9679, 0.9626,\n",
      "        0.9673, 0.9687, 0.9592, 0.9683, 0.9626, 0.9746, 0.9653, 0.9699, 0.9672,\n",
      "        0.9658, 0.9665, 0.9700, 0.9704, 0.9764, 0.9753, 0.9722, 0.9484, 0.9713,\n",
      "        0.9712, 0.9673, 0.9659, 0.9661, 0.9637, 0.9691, 0.9701, 0.9682, 0.9755,\n",
      "        0.9639, 0.9700, 0.9652, 0.9692, 0.9633, 0.9703, 0.9736, 0.9738, 0.9779,\n",
      "        0.9701, 0.9613, 1.0623, 0.9758, 0.9670, 0.9722, 0.9659, 0.9626, 0.9593,\n",
      "        0.9648, 0.9643, 0.9692, 0.9691, 0.9655, 0.9656, 0.9628, 0.9566, 0.9782,\n",
      "        0.9660, 0.9665, 0.9752, 0.9817, 0.9778, 0.9768, 0.9653, 0.9669, 0.9588,\n",
      "        0.9693, 0.9603, 0.9742, 0.9501, 0.9616, 0.9690, 0.9681, 0.9847, 0.9687,\n",
      "        0.9725, 0.9686, 0.9657, 0.9620, 0.9907, 0.9609, 0.9743, 0.9675, 0.9659,\n",
      "        0.9748, 0.9633, 0.9688, 0.9691, 0.9704, 0.9735, 0.9869, 0.9711, 0.9722,\n",
      "        0.9695, 0.9699, 0.9709, 0.9775, 0.9683, 0.9761, 0.9700, 0.9678, 0.9715,\n",
      "        0.9519, 0.9666, 0.9696, 0.9677, 0.9787, 0.9679, 0.9661, 0.9661, 0.9732,\n",
      "        0.9744, 0.9687, 0.9604, 0.9611, 0.9740, 0.9704, 0.9674, 0.9672, 0.9676,\n",
      "        0.9684, 0.9731, 0.9736, 0.9684, 0.9721, 0.9639, 0.9682, 0.9695])\n",
      "Pruned 2 filters\n",
      "tensor([0.9650, 0.9690, 0.9699, 0.9636, 0.9695, 0.9740, 0.9677, 0.9804, 0.9719,\n",
      "        0.9684, 0.9664, 0.9747, 0.9691, 0.9626, 0.9698, 0.9630, 0.9670, 0.9711,\n",
      "        0.9712, 0.9669, 0.9693, 0.9643, 0.9750, 0.9710, 0.9689, 0.9642, 0.9689,\n",
      "        0.9667, 0.9823, 0.9614, 0.9680, 0.9712, 0.9665, 0.9691, 0.9672, 0.9631,\n",
      "        0.9649, 0.9684, 0.9766, 0.9635, 0.9704, 0.9660, 0.9705, 0.9769, 0.9545,\n",
      "        0.9666, 0.9722, 0.9724, 0.9725, 0.9732, 0.9611, 0.9717, 0.9651, 0.9793,\n",
      "        0.9693, 0.9709, 0.9681, 0.9700, 0.9807, 0.9742, 0.9597, 0.9682, 0.9664,\n",
      "        0.9706, 0.9680, 0.9652, 0.9676, 0.9640, 0.9765, 0.9690, 0.9713, 0.9590,\n",
      "        0.9629, 0.9685, 0.9679, 0.9644, 0.9491, 0.9706, 0.9620, 0.9713, 0.9641,\n",
      "        0.9741, 0.9655, 0.9684, 0.9695, 0.9703, 0.9646, 0.9642, 0.9755, 0.9709,\n",
      "        0.9702, 0.9665, 0.9642, 0.9648, 0.9607, 0.9729, 0.9673, 0.9741, 0.9669,\n",
      "        0.9673, 0.9610, 0.9601, 0.9688, 0.9693, 0.9518, 0.9670, 0.9596, 0.9743,\n",
      "        0.9655, 0.9520, 0.9680, 0.9720, 0.9680, 0.9607, 0.9718, 0.9716, 0.9733,\n",
      "        0.9644, 0.9658, 0.9695, 0.9645, 0.9609, 0.9725, 0.9596, 0.9669, 0.9731,\n",
      "        0.9678, 0.9752, 0.9776, 0.9656, 0.9782, 0.9673, 0.9687, 0.9635, 0.9692,\n",
      "        0.9712, 0.9702, 0.9737, 0.9657, 0.9646, 0.9678, 0.9697, 0.9643, 0.9671,\n",
      "        0.9676, 0.9730, 0.9541, 0.9662, 0.9738, 0.9783, 0.9603, 0.9611, 0.9701,\n",
      "        0.9701, 0.9751, 0.9691, 0.9631, 0.9671, 0.9691, 0.9611, 0.9798, 0.9853,\n",
      "        0.9652, 0.9748, 0.9774, 0.9660, 0.9694, 0.9632, 0.9689, 0.9682, 0.9701,\n",
      "        0.9743, 0.9667, 0.9660, 0.9738, 0.9651, 0.9566, 0.9622, 0.9734, 0.9681,\n",
      "        0.9661, 0.9648, 0.9673, 0.9695, 0.9752, 0.9465, 0.9708, 0.9724, 0.9678,\n",
      "        0.9662, 0.9595, 0.9638, 0.9634, 0.9737, 0.9726, 0.9694, 0.9680, 0.9728,\n",
      "        0.9805, 0.9686, 0.9703, 0.9751, 0.9705, 0.9729, 0.9628, 0.9645, 0.9783,\n",
      "        0.9674, 0.9517, 0.9667, 0.9722, 0.9669, 0.9722, 0.9700, 0.9607, 0.9700,\n",
      "        0.9647, 0.9658, 0.9643, 0.9636, 0.9671, 0.9676, 0.9643, 0.9754, 1.0115,\n",
      "        0.9672, 0.9740, 0.9627, 0.9683, 0.9773, 0.9884, 0.9678, 0.9732, 0.9671,\n",
      "        0.9756, 0.9757, 0.9669, 0.9669, 0.9534, 0.9692, 0.9728, 0.9677, 0.9725,\n",
      "        0.9724, 0.9689, 0.9678, 0.9807, 0.9630, 0.9530, 0.9665, 0.9680, 0.9741,\n",
      "        0.9530, 0.9618, 0.9672, 0.9753, 0.9741, 0.9826, 0.9634, 0.9610, 0.9777,\n",
      "        0.9646, 0.9792, 0.9638, 0.9701, 0.9829, 0.9659, 0.9663, 0.9678, 0.9686,\n",
      "        0.9756, 0.9712, 0.9686, 0.9709, 0.9649, 0.9697, 0.9625, 0.9760, 0.9671,\n",
      "        0.9639, 0.9723, 0.9775, 0.9734, 0.9691, 0.9718, 0.9826, 0.9668, 0.9798,\n",
      "        0.9691, 0.9646, 0.9681, 0.9700, 0.9617, 0.9697, 0.9598, 0.9708, 0.9706,\n",
      "        0.9738, 0.9658, 0.9724, 0.9605, 0.9688, 0.9734, 0.9721, 0.9695, 0.9662,\n",
      "        0.9746, 0.9670, 0.9675, 0.9507, 0.9670, 0.9677, 0.9776, 0.9779, 0.9674,\n",
      "        0.9720, 0.9731, 0.9590, 0.9799, 0.9710, 0.9757, 0.9608, 0.9688, 0.9731,\n",
      "        0.9657, 0.9716, 0.9896, 0.9714, 0.9620, 0.9680, 0.9705, 0.9621, 0.9694,\n",
      "        0.9558, 0.9771, 0.9716, 0.9764, 0.9678, 0.9656, 0.9791, 0.9646, 0.9705,\n",
      "        0.9628, 0.9731, 0.9743, 0.9689, 0.9688, 0.9694, 0.9746, 0.9730, 0.9735,\n",
      "        0.9790, 0.9710, 0.9555, 0.9651, 0.9745, 0.9596, 0.9642, 0.9793, 0.9726,\n",
      "        0.9550, 0.9646, 0.9643, 0.9615, 0.9667, 0.9796, 0.9762, 0.9656, 0.9702,\n",
      "        0.9690, 0.9726, 0.9695, 0.9637, 0.9550, 0.9829, 0.9592, 0.9656, 0.9615,\n",
      "        0.9703, 0.9691, 0.9728, 0.9641, 0.9771, 0.9665, 0.9865, 0.9738, 0.9664,\n",
      "        0.9677, 0.9705, 0.9703, 0.9585, 0.9776, 0.9660, 0.9706, 0.9700, 0.9734,\n",
      "        0.9799, 0.9670, 0.9687, 0.9726, 0.9673, 0.9619, 0.9693, 0.9729, 0.9644,\n",
      "        0.9672, 0.9594, 0.9694, 0.9716, 0.9605, 0.9917, 0.9682, 0.9665, 0.9683,\n",
      "        0.9690, 0.9662, 0.9684, 0.9620, 0.9662, 0.9716, 0.9662, 0.9674, 0.9833,\n",
      "        0.9654, 0.9724, 0.9741, 0.9665, 0.9841, 0.9672, 0.9674, 0.9716, 0.9800,\n",
      "        0.9589, 0.9720, 0.9668, 0.9687, 0.9681, 0.9689, 0.9718, 0.9615, 0.9639,\n",
      "        0.9848, 0.9734, 0.9720, 0.9641, 0.9762, 0.9686, 0.9650, 0.9750, 0.9852,\n",
      "        0.9643, 0.9618, 0.9835, 0.9702, 1.0184, 0.9703, 0.9722, 0.9730, 0.9625,\n",
      "        0.9716, 0.9706, 0.9704, 0.9609, 0.9716, 0.9691, 0.9657, 0.9619, 0.9704,\n",
      "        0.9729, 0.9711, 0.9724, 0.9720, 0.9722, 0.9610, 0.9649, 0.9694, 0.9672,\n",
      "        0.9690, 0.9646, 0.9698, 0.9796, 0.9697, 0.9681, 0.9677, 0.9718, 0.9760,\n",
      "        0.9701, 0.9778, 0.9661, 0.9697, 0.9698, 0.9666, 0.9651, 0.9716, 0.9577,\n",
      "        0.9614, 0.9553, 0.9707, 0.9643, 0.9656, 0.9740, 0.9661, 0.9692, 0.9712,\n",
      "        0.9668, 0.9666, 0.9697, 0.9692, 0.9673, 0.9737, 0.9821, 0.9797])\n",
      "Pruned 6 filters\n",
      "tensor([0.9682, 0.9672, 0.9656, 0.9723, 0.9758, 0.9719, 0.9690, 0.9672, 0.9722,\n",
      "        0.9703, 0.9664, 0.9754, 0.9634, 0.9635, 0.9640, 0.9719, 0.9564, 0.9590,\n",
      "        0.9749, 0.9663, 0.9665, 0.9685, 0.9735, 0.9590, 0.9693, 0.9817, 0.9836,\n",
      "        0.9597, 0.9659, 0.9710, 0.9755, 0.9727, 0.9647, 0.9713, 0.9663, 0.9726,\n",
      "        0.9647, 0.9697, 0.9766, 0.9686, 0.9660, 0.9680, 0.9787, 0.9723, 0.9746,\n",
      "        0.9463, 0.9869, 0.9759, 0.9696, 0.9658, 0.9779, 0.9679, 0.9685, 0.9721,\n",
      "        0.9624, 0.9673, 0.9742, 0.9651, 0.9697, 0.9666, 0.9651, 0.9741, 0.9650,\n",
      "        0.9977, 0.9738, 0.9676, 0.9685, 0.9620, 0.9723, 0.9666, 0.9717, 0.9722,\n",
      "        0.9481, 0.9621, 0.9648, 0.9673, 0.9671, 0.9713, 0.9796, 0.9756, 0.9691,\n",
      "        0.9673, 0.9645, 0.9689, 0.9800, 0.9681, 0.9776, 0.9579, 0.9771, 0.9745,\n",
      "        0.9727, 0.9648, 0.9735, 0.9775, 0.9695, 0.9696, 0.9668, 0.9686, 0.9689,\n",
      "        0.9652, 0.9736, 0.9687, 0.9735, 0.9647, 0.9664, 0.9677, 0.9696, 0.9672,\n",
      "        0.9668, 0.9640, 0.9789, 0.9668, 0.9651, 0.9675, 0.9801, 0.9670, 0.9622,\n",
      "        0.9702, 0.9704, 0.9663, 0.9527, 0.9647, 0.9712, 0.9634, 0.9512, 0.9700,\n",
      "        0.9652, 0.9688, 0.9730, 0.9671, 0.9651, 0.9683, 0.9815, 0.9629, 0.9778,\n",
      "        0.9711, 0.9665, 0.9784, 0.9714, 0.9709, 0.9650, 0.9675, 0.9728, 0.9498,\n",
      "        0.9720, 0.9668, 0.9711, 0.9674, 0.9691, 0.9750, 0.9576, 0.9680, 0.9626,\n",
      "        0.9634, 0.9713, 0.9634, 0.9638, 0.9666, 0.9740, 0.9684, 0.9698, 0.9607,\n",
      "        0.9756, 0.9728, 0.9684, 0.9700, 0.9666, 0.9779, 0.9649, 0.9597, 0.9703,\n",
      "        0.9695, 0.9721, 0.9701, 0.9684, 0.9723, 0.9682, 0.9640, 0.9644, 0.9596,\n",
      "        0.9771, 0.9643, 0.9675, 0.9681, 0.9689, 0.9574, 0.9682, 0.9684, 0.9647,\n",
      "        0.9752, 0.9697, 0.9681, 0.9663, 0.9689, 0.9687, 0.9719, 0.9670, 0.9693,\n",
      "        0.9677, 0.9651, 0.9687, 0.9699, 0.9681, 0.9699, 0.9647, 0.9689, 0.9665,\n",
      "        0.9701, 0.9779, 0.9583, 0.9703, 0.9712, 0.9704, 0.9720, 0.9803, 0.9728,\n",
      "        0.9669, 0.9696, 0.9710, 0.9727, 0.9693, 0.9676, 0.9617, 0.9560, 0.9696,\n",
      "        0.9759, 0.9669, 0.9641, 0.9654, 0.9655, 0.9702, 0.9576, 0.9697, 0.9687,\n",
      "        0.9695, 0.9607, 0.9698, 0.9700, 0.9669, 0.9646, 1.0187, 0.9644, 0.9730,\n",
      "        0.9676, 0.9685, 0.9669, 0.9698, 0.9695, 0.9617, 0.9585, 0.9628, 0.9681,\n",
      "        0.9693, 0.9731, 0.9732, 0.9683, 0.9654, 0.9735, 0.9725, 0.9681, 0.9657,\n",
      "        0.9645, 0.9690, 0.9851, 0.9501, 0.9703, 0.9679, 0.9479, 0.9754, 0.9682,\n",
      "        0.9699, 0.9690, 0.9672, 0.9688, 0.9726, 0.9702, 0.9701, 0.9716, 0.9608,\n",
      "        0.9782, 0.9688, 0.9569, 0.9651, 0.9568, 0.9744, 0.9673, 0.9641, 0.9814,\n",
      "        0.9648, 0.9662, 0.9699, 0.9669, 0.9638, 0.9730, 0.9655, 0.9739, 0.9781,\n",
      "        0.9680, 0.9661, 0.9646, 0.9729, 0.9702, 0.9714, 0.9752, 0.9665, 0.9640,\n",
      "        0.9690, 0.9761, 0.9678, 0.9741, 0.9626, 0.9683, 0.9733, 0.9750, 0.9737,\n",
      "        0.9731, 0.9774, 0.9705, 0.9683, 0.9709, 0.9618, 0.9644, 0.9701, 0.9752,\n",
      "        0.9881, 0.9709, 0.9485, 0.9667, 0.9675, 0.9720, 0.9631, 0.9717, 0.9557,\n",
      "        0.9721, 0.9680, 0.9719, 0.9663, 0.9611, 0.9699, 0.9779, 0.9733, 0.9775,\n",
      "        0.9725, 0.9749, 0.9766, 0.9726, 0.9716, 0.9824, 0.9579, 0.9727, 0.9714,\n",
      "        0.9711, 0.9590, 0.9694, 0.9709, 0.9667, 0.9690, 0.9579, 0.9688, 0.9651,\n",
      "        0.9618, 0.9731, 0.9725, 0.9680, 0.9697, 0.9670, 0.9648, 0.9884, 0.9688,\n",
      "        0.9761, 0.9703, 0.9483, 0.9724, 0.9686, 0.9562, 0.9709, 0.9631, 0.9695,\n",
      "        0.9751, 0.9695, 0.9672, 0.9796, 0.9759, 0.9689, 0.9794, 0.9591, 0.9816,\n",
      "        0.9692, 0.9667, 0.9624, 0.9839, 0.9664, 0.9832, 0.9666, 0.9875, 0.9673,\n",
      "        0.9646, 0.9660, 0.9731, 0.9687, 0.9814, 0.9679, 0.9662, 0.9623, 0.9666,\n",
      "        0.9616, 0.9678, 0.9681, 0.9654, 0.9666, 0.9679, 0.9751, 0.9753, 0.9947,\n",
      "        0.9689, 0.9645, 0.9671, 0.9673, 0.9635, 0.9687, 0.9762, 0.9703, 0.9717,\n",
      "        0.9642, 0.9727, 0.9591, 0.9573, 0.9759, 0.9511, 0.9688, 0.9699, 0.9665,\n",
      "        0.9732, 0.9650, 0.9659, 0.9545, 0.9650, 0.9694, 0.9717, 0.9672, 0.9673,\n",
      "        0.9637, 0.9680, 0.9677, 0.9558, 0.9674, 0.9746, 0.9720, 0.9872, 0.9705,\n",
      "        0.9688, 0.9672, 0.9744, 0.9801, 0.9627, 0.9748, 0.9693, 0.9741, 0.9740,\n",
      "        0.9791, 0.9730, 0.9657, 0.9792, 0.9680, 0.9644, 0.9707, 0.9750, 0.9719,\n",
      "        0.9700, 0.9517, 0.9679, 0.9697, 0.9725, 0.9661, 0.9674, 0.9696, 0.9745,\n",
      "        0.9681, 0.9686, 0.9704, 0.9697, 0.9596, 0.9788, 0.9703, 0.9648, 0.9548,\n",
      "        0.9673, 0.9666, 0.9725, 0.9625, 0.9726, 0.9965, 0.9726, 0.9746, 0.9716,\n",
      "        0.9674, 0.9684, 0.9709, 0.9673, 0.9711, 0.9699, 0.9820, 0.9715, 0.9687,\n",
      "        0.9671, 0.9741, 0.9708, 0.9663, 0.9762, 0.9698, 0.9695, 0.9625])\n",
      "Pruned 9 filters\n",
      "tensor([0.9677, 0.9743, 0.9676, 0.9755, 0.9721, 0.9619, 0.9692, 0.9630, 0.9748,\n",
      "        0.9796, 0.9683, 0.9682, 0.9664, 0.9645, 0.9667, 0.9422, 0.9755, 0.9679,\n",
      "        0.9762, 0.9609, 0.9761, 0.9694, 0.9696, 0.9652, 0.9891, 0.9841, 0.9729,\n",
      "        0.9670, 0.9658, 0.9650, 0.9702, 0.9721, 0.9678, 0.9648, 0.9650, 0.9664,\n",
      "        0.9689, 0.9674, 0.9729, 0.9665, 0.9711, 0.9714, 0.9804, 0.9695, 0.9578,\n",
      "        0.9688, 0.9670, 0.9668, 0.9615, 0.9639, 0.9689, 0.9709, 0.9758, 0.9724,\n",
      "        0.9684, 0.9639, 0.9738, 0.9661, 0.9701, 0.9795, 0.9567, 0.9791, 0.9729,\n",
      "        0.9650, 0.9650, 0.9633, 0.9787, 0.9659, 0.9702, 0.9662, 0.9679, 0.9725,\n",
      "        0.9654, 0.9712, 0.9913, 0.9673, 0.9698, 0.9723, 0.9664, 0.9652, 0.9807,\n",
      "        0.9700, 0.9688, 0.9657, 0.9708, 0.9667, 0.9817, 0.9659, 0.9721, 0.9628,\n",
      "        0.9713, 0.9653, 0.9753, 0.9664, 0.9654, 0.9622, 0.9654, 0.9648, 0.9697,\n",
      "        0.9558, 0.9711, 0.9760, 0.9654, 0.9649, 0.9789, 0.9686, 0.9672, 0.9675,\n",
      "        0.9634, 0.9671, 0.9826, 0.9748, 0.9980, 0.9673, 0.9720, 0.9721, 0.9759,\n",
      "        0.9773, 0.9556, 0.9692, 0.9864, 0.9690, 0.9729, 0.9648, 0.9700, 0.9678,\n",
      "        0.9677, 0.9701, 0.9763, 0.9647, 0.9708, 0.9655, 0.9728, 0.9783, 0.9789,\n",
      "        0.9675, 0.9702, 0.9717, 0.9690, 0.9682, 0.9648, 0.9669, 0.9737, 0.9748,\n",
      "        0.9800, 0.9717, 0.9804, 0.9725, 0.9748, 0.9646, 0.9587, 0.9663, 0.9705,\n",
      "        0.9670, 0.9664, 0.9675, 0.9689, 0.9704, 0.9629, 0.9637, 0.9626, 0.9657,\n",
      "        0.9725, 0.9714, 0.9848, 0.9600, 0.9840, 0.9680, 0.9674, 0.9685, 0.9642,\n",
      "        0.9698, 0.9727, 0.9819, 0.9671, 0.9715, 0.9708, 0.9697, 0.9671, 0.9690,\n",
      "        0.9905, 0.9652, 0.9697, 0.9695, 0.9680, 0.9709, 0.9767, 0.9681, 0.9810,\n",
      "        0.9661, 0.9735, 0.9507, 0.9618, 0.9628, 0.9787, 0.9708, 0.9657, 0.9547,\n",
      "        0.9725, 0.9683, 0.9673, 0.9703, 0.9738, 0.9707, 0.9713, 0.9595, 0.9655,\n",
      "        0.9784, 0.9709, 0.9682, 0.9627, 0.9657, 0.9538, 0.9666, 0.9684, 0.9688,\n",
      "        0.9898, 0.9631, 0.9694, 0.9685, 0.9775, 0.9748, 0.9735, 0.9688, 0.9740,\n",
      "        0.9697, 0.9670, 0.9697, 0.9706, 0.9721, 0.9662, 0.9661, 0.9779, 0.9738,\n",
      "        0.9609, 0.9698, 0.9678, 0.9747, 0.9675, 0.9787, 0.9663, 0.9829, 0.9686,\n",
      "        0.9702, 0.9617, 0.9682, 0.9728, 0.9677, 0.9699, 0.9744, 0.9686, 0.9686,\n",
      "        0.9751, 0.9613, 0.9667, 0.9723, 0.9694, 0.9664, 0.9807, 0.9452, 0.9716,\n",
      "        0.9745, 0.9613, 0.9508, 0.9705, 0.9681, 0.9661, 0.9706, 1.0504, 0.9684,\n",
      "        0.9741, 0.9657, 0.9758, 0.9771, 0.9676, 0.9742, 0.9677, 0.9798, 0.9793,\n",
      "        0.9721, 0.9594, 0.9778, 0.9755, 0.9675, 0.9715, 0.9817, 0.9711, 0.9539,\n",
      "        0.9560, 0.9633, 0.9615, 0.9659, 0.9734, 0.9537, 0.9733, 0.9597, 0.9685,\n",
      "        0.9628, 0.9684, 0.9652, 0.9208, 0.9662, 0.9721, 0.9678, 0.9674, 0.9754,\n",
      "        0.9705, 0.9805, 0.9706, 0.9716, 0.9674, 0.9711, 0.9644, 0.9693, 0.9744,\n",
      "        0.9673, 0.9753, 0.9694, 0.8754, 0.9656, 0.9683, 0.9750, 0.9694, 0.9696,\n",
      "        0.9805, 0.9320, 0.9638, 0.9954, 0.9677, 0.9774, 0.9798, 0.9739, 0.9722,\n",
      "        0.9670, 0.9724, 0.9674, 0.9660, 0.9681, 0.9626, 0.9653, 0.9649, 0.9656,\n",
      "        0.9688, 0.9642, 0.9659, 0.9462, 0.9770, 0.9677, 0.9570, 0.9652, 0.9768,\n",
      "        0.9692, 0.9720, 0.9681, 0.9724, 0.9648, 0.9711, 0.9778, 0.9679, 0.9642,\n",
      "        0.9616, 0.9685, 0.9653, 0.9664, 0.9660, 0.9666, 0.9765, 0.9657, 0.9489,\n",
      "        0.9705, 0.9668, 0.9709, 0.9675, 0.9691, 0.9661, 0.9722, 0.9685, 0.9693,\n",
      "        0.9766, 0.9681, 0.9677, 0.9689, 0.9707, 0.9751, 0.9670, 0.9419, 0.9713,\n",
      "        0.9670, 0.9683, 0.9661, 0.9732, 0.9676, 0.9684, 0.9719, 0.9670, 0.9669,\n",
      "        0.9671, 0.9706, 0.9765, 0.9680, 0.9639, 0.9687, 0.9675, 0.9691, 0.9704,\n",
      "        0.9729, 0.9687, 0.9562, 0.9728, 0.9703, 0.9676, 0.9708, 0.9734, 0.9736,\n",
      "        0.9701, 0.9780, 0.9699, 0.9692, 0.9539, 0.9725, 0.9610, 0.9749, 0.9687,\n",
      "        0.9688, 0.9736, 0.9604, 0.9672, 0.9720, 0.9737, 0.9678, 0.9780, 0.9677,\n",
      "        0.9668, 0.9738, 0.9726, 0.9580, 0.9675, 0.9625, 0.9668, 0.9739, 0.9818,\n",
      "        0.9660, 0.9632, 0.9638, 0.9677, 0.9651, 0.9645, 0.9684, 0.9879, 0.9665,\n",
      "        0.9671, 0.9621, 0.9777, 0.9722, 0.9682, 0.9667, 0.9732, 0.9679, 0.9830,\n",
      "        0.9616, 0.9702, 0.9639, 0.9720, 0.9692, 0.9715, 0.9715, 0.9788, 0.9655,\n",
      "        0.9691, 0.9503, 0.9709, 0.9626, 0.9751, 0.9656, 0.9700, 0.9662, 0.9633,\n",
      "        0.9724, 0.9875, 0.9666, 0.9736, 0.9687, 0.9669, 0.9664, 0.9561, 0.9747,\n",
      "        0.9664, 0.9799, 0.9728, 0.9699, 0.9690, 0.9785, 0.9729, 0.9694, 0.9736,\n",
      "        0.9629, 0.9655, 0.9714, 0.9708, 0.9930, 0.9684, 0.9724, 0.9633, 0.9714,\n",
      "        0.9680, 0.9548, 0.9698, 0.9605, 0.9684, 0.9687, 0.9701, 0.9614])\n",
      "Pruned 9 filters\n",
      "tensor([0.9686, 0.9666, 0.9763, 0.9670, 0.9663, 0.9800, 0.9689, 0.9685, 0.9687,\n",
      "        0.9691, 0.9678, 0.9722, 0.9674, 0.9694, 0.9674, 0.9716, 0.9698, 0.9752,\n",
      "        0.9695, 0.9681, 0.9660, 0.9676, 0.9844, 0.9587, 0.9682, 0.9676, 0.9738,\n",
      "        0.9117, 0.9726, 0.9696, 0.9598, 0.9646, 0.9674, 0.9675, 0.9726, 0.9706,\n",
      "        0.9671, 0.9726, 0.9727, 0.9762, 0.9706, 0.9709, 0.9710, 0.9696, 0.9676,\n",
      "        0.9699, 0.9676, 0.9771, 0.9745, 0.9623, 0.9692, 0.9713, 0.9789, 0.9688,\n",
      "        0.9677, 0.9751, 0.9677, 0.9660, 0.9702, 0.9689, 0.9712, 0.9693, 0.9741,\n",
      "        0.9740, 0.9690, 0.9612, 0.9630, 0.9764, 0.9686, 0.9718, 0.9753, 0.9737,\n",
      "        0.9694, 0.9710, 0.9648, 0.9698, 0.9589, 0.9693, 0.9614, 0.9729, 0.9715,\n",
      "        0.9728, 0.9685, 0.9696, 0.9705, 0.9616, 0.9701, 0.9731, 0.9691, 0.9668,\n",
      "        0.9696, 0.9691, 0.9732, 0.9735, 0.9653, 0.9761, 0.9689, 0.9594, 0.9673,\n",
      "        0.9737, 0.9723, 0.9651, 0.9697, 0.9650, 0.9698, 0.9695, 0.9662, 0.9684,\n",
      "        0.9685, 0.9631, 0.9690, 0.9683, 0.9672, 0.9690, 0.9689, 0.9633, 0.9708,\n",
      "        0.9723, 0.9692, 0.9689, 0.9738, 0.9629, 0.9745, 0.9727, 0.9758, 0.9714,\n",
      "        0.9726, 0.9711, 0.9243, 0.9742, 0.9682, 0.9703, 0.9629, 0.9703, 0.9653,\n",
      "        0.9761, 0.9720, 0.9693, 0.9629, 0.9721, 0.9510, 0.9668, 0.9697, 0.9671,\n",
      "        0.9687, 0.9693, 0.9513, 0.9750, 0.9761, 0.9705, 0.9696, 0.9690, 0.9694,\n",
      "        0.9852, 0.9672, 0.9752, 0.9679, 0.9684, 0.9249, 0.9672, 0.9680, 0.9662,\n",
      "        0.9701, 0.9713, 0.9656, 0.9703, 0.9722, 0.9684, 0.9715, 0.9702, 0.9448,\n",
      "        0.9702, 0.9774, 0.9695, 0.9670, 0.9605, 0.9741, 0.9694, 0.9687, 0.9747,\n",
      "        0.9735, 0.9793, 0.9769, 0.9696, 0.9656, 0.9687, 0.9688, 0.9687, 0.9684,\n",
      "        0.9692, 0.9687, 0.9730, 0.9645, 0.9770, 0.9721, 0.9681, 0.9740, 0.9637,\n",
      "        0.9649, 0.9833, 0.9725, 0.9679, 0.9652, 0.9625, 0.9720, 0.9725, 0.9807,\n",
      "        0.9815, 0.9759, 0.9707, 0.9627, 0.9673, 0.9682, 0.9690, 0.9690, 0.9720,\n",
      "        0.9682, 0.9553, 0.9634, 0.9668, 0.9674, 0.9670, 0.9737, 0.9728, 0.9655,\n",
      "        0.9709, 0.9715, 0.9709, 0.9716, 0.9714, 0.9672, 0.9718, 0.9744, 0.9767,\n",
      "        0.9717, 0.9711, 0.9731, 0.9731, 0.9710, 0.9688, 0.9627, 0.9624, 0.9712,\n",
      "        0.9678, 0.9763, 0.9713, 0.9713, 0.9651, 0.9632, 0.9697, 0.9702, 0.9687,\n",
      "        0.9644, 0.9698, 0.9764, 0.9700, 0.9740, 0.9606, 0.9707, 0.9725, 0.9775,\n",
      "        0.9689, 0.9657, 0.9694, 0.9546, 0.9687, 0.9741, 0.9708, 0.9681, 0.9736,\n",
      "        0.9611, 0.9524, 0.9735, 0.9701, 0.9650, 0.9710, 0.9699, 0.9692, 0.9667,\n",
      "        0.9742, 0.9704, 0.9745, 0.9728, 0.9715, 0.9710, 0.9643, 0.9685, 0.9714,\n",
      "        0.9657, 0.9731, 0.9731, 0.9678, 0.9720, 0.9745, 0.9659, 0.9702, 0.9726,\n",
      "        0.9716, 0.9777, 0.9716, 0.9816, 0.9682, 0.9847, 0.9698, 0.9662, 0.9733,\n",
      "        0.9682, 0.9696, 0.9728, 0.9695, 0.9671, 0.9685, 0.9707, 0.9716, 0.9691,\n",
      "        0.9615, 0.9718, 0.9688, 0.9753, 0.9700, 0.9744, 0.9812, 0.9683, 0.9744,\n",
      "        0.9728, 0.9729, 0.9659, 0.9857, 0.9137, 0.9797, 0.9662, 0.9683, 0.9758,\n",
      "        0.9710, 0.9634, 0.9689, 0.9644, 0.9677, 0.9686, 0.9616, 0.9743, 0.9737,\n",
      "        0.9761, 0.9607, 0.9770, 0.9743, 0.9694, 0.9805, 0.9728, 0.9775, 0.9709,\n",
      "        0.9625, 0.9697, 0.9601, 0.9640, 0.9695, 0.9770, 0.9668, 0.9695, 0.9713,\n",
      "        0.9604, 0.9691, 0.9641, 0.9682, 0.9694, 0.9840, 0.9714, 0.9793, 0.9411,\n",
      "        0.9677, 0.9659, 0.9727, 0.9673, 0.9687, 0.9759, 0.9672, 0.9680, 0.9691,\n",
      "        0.9806, 0.9681, 0.9653, 0.9132, 0.9679, 0.9659, 0.9677, 0.9716, 0.9736,\n",
      "        0.9653, 0.9728, 0.9770, 0.9673, 0.9698, 0.9676, 0.9812, 0.9710, 0.9696,\n",
      "        0.9848, 0.9760, 0.9768, 0.9845, 0.9714, 0.9693, 0.9751, 0.9702, 0.9701,\n",
      "        0.9665, 0.9708, 0.9701, 0.9741, 0.9760, 0.9754, 0.9691, 0.9698, 0.9750,\n",
      "        0.9779, 0.9665, 0.9748, 0.9696, 0.9704, 0.9629, 0.9750, 0.9735, 0.9663,\n",
      "        0.9707, 0.9648, 0.9735, 0.9732, 0.9764, 0.9668, 0.9673, 0.9752, 0.9742,\n",
      "        0.9732, 0.9656, 0.9642, 0.9705, 0.9699, 0.9712, 0.9673, 0.9568, 0.9718,\n",
      "        0.9726, 0.9687, 0.9618, 0.9704, 0.9477, 0.9544, 0.9757, 0.9462, 0.9910,\n",
      "        0.9743, 0.9699, 0.9740, 0.9695, 0.9666, 0.9781, 0.9527, 0.9697, 0.9647,\n",
      "        0.9711, 0.9704, 0.9761, 0.9739, 0.9669, 0.9742, 0.9656, 0.9734, 0.9695,\n",
      "        0.9662, 0.9680, 0.9706, 0.9714, 0.9755, 0.9698, 0.9701, 0.9702, 0.9671,\n",
      "        0.9741, 0.9728, 0.9701, 0.9680, 0.9706, 0.9726, 0.9727, 0.9671, 0.9686,\n",
      "        0.9671, 0.9681, 0.9739, 0.9642, 0.9665, 0.9684, 0.9710, 0.9723, 0.9617,\n",
      "        0.9761, 0.9691, 0.9748, 0.9700, 0.9806, 0.9739, 0.9642, 0.9678, 0.9655,\n",
      "        0.9613, 0.9718, 0.9669, 0.9736, 0.9692, 0.9812, 0.9754, 0.9512])\n",
      "Pruned 12 filters\n",
      "tensor([0.9718, 0.9696, 0.9727, 0.9688, 0.9692, 0.9758, 0.9694, 0.9620, 0.9737,\n",
      "        0.9696, 0.9710, 0.9680, 0.9755, 0.9737, 0.9722, 0.9701, 0.9623, 0.9711,\n",
      "        0.9721, 0.9753, 0.9700, 0.9721, 0.9677, 0.9677, 0.9729, 0.9675, 0.9805,\n",
      "        0.9757, 0.9674, 0.9698, 0.9714, 0.9692, 0.9699, 0.9701, 0.9677, 0.9687,\n",
      "        0.9706, 0.9710, 0.9704, 0.9740, 0.9683, 0.9724, 0.9730, 0.9700, 0.9752,\n",
      "        0.9688, 0.9602, 0.9694, 0.9679, 0.9684, 0.9715, 0.9745, 0.9665, 0.9724,\n",
      "        0.9683, 0.9708, 0.9699, 0.9689, 0.9680, 0.9468, 0.9711, 0.9713, 0.9674,\n",
      "        0.9688, 0.9734, 0.9735, 0.9736, 0.9682, 0.9692, 0.9712, 0.9697, 0.9704,\n",
      "        0.9699, 0.9740, 0.9699, 0.9693, 0.9733, 0.9696, 0.9687, 0.9738, 0.9697,\n",
      "        0.9687, 0.9741, 0.9677, 0.9683, 0.9720, 0.9649, 0.9706, 0.9700, 0.9690,\n",
      "        0.9676, 0.9690, 0.9673, 0.9754, 0.9690, 0.9678, 0.9727, 0.9724, 0.9725,\n",
      "        0.9755, 0.9714, 0.9654, 0.9431, 0.9710, 0.9710, 0.9721, 0.9708, 0.9678,\n",
      "        0.9669, 0.9727, 0.9690, 0.9722, 0.9606, 0.9679, 0.9708, 0.9480, 0.9777,\n",
      "        0.9738, 0.9682, 0.9745, 0.9698, 0.9804, 0.9687, 0.9687, 0.9685, 0.9731,\n",
      "        0.9791, 0.9698, 0.9744, 0.9715, 0.9688, 0.9693, 0.9699, 0.9712, 0.9798,\n",
      "        0.9725, 0.9687, 0.9468, 0.9691, 0.9694, 0.9660, 0.9726, 0.9679, 0.9698,\n",
      "        0.9684, 0.9669, 0.9733, 0.9669, 0.9735, 0.9710, 0.9688, 0.9694, 0.9683,\n",
      "        0.9715, 0.9684, 0.9698, 0.9677, 0.9728, 0.9762, 0.9679, 0.9735, 0.9689,\n",
      "        0.9710, 0.9526, 0.9698, 0.9681, 0.9669, 0.9701, 0.9685, 0.9693, 0.9705,\n",
      "        0.9724, 0.9721, 0.9730, 0.9716, 0.9675, 0.9647, 0.9681, 0.9666, 0.9722,\n",
      "        0.9699, 0.9697, 0.9704, 0.9702, 0.9713, 0.9778, 0.9699, 0.9748, 0.9721,\n",
      "        0.9693, 0.9656, 0.9686, 0.9683, 0.9701, 0.9750, 0.9675, 0.9690, 0.9684,\n",
      "        0.9671, 0.9727, 0.9728, 0.9710, 0.9687, 0.9683, 0.9730, 0.9677, 0.9953,\n",
      "        0.9682, 0.9688, 0.9811, 0.9740, 0.9680, 0.9760, 0.9685, 0.9683, 0.9681,\n",
      "        0.9826, 0.9733, 0.9820, 0.9692, 0.9707, 0.9694, 0.9720, 0.9740, 0.9694,\n",
      "        0.9707, 0.9362, 0.9689, 0.9702, 0.9690, 0.9771, 0.9735, 0.9721, 0.9680,\n",
      "        0.9691, 0.9684, 0.9670, 0.9812, 0.9727, 0.9683, 0.9741, 0.9689, 0.9595,\n",
      "        0.9705, 0.9692, 0.9572, 0.9746, 0.9700, 0.9853, 0.9695, 0.9675, 0.9691,\n",
      "        0.9742, 0.9686, 0.9693, 0.9718, 0.9680, 0.9709, 0.9642, 0.9678, 0.9412,\n",
      "        0.9689, 0.9695, 0.9707, 0.9703, 0.9679, 0.9698, 0.9735, 0.9695, 0.9705,\n",
      "        0.9700, 0.9683, 0.9746, 0.9694, 0.9693, 0.9678, 0.9709, 0.9685, 0.9711,\n",
      "        0.9698, 0.9693, 0.9769, 0.9757, 0.9687, 0.9682, 0.9696, 0.9688, 0.9689,\n",
      "        0.9703, 0.9686, 0.9816, 0.9739, 0.9677, 0.9750, 0.9692, 0.9711, 0.9702,\n",
      "        0.9728, 0.9718, 0.9426, 0.9709, 0.9736, 0.9694, 0.9708, 0.9683, 0.9684,\n",
      "        0.9726, 0.9669, 0.9688, 0.9689, 0.9704, 0.9364, 0.9683, 0.9688, 0.9736,\n",
      "        0.9741, 0.9694, 0.9741, 0.9700, 0.9701, 0.9694, 0.9576, 0.9699, 0.9713,\n",
      "        0.9695, 0.9682, 0.9724, 0.9710, 0.9711, 0.9700, 0.9684, 0.8443, 0.9882,\n",
      "        0.9702, 0.9771, 0.9706, 0.9682, 0.9674, 0.9697, 0.9692, 0.9680, 0.9590,\n",
      "        0.9695, 0.9676, 0.9701, 0.9678, 0.9696, 0.9721, 0.9689, 0.9699, 0.9679,\n",
      "        0.9691, 0.9689, 0.9714, 0.9677, 0.9687, 0.9714, 0.9697, 0.9709, 0.9652,\n",
      "        0.9534, 0.9677, 0.9710, 0.9703, 0.9684, 0.9737, 0.9703, 0.9677, 0.9752,\n",
      "        0.9687, 0.9708, 0.9677, 0.9707, 0.9699, 0.9680, 0.9687, 0.9660, 0.9633,\n",
      "        0.9680, 0.9696, 0.9700, 0.9688, 0.9715, 0.9707, 0.9679, 0.9696, 0.9692,\n",
      "        0.9379, 0.9686, 0.9700, 0.9692, 0.9755, 0.9782, 0.9679, 0.9722, 0.9694,\n",
      "        0.9697, 0.9694, 0.9688, 0.9741, 0.9684, 0.9692, 0.9710, 0.9715, 0.9686,\n",
      "        0.9686, 0.9690, 0.9707, 0.9691, 0.9688, 0.9697, 0.9679, 0.9687, 0.9817,\n",
      "        0.9717, 0.9798, 0.9403, 0.9704, 0.9682, 0.9641, 0.9689, 0.9733, 0.9655,\n",
      "        0.9680, 0.9679, 0.9689, 0.9688, 0.9691, 0.9684, 0.9691, 0.9684, 0.9767,\n",
      "        0.9707, 0.9719, 0.9681, 0.9688, 0.9686, 0.9715, 0.9706, 0.9707, 0.9736,\n",
      "        0.9620, 0.9690, 0.9732, 0.9745, 0.9718, 0.9748, 0.9691, 0.9676, 0.9721,\n",
      "        0.9769, 0.9813, 0.9696, 0.9682, 0.9716, 0.9574, 0.9692, 0.9828, 0.9685,\n",
      "        0.9709, 0.9677, 0.9714, 0.9732, 0.9690, 0.9650, 0.9701, 0.9718, 0.9696,\n",
      "        0.9743, 0.9685, 0.9703, 0.9691, 0.9759, 0.9688, 0.9698, 0.9690, 0.9680,\n",
      "        0.9684, 0.9746, 0.9745, 0.9679, 0.9722, 0.9709, 0.9696, 0.9683, 0.9751,\n",
      "        0.9684, 0.9698, 0.9686, 0.9725, 0.9845, 0.9696, 0.9678, 0.9706, 0.9714,\n",
      "        0.9690, 0.9710, 0.9324, 0.9699, 0.9696, 0.9682, 0.9629, 0.9686, 0.9687,\n",
      "        0.9694, 0.9737, 0.9705, 0.9697, 0.9683, 0.9752, 0.9716, 0.9728])\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 2.3262 Acc: 0.4316 Balanced Acc: 0.4316\n",
      "val Loss: 2.4903 Acc: 0.3982 Balanced Acc: 0.4012\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.9910 Acc: 0.4930 Balanced Acc: 0.4930\n",
      "val Loss: 2.3954 Acc: 0.4151 Balanced Acc: 0.4181\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.8481 Acc: 0.5239 Balanced Acc: 0.5238\n",
      "val Loss: 2.4226 Acc: 0.4084 Balanced Acc: 0.4111\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.7727 Acc: 0.5415 Balanced Acc: 0.5415\n",
      "val Loss: 2.3062 Acc: 0.4317 Balanced Acc: 0.4356\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.7086 Acc: 0.5559 Balanced Acc: 0.5559\n",
      "val Loss: 2.2945 Acc: 0.4287 Balanced Acc: 0.4331\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.6748 Acc: 0.5642 Balanced Acc: 0.5643\n",
      "val Loss: 2.3055 Acc: 0.4246 Balanced Acc: 0.4289\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.6225 Acc: 0.5827 Balanced Acc: 0.5827\n",
      "val Loss: 2.3227 Acc: 0.4289 Balanced Acc: 0.4332\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.6097 Acc: 0.5888 Balanced Acc: 0.5888\n",
      "val Loss: 2.2667 Acc: 0.4356 Balanced Acc: 0.4402\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.5276 Acc: 0.6089 Balanced Acc: 0.6089\n",
      "val Loss: 2.3098 Acc: 0.4336 Balanced Acc: 0.4370\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.4978 Acc: 0.6195 Balanced Acc: 0.6195\n",
      "val Loss: 2.2937 Acc: 0.4422 Balanced Acc: 0.4453\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.4984 Acc: 0.6134 Balanced Acc: 0.6134\n",
      "val Loss: 2.2314 Acc: 0.4551 Balanced Acc: 0.4582\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.4485 Acc: 0.6291 Balanced Acc: 0.6291\n",
      "val Loss: 2.2240 Acc: 0.4486 Balanced Acc: 0.4520\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.4829 Acc: 0.6181 Balanced Acc: 0.6181\n",
      "val Loss: 2.2565 Acc: 0.4477 Balanced Acc: 0.4519\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.4829 Acc: 0.6196 Balanced Acc: 0.6196\n",
      "val Loss: 2.2315 Acc: 0.4475 Balanced Acc: 0.4521\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.4297 Acc: 0.6366 Balanced Acc: 0.6366\n",
      "val Loss: 2.1885 Acc: 0.4544 Balanced Acc: 0.4593\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.4245 Acc: 0.6301 Balanced Acc: 0.6301\n",
      "val Loss: 2.2346 Acc: 0.4487 Balanced Acc: 0.4524\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.3880 Acc: 0.6461 Balanced Acc: 0.6461\n",
      "val Loss: 2.1908 Acc: 0.4562 Balanced Acc: 0.4604\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.4261 Acc: 0.6310 Balanced Acc: 0.6310\n",
      "val Loss: 2.2090 Acc: 0.4524 Balanced Acc: 0.4565\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.3902 Acc: 0.6423 Balanced Acc: 0.6424\n",
      "val Loss: 2.1868 Acc: 0.4551 Balanced Acc: 0.4595\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.3484 Acc: 0.6567 Balanced Acc: 0.6567\n",
      "val Loss: 2.1953 Acc: 0.4575 Balanced Acc: 0.4597\n",
      "\n",
      "Training complete in 90m 39s\n",
      "Best val Balanced Acc: 0.460413\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.2876 Acc: 0.6645 Balanced Acc: 0.6645\n",
      "val Loss: 2.2142 Acc: 0.4663 Balanced Acc: 0.4688\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.2511 Acc: 0.6652 Balanced Acc: 0.6651\n",
      "val Loss: 2.2374 Acc: 0.4589 Balanced Acc: 0.4623\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.2502 Acc: 0.6717 Balanced Acc: 0.6717\n",
      "val Loss: 2.1513 Acc: 0.4746 Balanced Acc: 0.4778\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.2457 Acc: 0.6795 Balanced Acc: 0.6795\n",
      "val Loss: 2.1911 Acc: 0.4629 Balanced Acc: 0.4653\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.1893 Acc: 0.6907 Balanced Acc: 0.6906\n",
      "val Loss: 2.1611 Acc: 0.4688 Balanced Acc: 0.4706\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.2015 Acc: 0.6889 Balanced Acc: 0.6888\n",
      "val Loss: 2.1865 Acc: 0.4663 Balanced Acc: 0.4695\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.2074 Acc: 0.6862 Balanced Acc: 0.6861\n",
      "val Loss: 2.1762 Acc: 0.4689 Balanced Acc: 0.4733\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.1758 Acc: 0.6942 Balanced Acc: 0.6941\n",
      "val Loss: 2.1351 Acc: 0.4745 Balanced Acc: 0.4786\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.1451 Acc: 0.7047 Balanced Acc: 0.7047\n",
      "val Loss: 2.1226 Acc: 0.4798 Balanced Acc: 0.4827\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.1435 Acc: 0.7020 Balanced Acc: 0.7021\n",
      "val Loss: 2.1555 Acc: 0.4732 Balanced Acc: 0.4767\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.1926 Acc: 0.6979 Balanced Acc: 0.6979\n",
      "val Loss: 2.1348 Acc: 0.4776 Balanced Acc: 0.4809\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.1784 Acc: 0.6937 Balanced Acc: 0.6937\n",
      "val Loss: 2.1297 Acc: 0.4753 Balanced Acc: 0.4785\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.1279 Acc: 0.7102 Balanced Acc: 0.7102\n",
      "val Loss: 2.1350 Acc: 0.4810 Balanced Acc: 0.4833\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.1594 Acc: 0.6962 Balanced Acc: 0.6962\n",
      "val Loss: 2.0916 Acc: 0.4864 Balanced Acc: 0.4895\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.1509 Acc: 0.7027 Balanced Acc: 0.7027\n",
      "val Loss: 2.0986 Acc: 0.4793 Balanced Acc: 0.4822\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.1382 Acc: 0.7127 Balanced Acc: 0.7127\n",
      "val Loss: 2.1080 Acc: 0.4802 Balanced Acc: 0.4846\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.1247 Acc: 0.7075 Balanced Acc: 0.7075\n",
      "val Loss: 2.1379 Acc: 0.4753 Balanced Acc: 0.4780\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.1280 Acc: 0.7089 Balanced Acc: 0.7089\n",
      "val Loss: 2.1106 Acc: 0.4810 Balanced Acc: 0.4845\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.1267 Acc: 0.7072 Balanced Acc: 0.7072\n",
      "val Loss: 2.1266 Acc: 0.4762 Balanced Acc: 0.4785\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.1175 Acc: 0.7079 Balanced Acc: 0.7079\n",
      "val Loss: 2.1052 Acc: 0.4855 Balanced Acc: 0.4902\n",
      "\n",
      "Training complete in 73m 23s\n",
      "Best val Balanced Acc: 0.490186\n",
      "Pruned 2 filters\n",
      "tensor([1.0145, 0.9814, 1.0010, 0.9662, 1.0209, 0.9660, 0.9706, 0.9663, 0.9890,\n",
      "        0.9676, 0.9890, 0.9729, 0.9873, 0.9856, 0.9933, 0.9820, 1.0182, 0.9403,\n",
      "        1.0054, 1.0112, 0.9958, 1.0005, 0.9688, 1.0014, 0.9865, 0.9844, 0.9801,\n",
      "        0.9894, 0.9723, 0.9845, 0.9846, 0.9647, 0.9807, 0.9896, 0.9746, 0.9728,\n",
      "        0.9676, 0.9823, 0.9675, 0.9754, 0.9508, 0.9642, 0.9774, 0.9719, 0.9926,\n",
      "        0.9807, 0.9676, 1.0291, 0.9754, 0.9622, 0.9581, 0.9983, 0.9665, 0.9679,\n",
      "        0.9674, 0.9785, 0.9728, 1.0048, 0.9499, 0.9848, 0.9795, 0.9974, 0.9727,\n",
      "        0.9706])\n",
      "Pruned 4 filters\n",
      "tensor([0.9690, 0.9787, 1.0120, 0.9887, 1.0055, 0.9597, 0.9868, 0.9649, 0.9795,\n",
      "        1.0031, 0.9710, 0.9506, 0.9992, 0.9676, 0.9665, 0.9668, 0.9362, 0.9822,\n",
      "        0.9431, 1.0371, 1.0237, 0.9781, 0.8967, 0.9651, 0.9784, 0.9694, 0.9733,\n",
      "        0.9837, 0.9882, 0.9886, 0.9858, 0.9763, 0.9622, 0.9726, 0.9815, 0.9826,\n",
      "        0.9895, 0.9676, 1.0124, 0.9868, 1.0075, 1.0020, 0.9914, 0.9799, 0.9914,\n",
      "        1.0035, 1.0049, 0.9954, 0.9390, 0.9853, 0.9987, 0.9735, 0.9698, 0.9726,\n",
      "        0.9937, 0.9775, 1.0135, 0.9934, 0.9862, 0.9676, 1.0090, 0.9782, 0.9676,\n",
      "        0.9897])\n",
      "Pruned 2 filters\n",
      "tensor([0.9917, 0.9617, 1.0094, 0.9804, 0.9847, 0.9624, 0.9780, 0.9707, 0.9791,\n",
      "        0.9615, 0.9786, 0.9742, 0.9720, 0.9669, 0.9571, 0.9529, 0.9709, 0.9554,\n",
      "        0.9511, 0.9866, 0.9872, 0.9716, 0.9760, 0.9608, 0.9707, 0.9611, 0.9830,\n",
      "        0.9672, 0.9713, 0.9733, 0.9925, 0.9814, 0.9755, 0.9491, 0.9803, 0.9728,\n",
      "        0.9967, 0.9771, 0.9745, 0.9821, 0.9596, 0.9671, 0.9541, 0.9822, 0.9858,\n",
      "        0.9703, 0.9839, 1.0236, 1.0049, 0.9554, 0.9860, 0.9635, 0.9570, 0.9986,\n",
      "        0.9501, 0.9904, 0.9988, 0.9957, 0.9718, 0.9662, 1.0052, 0.9774, 0.9850,\n",
      "        0.9757, 0.9840, 0.9692, 0.9635, 0.9589, 0.9593, 0.9611, 0.9731, 0.9893,\n",
      "        0.9584, 0.9879, 0.9697, 0.9540, 1.0066, 0.9985, 0.9508, 0.9589, 0.9698,\n",
      "        0.9664, 0.9632, 0.9683, 0.9676, 0.9741, 0.9612, 0.9663, 0.9769, 0.9594,\n",
      "        0.9503, 0.9732, 0.9618, 0.9949, 0.9883, 0.9686, 0.9696, 0.9637, 0.9824,\n",
      "        0.9877, 0.9528, 0.9796, 0.9685, 0.9704, 0.9840, 0.9886, 0.9618, 0.9902,\n",
      "        1.0059, 0.9891, 0.9657, 0.9600, 0.9805, 0.9667, 1.0150, 0.9752, 0.9823,\n",
      "        0.9728, 0.9747, 0.9703, 0.9611, 1.0013, 0.9914, 0.9615, 0.9444, 0.9875,\n",
      "        0.9983, 0.9639])\n",
      "Pruned 19 filters\n",
      "tensor([0.9531, 0.9953, 0.9677, 0.9676, 0.9508, 0.9674, 1.0138, 0.9909, 0.9994,\n",
      "        0.9475, 1.0112, 0.9676, 0.9694, 0.9324, 0.9922, 0.9741, 0.9764, 0.9622,\n",
      "        0.9987, 1.0130, 0.9230, 1.0710, 0.9757, 0.9720, 0.9933, 0.9757, 1.0115,\n",
      "        0.9171, 0.9694, 0.9780, 0.9689, 1.0057, 0.9398, 0.9569, 0.9720, 0.9537,\n",
      "        0.9531, 0.9997, 0.9111, 0.9682, 1.0064, 0.9578, 0.9579, 0.9676, 0.9918,\n",
      "        0.9676, 0.9590, 0.9692, 0.9679, 0.9676, 0.9978, 0.9801, 0.9608, 0.9841,\n",
      "        0.9576, 0.9696, 0.9558, 0.9643, 0.9525, 0.9363, 0.9820, 0.9796, 1.0385,\n",
      "        0.9605, 0.9599, 1.0044, 1.0196, 0.9896, 0.9552, 0.9735, 0.9753, 0.9739,\n",
      "        1.0877, 1.0172, 0.9661, 0.9948, 0.9747, 1.0030, 1.0219, 1.0238, 0.9077,\n",
      "        0.9146, 1.0098, 0.9759, 0.9631, 1.0002, 0.9706, 1.0126, 0.9653, 0.9775,\n",
      "        1.0012, 0.9697, 0.9257, 0.9748, 0.9538, 1.0123, 0.9998, 0.9569, 0.8870,\n",
      "        0.9862, 0.9399, 0.9544, 0.9810, 0.9814, 0.9798, 0.9943, 0.9260, 0.9373,\n",
      "        0.9861, 0.9684, 1.0068, 0.8563, 0.9900, 1.0015, 1.0471, 0.9695, 0.9243,\n",
      "        1.0044, 0.9559, 1.0435, 0.9449, 0.9676, 0.9761, 0.9520, 1.0312, 0.9524,\n",
      "        0.9535, 1.0140])\n",
      "Pruned 15 filters\n",
      "tensor([0.9711, 0.9554, 0.9563, 0.9835, 0.9729, 0.9691, 0.9707, 0.9656, 0.9874,\n",
      "        0.9741, 0.9823, 0.9756, 0.9350, 0.8313, 0.9637, 0.9544, 0.9720, 0.9755,\n",
      "        0.9400, 0.9467, 0.9798, 0.9743, 0.9855, 0.9730, 0.9802, 0.9596, 0.9650,\n",
      "        0.9599, 0.9701, 0.9833, 1.0106, 0.9718, 0.9857, 0.9918, 0.9576, 0.9709,\n",
      "        0.9469, 0.9818, 0.9720, 0.9908, 0.9846, 0.9739, 0.9788, 0.9642, 0.9864,\n",
      "        0.9704, 0.9715, 0.9872, 0.9707, 0.9556, 1.0331, 0.9768, 0.9840, 0.9680,\n",
      "        0.9700, 0.9716, 0.9616, 0.9615, 0.9792, 0.9754, 0.9576, 0.9631, 0.9713,\n",
      "        0.9627, 0.9645, 0.9736, 0.9973, 0.9805, 0.9639, 0.9503, 0.9726, 0.9680,\n",
      "        0.9732, 0.9651, 0.9775, 0.9496, 0.9682, 0.9692, 0.9613, 0.9311, 0.9663,\n",
      "        0.9783, 0.9841, 0.9681, 0.9758, 0.9631, 0.9751, 0.9704, 0.9749, 0.9516,\n",
      "        0.9908, 0.9603, 0.9921, 0.9591, 0.9620, 0.9763, 0.9743, 1.0130, 0.9769,\n",
      "        0.9839, 0.9732, 0.9797, 0.9802, 0.9661, 0.9670, 0.9703, 0.9622, 0.9385,\n",
      "        0.9860, 0.9947, 0.9778, 0.9621, 0.9699, 0.9519, 0.9529, 0.9661, 0.9730,\n",
      "        0.9546, 0.9766, 0.9968, 0.9674, 0.9846, 0.9586, 0.9630, 0.9750, 0.9871,\n",
      "        0.9616, 0.9750, 0.9586, 0.9906, 0.9766, 0.9520, 0.9498, 0.9712, 1.0118,\n",
      "        0.9663, 0.9667, 0.9633, 0.9838, 0.9770, 0.9754, 0.9539, 0.9679, 0.9816,\n",
      "        0.9839, 0.9698, 1.0017, 0.9822, 0.9430, 0.9780, 0.9891, 0.9878, 0.9853,\n",
      "        0.9487, 0.9255, 0.9880, 0.9701, 0.9752, 0.9712, 0.9598, 0.9811, 0.9519,\n",
      "        0.9647, 0.9671, 0.9767, 0.9866, 0.9709, 0.9656, 0.9891, 0.9621, 0.9757,\n",
      "        0.9553, 0.9698, 0.9646, 0.9992, 0.9721, 0.9780, 0.9873, 0.9742, 0.9762,\n",
      "        0.9721, 0.9847, 0.8926, 1.0157, 0.9737, 0.9607, 0.9832, 1.0300, 0.9855,\n",
      "        0.9733, 0.9739, 0.9502, 0.9501, 0.9683, 0.9717, 0.9715, 0.9460, 0.9632,\n",
      "        0.9918, 0.9591, 0.9969, 0.9691, 0.9689, 0.9695, 0.9672, 0.9667, 0.9820,\n",
      "        0.9704, 0.9681, 0.9743, 1.0140, 0.9477, 0.9705, 0.9753, 0.9727, 0.9885,\n",
      "        0.9752, 0.9668, 0.9555, 0.9970, 0.9678, 0.9763, 0.9641, 0.9905, 0.9689,\n",
      "        0.9755, 0.9825, 0.9811, 0.9754, 0.9835, 0.9676, 0.9640, 0.9873, 0.9862,\n",
      "        0.9696, 0.9640, 0.9507, 0.9612, 0.9569, 0.9701, 0.9837, 0.9505, 1.0009,\n",
      "        0.9794, 0.9880, 0.9802, 0.9905, 0.9795, 0.9658, 0.9791, 0.9791, 0.9681,\n",
      "        0.9615, 0.9579, 0.9704, 0.9726])\n",
      "Pruned 14 filters\n",
      "tensor([0.9586, 0.9670, 0.9734, 0.9750, 0.9675, 0.9765, 0.9694, 0.9713, 0.9797,\n",
      "        0.9869, 0.9776, 0.9860, 0.9627, 0.9723, 0.9769, 0.9809, 0.9709, 0.9474,\n",
      "        1.0080, 0.9822, 0.9726, 0.9748, 0.9673, 0.9789, 0.9740, 0.9362, 1.0060,\n",
      "        0.9714, 0.9521, 0.9750, 0.9685, 0.9736, 0.9586, 0.9664, 0.9743, 0.9902,\n",
      "        0.9684, 0.9735, 0.9712, 0.9559, 0.9723, 0.9713, 0.9805, 0.9644, 0.9760,\n",
      "        0.9816, 0.9917, 0.9519, 0.9589, 0.9797, 0.9710, 0.9741, 0.9647, 0.9729,\n",
      "        0.9659, 0.9716, 0.9918, 0.9533, 0.9539, 0.9553, 0.9691, 1.0035, 0.9680,\n",
      "        0.9745, 0.9859, 0.9826, 0.9641, 0.9653, 0.9734, 0.9691, 0.9885, 0.9939,\n",
      "        0.9888, 0.9673, 0.9760, 0.9724, 0.9724, 0.9704, 0.9855, 0.9763, 0.9748,\n",
      "        0.9588, 0.9779, 0.9631, 0.9801, 0.9758, 0.9790, 0.9669, 0.9796, 0.9914,\n",
      "        0.9812, 0.9812, 0.9557, 0.9631, 0.9741, 0.9649, 0.9689, 0.9425, 0.9697,\n",
      "        0.9375, 0.9517, 0.9648, 0.9750, 0.9666, 0.9677, 0.9810, 0.9826, 0.9784,\n",
      "        0.9811, 0.9794, 0.9747, 0.9813, 0.9872, 0.9450, 0.9759, 0.9726, 0.9749,\n",
      "        0.9691, 0.9845, 0.9782, 0.9701, 0.9801, 0.9794, 0.9740, 0.9771, 0.9727,\n",
      "        0.9523, 0.9847, 0.9591, 0.9777, 0.9726, 0.9689, 0.9629, 0.9684, 0.9797,\n",
      "        0.9737, 0.9681, 0.9808, 0.9298, 0.9713, 0.9841, 0.9647, 1.0025, 0.9792,\n",
      "        0.9620, 0.9487, 0.9834, 0.9730, 0.9756, 0.9528, 0.9672, 0.9749, 0.9724,\n",
      "        0.9713, 0.9690, 0.9386, 0.9607, 0.9592, 0.9561, 0.9658, 0.9714, 0.9704,\n",
      "        0.9747, 0.9906, 0.9892, 0.9820, 0.9731, 0.9732, 0.9993, 0.9785, 0.9963,\n",
      "        0.9814, 0.9885, 0.9612, 0.9756, 0.9711, 0.9740, 0.9634, 0.9649, 0.9983,\n",
      "        0.9742, 0.9528, 0.9756, 0.9726, 0.9854, 0.9797, 0.9872, 0.9756, 0.9781,\n",
      "        0.9550, 0.9719, 0.9703, 0.9845, 0.9742, 0.9479, 0.9516, 0.9697, 0.9669,\n",
      "        0.9713, 0.9831, 0.9597, 0.9648, 0.9766, 0.9774, 0.9720, 0.9727, 0.9510,\n",
      "        0.9779, 0.9440, 0.9757, 0.9600, 0.9689, 0.9701, 0.9644, 0.9359, 0.9711,\n",
      "        0.9907, 0.9742, 0.9691, 0.9657, 0.9756, 0.9643, 0.9472, 0.9726, 0.9811,\n",
      "        0.9738, 0.9583, 0.9796, 0.9616, 0.9934, 0.9645, 0.9827, 0.9590, 0.9708,\n",
      "        0.9697, 0.9674, 0.9771, 0.9835, 0.9702, 0.9718, 0.9656, 0.9808, 0.9862,\n",
      "        0.9625, 0.9855, 0.9948, 0.9780, 0.9708, 0.9719, 0.9725, 0.9472, 0.9713,\n",
      "        1.0035, 0.9694, 0.9093, 0.9774])\n",
      "Pruned 15 filters\n",
      "tensor([0.9776, 0.9719, 0.9729, 0.9739, 0.9511, 0.9670, 0.9691, 0.9826, 0.9669,\n",
      "        0.9286, 0.9768, 0.9630, 0.9638, 0.9567, 0.9723, 0.9813, 0.9761, 0.9676,\n",
      "        0.9716, 1.0399, 0.9948, 0.9615, 0.9603, 0.9669, 0.9829, 0.9929, 0.9666,\n",
      "        0.9816, 1.0149, 0.9352, 0.9947, 0.9813, 0.9597, 0.9517, 0.9637, 1.0284,\n",
      "        0.9747, 0.9291, 0.9719, 0.9757, 0.9694, 0.9616, 0.9699, 0.9730, 0.9779,\n",
      "        1.0305, 0.9673, 0.9810, 0.9699, 0.9715, 0.9704, 0.9867, 0.9656, 0.9896,\n",
      "        0.9639, 0.9717, 0.9676, 0.9900, 0.9740, 0.9822, 0.9751, 0.9781, 0.9687,\n",
      "        0.9761, 0.9624, 0.9554, 0.9542, 0.9562, 0.9962, 0.9558, 0.9794, 0.9832,\n",
      "        0.9929, 0.9791, 0.9491, 0.9774, 0.9325, 0.9615, 0.9657, 0.9699, 0.9495,\n",
      "        0.9615, 0.9667, 0.9712, 0.9868, 0.9687, 0.9673, 0.9732, 0.9794, 0.9812,\n",
      "        0.9726, 0.9478, 0.9876, 0.9806, 0.9813, 0.9675, 0.9930, 0.9636, 0.9827,\n",
      "        0.9560, 0.9707, 0.9814, 0.9623, 0.9746, 0.9828, 0.9432, 0.9536, 0.9786,\n",
      "        0.9744, 0.9820, 0.9635, 0.9799, 0.9641, 0.9768, 0.9768, 0.9798, 1.0084,\n",
      "        0.9684, 0.9594, 0.9821, 0.9661, 1.0047, 0.9678, 0.9528, 0.9632, 0.9902,\n",
      "        0.9783, 0.9713, 0.9664, 0.9542, 0.9597, 0.9521, 0.9705, 0.9623, 0.9676,\n",
      "        0.9697, 0.9685, 0.9814, 0.9721, 0.9619, 0.9687, 0.9823, 0.9797, 0.9549,\n",
      "        0.9762, 0.9644, 0.9623, 0.9748, 0.9964, 0.9718, 0.9542, 0.9681, 0.9666,\n",
      "        0.9853, 0.9789, 0.9566, 0.9591, 0.9769, 0.9887, 0.9738, 0.9845, 0.9745,\n",
      "        0.9609, 0.9701, 0.9850, 0.9373, 0.9545, 0.9621, 0.9822, 0.9563, 0.9584,\n",
      "        0.9659, 0.9646, 0.9691, 0.9770, 0.9774, 0.9756, 0.9680, 0.9345, 0.9850,\n",
      "        0.9765, 0.9735, 0.9731, 0.9639, 0.9764, 0.9836, 0.9936, 0.9685, 0.9642,\n",
      "        0.9812, 1.0066, 0.9949, 0.9695, 0.9414, 0.9753, 1.0011, 0.9723, 1.0150,\n",
      "        0.9774, 0.9793, 0.9920, 0.9781, 0.9564, 0.9824, 0.9816, 0.9689, 0.9717,\n",
      "        0.9766, 0.9809, 0.9782, 0.9704, 0.9804, 0.9867, 0.9749, 0.9707, 0.9692,\n",
      "        0.9579, 0.9847, 0.9687, 0.9670, 0.9693, 0.9802, 0.9680, 0.9497, 0.9489,\n",
      "        0.9442, 0.9614, 0.9630, 0.9709, 0.9648, 0.9054, 0.9677, 0.9535, 0.9875,\n",
      "        0.9690, 0.9537, 0.9743, 0.9872, 0.9713, 0.9691, 0.9796, 0.9707, 0.9748,\n",
      "        0.9797, 0.9866, 0.9700, 0.9832, 0.9765, 0.9739, 0.9630, 0.9530, 0.9643,\n",
      "        0.9746, 0.9708, 1.0044, 0.9539])\n",
      "Pruned 12 filters\n",
      "tensor([0.9596, 0.9722, 0.9724, 0.9780, 0.9708, 0.9939, 0.9734, 0.9615, 0.9681,\n",
      "        0.9506, 0.9817, 0.9713, 0.9545, 0.9505, 0.9681, 0.9768, 1.0107, 0.9647,\n",
      "        0.9755, 0.9811, 0.9682, 0.9832, 0.9674, 0.9637, 0.9683, 0.9730, 0.9698,\n",
      "        0.9672, 0.9808, 0.9676, 0.9723, 0.9685, 0.9719, 0.9683, 0.9700, 0.9752,\n",
      "        0.9604, 0.9809, 0.9830, 0.9866, 0.9711, 0.9768, 0.9773, 0.9705, 0.9680,\n",
      "        0.9658, 0.9683, 0.9743, 0.9736, 0.9815, 0.9656, 0.9712, 0.9764, 0.9692,\n",
      "        0.9722, 0.9567, 0.9459, 0.9487, 0.9739, 1.0074, 0.9733, 0.9788, 0.9712,\n",
      "        0.9653, 0.9956, 0.9731, 0.9733, 0.9688, 0.9644, 0.9693, 0.9727, 0.9706,\n",
      "        0.9672, 0.9710, 0.9743, 0.9807, 0.9601, 0.9821, 0.9606, 0.9786, 0.9878,\n",
      "        0.9726, 0.9756, 0.9622, 0.9678, 0.9618, 0.9634, 0.9748, 0.9720, 0.9800,\n",
      "        0.9698, 0.9716, 0.9698, 0.9656, 0.9688, 0.9855, 0.9684, 0.9777, 0.9706,\n",
      "        0.9349, 0.9635, 0.9786, 0.9660, 0.9701, 0.9723, 0.9686, 0.9711, 0.9656,\n",
      "        0.9703, 0.9593, 0.9676, 0.9521, 0.9730, 0.9719, 0.9513, 0.9446, 0.9693,\n",
      "        0.9701, 0.9668, 0.9474, 0.9727, 0.9592, 0.9694, 0.9642, 0.9688, 0.9546,\n",
      "        0.9771, 0.9611, 0.9769, 0.9764, 0.9692, 0.9665, 0.9744, 0.9645, 0.9767,\n",
      "        0.9666, 0.9724, 0.9806, 0.9715, 0.9733, 0.9809, 0.9987, 0.9723, 0.9753,\n",
      "        0.9695, 0.9658, 0.9724, 0.9632, 0.9555, 0.9823, 1.0372, 0.9688, 0.9681,\n",
      "        0.9660, 0.9614, 0.9842, 0.9715, 0.9643, 0.9720, 0.9758, 0.9716, 0.9637,\n",
      "        0.9624, 0.9615, 0.9547, 0.9664, 0.9648, 0.9702, 0.9748, 0.9625, 0.9706,\n",
      "        0.9647, 0.9741, 0.9560, 0.9744, 0.9679, 0.9681, 0.9716, 0.9738, 0.9710,\n",
      "        0.9880, 0.9731, 0.9810, 0.9660, 0.9664, 0.9697, 0.9795, 0.9626, 0.9538,\n",
      "        0.9716, 0.9644, 0.9643, 1.0003, 0.9662, 0.9821, 0.9701, 0.9781, 0.9714,\n",
      "        0.9803, 0.9684, 0.9737, 0.9768, 0.9572, 0.9548, 0.9679, 0.9650, 0.9674,\n",
      "        0.9669, 0.9700, 0.9719, 0.9654, 0.9726, 0.9740, 0.9607, 0.9708, 0.9805,\n",
      "        0.9703, 0.9663, 0.9754, 0.9764, 0.9620, 0.9800, 0.9656, 0.9628, 0.9760,\n",
      "        0.9697, 0.9651, 0.9662, 0.9846, 0.9609, 0.9568, 0.9643, 0.9560, 0.9686,\n",
      "        0.9724, 0.9939, 0.9714, 0.9696, 0.9646, 0.9827, 0.9739, 0.9670, 0.9635,\n",
      "        0.9676, 0.9733, 0.9714, 0.9597, 0.9582, 0.9910, 0.9676, 0.9664, 0.9674,\n",
      "        0.9689, 0.9713, 0.9708, 0.9659, 0.9592, 0.9696, 0.9784, 0.9647, 0.9721,\n",
      "        0.9712, 0.9693, 0.9731, 0.9681, 0.9697, 0.9548, 0.9698, 0.9502, 0.9676,\n",
      "        0.9651, 0.9507, 0.9685, 0.9657, 0.9710, 0.9731, 0.9647, 0.9644, 0.9746,\n",
      "        0.9792, 0.9798, 0.9812, 0.9786, 0.9705, 0.9597, 0.9686, 0.9806, 0.9678,\n",
      "        0.9680, 0.9679, 0.9621, 0.9818, 0.9677, 0.9306, 0.9780, 0.9838, 0.9816,\n",
      "        0.9791, 0.9693, 0.9702, 0.9788, 0.9683, 0.9683, 0.9693, 0.9717, 0.9580,\n",
      "        0.9883, 0.9689, 0.9748, 0.9590, 0.9683, 0.9695, 0.9728, 0.9692, 0.9575,\n",
      "        0.9740, 0.9843, 0.9826, 0.9727, 0.9710, 0.9638, 0.9667, 0.9610, 0.9665,\n",
      "        0.9747, 0.9729, 0.9679, 0.9676, 0.9517, 0.9790, 0.9663, 0.9777, 0.9577,\n",
      "        0.9665, 0.9799, 0.9684, 0.9810, 0.9701, 0.9615, 0.9735, 0.9661, 0.9680,\n",
      "        0.9800, 0.9680, 0.9660, 0.9780, 0.9695, 0.9712, 0.9657, 0.9766, 0.9643,\n",
      "        0.9623, 0.9546, 0.9680, 0.9694, 0.9671, 0.9905, 0.9665, 0.9679, 0.9668,\n",
      "        0.9671, 0.9621, 0.9667, 0.9668, 0.9623, 0.9728, 0.9746, 0.9518, 0.9719,\n",
      "        0.9523, 0.9827, 0.9818, 0.9796, 0.9693, 0.9760, 0.9719, 0.9620, 0.9676,\n",
      "        0.9635, 0.9609, 0.9685, 0.9738, 0.9267, 0.9788, 0.9702, 0.9744, 0.9682,\n",
      "        0.9739, 0.9743, 0.9748, 0.9669, 0.9663, 0.9609, 0.9679, 0.9702, 0.9548,\n",
      "        0.9810, 0.9648, 0.9668, 0.9742, 0.9758, 0.9282, 0.9653, 0.9676, 0.9661,\n",
      "        0.9734, 0.9612, 0.9710, 0.9717, 0.9644, 0.9750, 0.9658, 0.9656, 0.9733,\n",
      "        0.9700, 0.9704, 0.9657, 0.9630, 0.9501, 0.9696, 0.9634, 0.9818, 0.9750,\n",
      "        0.9687, 0.9665, 0.9718, 0.9779, 0.9663, 0.9715, 0.9780, 0.9740, 0.9692,\n",
      "        0.9698, 0.9673, 0.9682, 0.9723, 0.9634, 0.9673, 0.9678, 0.9558, 0.9795,\n",
      "        0.9749, 0.9693, 0.9742, 1.0185, 0.9858, 0.9699, 0.9700, 0.9746, 0.9653,\n",
      "        0.9595, 0.9677, 0.9695, 0.9855, 0.9693, 0.9615, 0.9673, 0.9645, 0.9774,\n",
      "        0.9787, 0.9639, 0.9350, 0.9662, 0.9889, 0.9690, 0.9689, 0.9715, 0.9271,\n",
      "        0.9687, 0.9676, 0.9628, 0.9660, 0.9473, 0.9878, 0.9561, 0.9739, 0.9715,\n",
      "        0.9726, 0.9660, 0.9680, 0.9812, 0.9660, 0.9683, 0.9869, 0.9675, 0.9756,\n",
      "        0.9435, 0.9749, 0.9705, 0.9680, 0.9747, 0.9663, 0.9608, 0.9682, 0.9838,\n",
      "        0.9738, 0.9647, 0.9676, 0.9665, 0.9765, 0.9735, 0.9744, 0.9824, 0.9673,\n",
      "        0.9800, 0.9799, 0.9777, 0.9666, 0.9825, 0.9719, 0.9634, 0.9657])\n",
      "Pruned 9 filters\n",
      "tensor([0.9683, 0.9692, 0.9646, 0.9638, 0.9669, 0.9712, 0.9683, 0.9728, 0.9715,\n",
      "        0.9693, 0.9686, 0.9718, 0.9683, 0.9673, 0.9694, 0.9681, 0.9660, 0.9670,\n",
      "        0.9690, 0.9721, 0.9685, 0.9623, 0.9685, 0.9726, 0.9684, 0.9635, 0.9699,\n",
      "        0.9677, 0.9699, 0.8973, 0.9700, 0.9741, 0.9690, 0.9765, 0.9750, 0.9787,\n",
      "        0.9697, 0.9689, 0.9767, 0.9656, 0.9897, 0.9686, 0.9798, 0.9728, 0.9692,\n",
      "        0.9670, 0.9757, 0.9705, 0.9748, 0.9733, 0.9760, 0.9731, 0.9598, 0.9926,\n",
      "        0.9699, 0.9623, 0.9699, 0.9719, 0.9657, 0.9843, 0.9718, 0.9676, 0.9665,\n",
      "        0.9731, 0.9694, 0.9640, 0.9674, 0.9662, 0.9862, 0.9704, 0.9730, 0.9695,\n",
      "        0.9683, 0.9710, 0.9706, 0.9666, 0.9668, 0.9664, 0.9657, 0.9793, 0.9669,\n",
      "        0.9720, 0.9521, 0.9670, 0.9687, 0.9687, 0.9555, 0.9708, 0.9907, 0.9664,\n",
      "        0.9797, 0.9661, 0.9667, 0.9676, 0.9728, 0.9682, 0.9657, 0.9710, 0.9679,\n",
      "        0.9668, 0.9664, 0.9445, 0.9696, 0.9584, 0.9738, 0.9698, 0.9668, 0.9643,\n",
      "        0.9722, 0.9698, 0.9773, 0.9731, 0.9676, 0.9690, 0.9684, 0.9698, 0.9789,\n",
      "        0.9660, 0.9666, 0.9716, 0.9535, 0.9555, 0.9651, 0.9731, 0.9668, 0.9845,\n",
      "        0.9758, 0.9634, 0.9857, 0.9618, 0.9746, 0.9710, 0.9622, 0.9632, 0.9678,\n",
      "        0.9721, 0.9771, 0.9718, 0.9689, 0.9613, 0.9691, 0.9714, 0.9577, 0.9707,\n",
      "        0.9730, 0.9712, 0.9522, 0.9555, 0.9801, 0.9761, 0.9741, 0.9701, 0.9756,\n",
      "        0.9702, 0.9793, 0.9757, 0.9683, 0.9422, 0.9694, 0.9880, 0.9739, 0.9718,\n",
      "        0.9666, 0.9901, 0.9786, 0.9707, 0.9634, 0.9653, 0.9733, 0.9669, 0.9746,\n",
      "        0.9735, 0.9739, 0.9647, 0.9748, 0.9725, 0.9641, 0.9690, 0.9760, 0.9866,\n",
      "        0.9666, 0.9779, 0.9811, 0.9675, 0.9848, 0.9676, 0.9676, 0.9740, 0.9682,\n",
      "        0.9675, 0.9593, 0.9692, 0.9784, 0.9782, 0.9722, 0.9635, 0.9730, 0.9752,\n",
      "        0.9701, 0.9750, 0.9727, 0.9769, 0.9668, 0.9724, 0.9703, 0.9520, 0.9728,\n",
      "        0.9713, 0.9707, 0.9677, 0.9711, 0.9614, 0.9764, 0.9661, 0.9701, 0.9688,\n",
      "        0.9611, 0.9698, 0.9681, 0.9490, 0.9692, 0.9661, 0.9667, 0.9791, 1.0045,\n",
      "        0.9744, 0.9722, 0.9573, 0.9712, 0.9906, 0.9883, 0.9602, 0.9804, 0.9707,\n",
      "        0.9720, 0.9672, 0.9674, 0.9654, 0.9758, 0.9692, 0.9756, 0.9696, 0.9715,\n",
      "        0.9642, 0.9696, 0.9624, 0.9747, 0.9736, 0.9675, 0.9897, 0.9692, 0.9746,\n",
      "        0.9721, 0.9633, 0.9693, 0.9765, 0.9631, 0.9835, 0.9619, 0.9570, 0.9896,\n",
      "        0.9612, 0.9764, 0.9656, 0.9767, 0.9808, 0.9669, 0.9679, 0.9631, 0.9572,\n",
      "        0.9750, 0.9769, 0.9657, 0.9720, 0.9671, 0.9520, 0.9675, 0.9724, 0.9769,\n",
      "        0.9642, 0.9719, 0.9673, 0.9759, 0.9711, 0.9622, 0.9943, 0.9686, 0.9678,\n",
      "        0.9713, 0.9595, 0.9639, 0.9766, 0.9617, 0.9631, 0.9584, 0.9713, 0.9675,\n",
      "        0.9659, 0.9710, 0.9713, 0.9440, 0.9704, 0.9711, 0.9703, 0.9684, 0.9652,\n",
      "        0.9649, 0.9612, 0.9695, 0.9751, 0.9629, 0.9657, 0.9787, 0.9766, 0.9665,\n",
      "        0.9727, 0.9711, 0.9680, 0.9488, 0.9722, 0.9760, 0.9672, 0.9595, 0.9748,\n",
      "        0.9426, 0.9701, 0.9953, 0.9698, 0.9683, 0.9594, 0.9639, 0.9720, 0.9746,\n",
      "        0.9514, 0.9781, 0.9643, 0.9700, 0.9664, 0.9571, 0.9825, 0.9651, 0.9649,\n",
      "        0.9488, 0.9707, 0.9678, 0.9628, 0.9717, 0.9728, 0.9713, 0.9694, 0.9702,\n",
      "        1.0010, 0.9752, 0.9666, 0.9677, 0.9914, 0.9554, 0.9672, 0.9765, 0.9707,\n",
      "        0.9676, 0.9515, 0.9588, 0.9658, 0.9663, 0.9788, 0.9750, 0.9715, 0.9688,\n",
      "        0.9685, 0.9664, 0.9717, 0.9848, 0.9589, 1.0012, 0.9766, 0.9683, 0.9606,\n",
      "        0.9697, 0.9657, 0.9496, 0.9627, 0.9837, 0.9643, 0.9876, 0.9774, 0.9702,\n",
      "        0.9677, 0.9693, 0.9685, 0.9506, 0.9704, 0.9705, 0.9661, 0.9699, 0.9630,\n",
      "        0.9659, 0.9715, 0.9704, 0.9587, 0.9674, 0.9792, 0.9741, 0.9762, 0.9714,\n",
      "        0.9668, 0.9557, 0.9680, 0.9710, 0.9689, 0.9988, 0.9678, 0.9742, 0.9677,\n",
      "        0.9676, 0.9623, 0.9699, 0.9781, 0.9677, 0.9656, 0.9701, 0.9755, 0.9767,\n",
      "        0.9683, 0.9718, 0.9696, 0.9816, 0.9701, 0.9580, 0.9693, 0.9777, 0.9725,\n",
      "        0.9671, 0.9636, 0.9818, 0.9640, 0.9635, 0.9703, 0.9763, 0.9545, 0.9671,\n",
      "        0.9832, 0.9771, 0.9729, 0.9743, 0.9811, 0.9722, 0.9756, 0.9747, 0.9800,\n",
      "        0.9628, 0.9717, 0.9946, 0.9684, 1.0366, 0.9604, 0.9707, 0.9628, 0.9628,\n",
      "        0.9715, 0.9650, 0.9698, 0.9672, 0.9702, 0.9679, 0.9684, 0.9523, 0.9609,\n",
      "        0.9736, 0.9566, 0.9670, 0.9778, 0.9738, 0.9702, 0.9676, 0.9680, 0.9803,\n",
      "        0.9692, 0.9640, 0.9626, 1.0053, 0.9724, 0.9757, 0.9677, 0.9763, 1.0008,\n",
      "        0.9671, 0.9772, 0.9611, 0.9657, 0.9669, 0.9791, 0.9662, 0.9740, 0.9705,\n",
      "        0.9707, 0.9762, 0.9629, 0.9590, 0.9503, 0.9702, 0.9649, 0.9736, 0.9714,\n",
      "        0.9650, 0.9799, 0.9571, 0.9664, 0.9689, 0.9871, 0.9805, 0.9693])\n",
      "Pruned 6 filters\n",
      "tensor([0.9773, 0.9666, 0.9722, 0.9654, 0.9714, 0.9491, 0.9785, 0.9665, 0.9704,\n",
      "        0.9668, 0.9654, 0.9784, 0.9580, 0.9591, 0.9664, 0.9711, 0.9731, 0.9539,\n",
      "        0.9607, 0.9724, 0.9643, 0.9736, 0.9750, 0.9566, 0.9670, 0.9795, 0.9804,\n",
      "        0.9698, 0.9618, 0.9666, 0.9658, 0.9765, 0.9650, 0.9688, 0.9667, 0.9671,\n",
      "        0.9633, 0.9755, 0.9609, 0.9688, 0.9621, 0.9589, 0.9983, 0.9775, 0.9772,\n",
      "        0.9677, 0.9814, 0.9664, 0.9600, 0.9527, 0.9701, 0.9634, 0.9645, 0.9626,\n",
      "        0.9655, 0.9608, 0.9432, 0.9646, 0.9776, 0.9650, 0.9791, 0.9751, 0.9632,\n",
      "        0.9962, 0.9830, 0.9710, 0.9641, 0.9790, 0.9720, 0.9688, 0.9700, 0.9861,\n",
      "        0.9676, 0.9701, 0.9579, 0.9678, 0.9684, 0.9701, 0.9690, 0.9821, 0.9704,\n",
      "        0.9667, 0.9682, 0.9695, 0.9786, 0.9669, 0.9769, 0.9559, 0.9878, 0.9660,\n",
      "        0.9739, 0.9699, 0.9689, 0.9737, 0.9649, 0.9647, 0.9634, 0.9805, 0.9807,\n",
      "        0.9765, 0.9641, 0.9686, 0.9711, 0.9685, 0.9453, 0.9614, 0.9706, 0.9578,\n",
      "        0.9714, 0.9720, 0.9826, 0.9696, 0.9713, 0.9686, 0.9763, 0.9735, 0.9750,\n",
      "        0.9717, 0.9678, 0.9634, 0.9857, 0.9672, 0.9720, 0.9677, 0.9554, 0.9723,\n",
      "        0.9650, 0.9734, 0.9719, 0.9722, 0.9650, 0.9692, 0.9819, 0.9719, 0.9683,\n",
      "        0.9572, 0.9625, 0.9847, 0.9676, 0.9691, 0.9741, 0.9686, 0.9774, 0.9677,\n",
      "        0.9663, 0.9696, 0.9671, 0.9658, 0.9722, 0.9893, 0.9612, 0.9666, 0.9591,\n",
      "        0.9712, 0.9727, 0.9687, 0.9821, 0.9715, 0.9741, 0.9619, 0.9605, 0.9663,\n",
      "        0.9800, 0.9713, 0.9670, 0.9685, 0.9733, 0.9750, 0.9706, 0.9772, 0.9647,\n",
      "        0.9639, 0.9728, 0.9694, 0.9678, 0.9702, 0.9697, 0.9639, 0.9670, 0.9512,\n",
      "        0.9829, 0.9658, 0.9621, 0.9623, 0.9611, 0.9590, 0.9616, 0.9707, 0.9590,\n",
      "        0.9793, 0.9644, 0.9678, 0.9657, 0.9675, 0.9597, 0.9676, 0.9715, 0.9661,\n",
      "        0.9539, 0.9775, 0.9642, 0.9688, 0.9617, 0.9652, 0.9599, 0.9704, 0.9743,\n",
      "        0.9664, 0.9865, 0.9615, 0.9761, 0.9628, 0.9709, 0.9768, 0.9875, 0.9711,\n",
      "        0.9699, 0.9720, 0.9713, 0.9823, 0.9698, 0.9651, 0.9662, 0.9586, 0.9731,\n",
      "        0.9752, 0.9717, 0.9687, 0.9685, 0.9698, 0.9672, 0.9859, 0.9825, 0.9723,\n",
      "        0.9772, 0.9666, 0.9702, 0.9680, 0.9744, 0.9647, 1.0032, 0.9679, 0.9663,\n",
      "        0.9643, 0.9686, 0.9678, 0.9667, 0.9738, 0.9686, 0.9803, 0.9604, 0.9711,\n",
      "        0.9752, 0.9729, 0.9706, 0.9703, 0.9773, 0.9723, 0.9676, 0.9692, 0.9711,\n",
      "        0.9697, 0.9688, 0.9939, 0.9724, 0.9669, 0.9657, 0.9676, 0.9867, 0.9671,\n",
      "        0.9597, 0.9674, 0.9731, 0.9684, 0.9729, 0.9717, 0.9720, 0.9625, 0.9806,\n",
      "        0.9641, 0.9702, 0.9720, 0.9665, 0.9685, 0.9718, 0.9675, 0.9709, 0.9782,\n",
      "        0.9746, 0.9736, 0.9689, 0.9655, 0.9666, 0.9765, 0.9797, 0.9624, 0.9852,\n",
      "        0.9646, 0.9766, 0.9702, 0.9717, 0.9586, 0.9684, 0.9673, 0.9654, 0.9674,\n",
      "        0.9762, 0.9790, 0.9679, 0.9755, 0.9664, 0.9722, 0.9715, 0.9731, 0.9710,\n",
      "        0.9702, 0.9762, 0.9723, 0.9580, 0.9787, 0.9445, 0.9630, 0.9779, 0.9669,\n",
      "        0.9801, 0.9654, 0.9680, 0.9646, 0.9674, 0.9715, 0.9654, 0.9804, 0.9746,\n",
      "        0.9773, 0.9676, 0.9688, 0.9723, 0.9713, 0.9689, 0.9484, 0.9814, 0.9780,\n",
      "        0.9739, 0.9712, 0.9767, 0.9726, 0.9692, 0.9860, 0.9504, 0.9731, 0.9627,\n",
      "        0.9725, 0.9643, 0.9694, 0.9733, 0.9657, 0.9737, 0.9423, 0.9760, 0.9698,\n",
      "        0.9818, 0.9728, 0.9712, 0.9774, 0.9811, 0.9632, 0.9701, 0.9849, 0.9731,\n",
      "        0.9819, 0.9648, 0.9681, 0.9683, 0.9766, 0.9684, 0.9724, 0.9611, 0.9645,\n",
      "        0.9702, 0.9750, 0.9667, 0.9668, 0.9733, 0.9736, 0.9730, 0.9734, 0.9742,\n",
      "        0.9656, 0.9702, 0.9725, 0.9939, 0.9787, 0.9895, 0.9677, 0.9795, 0.9645,\n",
      "        0.9653, 0.9666, 0.9760, 0.9613, 0.9736, 0.9700, 0.9771, 0.9685, 0.9722,\n",
      "        0.9652, 0.9686, 0.9648, 0.9582, 0.9623, 0.9701, 0.9790, 0.9741, 0.9894,\n",
      "        0.9619, 0.9638, 0.9661, 0.9612, 0.9584, 0.9677, 0.9846, 0.9651, 0.9736,\n",
      "        0.9566, 0.9688, 0.9629, 0.9623, 0.9781, 0.9754, 0.9674, 0.9673, 0.9656,\n",
      "        0.9645, 0.9644, 0.9684, 0.9785, 0.9672, 0.9713, 0.9690, 0.9692, 0.9675,\n",
      "        0.9692, 0.9660, 0.9569, 0.9686, 0.9649, 0.9697, 0.9758, 0.9865, 0.9694,\n",
      "        0.9710, 0.9677, 0.9730, 0.9782, 0.9727, 0.9650, 0.9706, 0.9652, 0.9728,\n",
      "        0.9793, 0.9711, 0.9813, 0.9746, 0.9740, 0.9704, 0.9663, 0.9695, 0.9703,\n",
      "        0.9864, 0.9689, 0.9637, 0.9732, 0.9751, 0.9625, 0.9672, 0.9733, 0.9780,\n",
      "        0.9844, 0.9688, 0.9729, 0.9696, 0.9708, 0.9795, 0.9670, 0.9654, 0.9764,\n",
      "        0.9673, 0.9777, 0.9735, 0.9684, 0.9698, 0.9971, 0.9775, 0.9839, 0.9714,\n",
      "        0.9668, 0.9646, 0.9678, 0.9581, 0.9635, 0.9683, 0.9765, 0.9722, 0.9755,\n",
      "        0.9692, 0.9730, 0.9690, 0.9682, 0.9594, 0.9667, 0.9687, 0.9699])\n",
      "Pruned 9 filters\n",
      "tensor([0.9694, 0.9721, 0.9671, 0.9764, 0.9680, 0.9583, 0.9683, 0.9665, 0.9763,\n",
      "        0.9929, 0.9670, 0.9675, 0.9607, 0.9717, 0.9676, 0.9656, 0.9856, 0.9697,\n",
      "        0.9707, 0.9696, 0.9748, 0.9681, 0.9630, 0.9616, 0.9884, 0.9996, 0.9868,\n",
      "        0.9621, 0.9663, 0.9659, 0.9729, 0.9752, 0.9655, 0.9656, 0.9593, 0.9662,\n",
      "        0.9640, 0.9682, 0.9777, 0.9619, 0.9679, 0.9707, 0.9509, 0.9729, 0.9683,\n",
      "        0.9678, 0.9667, 0.9582, 0.9712, 0.9643, 0.9685, 0.9727, 0.9787, 0.9709,\n",
      "        0.9723, 0.9622, 0.9721, 0.9672, 0.9619, 0.9844, 0.9760, 0.9713, 0.9720,\n",
      "        0.9639, 0.9691, 0.9560, 0.9824, 0.9652, 0.9715, 0.9645, 0.9682, 0.9711,\n",
      "        0.9650, 0.9727, 0.9927, 0.9647, 0.9724, 0.9795, 0.9663, 0.9730, 0.9703,\n",
      "        0.9721, 0.9661, 0.9663, 0.9732, 0.9623, 0.9753, 0.9644, 0.9710, 0.9656,\n",
      "        0.9646, 0.9624, 0.9743, 0.9697, 0.9640, 0.9584, 0.9602, 0.9650, 0.9635,\n",
      "        0.9967, 0.9708, 0.9717, 0.9690, 0.9645, 0.9735, 0.9665, 0.9669, 0.9705,\n",
      "        0.9606, 0.9640, 0.9799, 0.9747, 1.0125, 0.9678, 0.9705, 0.9673, 0.9747,\n",
      "        0.9743, 0.9858, 0.9685, 0.9986, 0.9692, 0.9710, 0.9631, 0.9647, 0.9610,\n",
      "        0.9678, 0.9662, 0.9677, 0.9689, 0.9775, 0.9567, 0.9717, 0.9733, 0.9729,\n",
      "        0.9632, 0.9694, 0.9721, 0.9752, 0.9658, 0.9598, 0.9672, 0.9783, 0.9706,\n",
      "        0.9929, 0.9738, 0.9787, 0.9711, 0.9793, 0.9669, 0.9657, 0.9703, 0.9711,\n",
      "        0.9669, 0.9664, 0.9689, 0.9691, 0.9747, 0.9604, 0.9856, 0.9770, 0.9663,\n",
      "        0.9845, 0.9646, 0.9896, 0.9682, 0.9815, 0.9617, 0.9678, 0.9629, 0.9580,\n",
      "        0.9660, 0.9749, 0.9855, 0.9682, 0.9690, 0.9660, 0.9678, 0.9672, 0.9677,\n",
      "        1.0053, 0.9705, 0.9662, 0.9691, 0.9701, 0.9674, 0.9680, 0.9621, 0.9824,\n",
      "        0.9687, 0.9734, 0.9693, 0.9597, 0.9631, 0.9800, 0.9704, 0.9763, 0.9415,\n",
      "        0.9644, 0.9677, 0.9690, 0.9675, 0.9629, 0.9667, 0.9680, 0.9451, 0.9720,\n",
      "        0.9729, 0.9704, 0.9574, 0.9565, 0.9644, 0.9308, 0.9741, 0.9693, 0.9680,\n",
      "        0.9930, 0.9637, 0.9671, 0.9635, 0.9878, 0.9682, 0.9755, 0.9609, 0.9805,\n",
      "        0.9764, 0.9725, 0.9745, 0.9705, 0.9737, 0.9689, 0.9665, 0.9756, 0.9806,\n",
      "        0.9730, 0.9715, 0.9771, 0.9663, 0.9658, 0.9809, 0.9654, 0.9893, 0.9672,\n",
      "        0.9700, 0.9638, 0.9708, 0.9758, 0.9687, 0.9651, 0.9412, 0.9652, 0.9712,\n",
      "        0.9723, 0.9757, 0.9663, 0.9737, 0.9701, 0.9656, 0.9862, 0.9675, 0.9701,\n",
      "        0.9715, 0.9643, 0.9796, 0.9669, 0.9655, 0.9644, 0.9729, 0.9900, 0.9715,\n",
      "        0.9836, 0.9644, 0.9797, 0.9829, 0.9611, 0.9689, 0.9676, 0.9622, 0.9779,\n",
      "        0.9698, 0.9641, 0.9758, 0.9723, 0.9683, 0.9743, 0.9905, 0.9784, 0.9353,\n",
      "        0.9883, 0.9648, 0.9715, 0.9627, 0.9789, 0.9673, 0.9728, 0.9647, 0.9737,\n",
      "        0.9679, 0.9689, 0.9673, 0.9683, 0.9655, 0.9697, 0.9718, 0.9609, 1.0024,\n",
      "        0.9698, 0.9888, 1.0024, 0.9767, 0.9578, 0.9669, 0.9561, 0.9734, 0.9696,\n",
      "        0.9620, 0.9734, 0.9557, 0.9677, 0.9644, 0.9591, 0.9781, 0.9709, 0.9700,\n",
      "        0.9758, 0.9676, 0.9652, 0.9915, 0.9683, 0.9732, 0.9865, 0.9611, 0.9685,\n",
      "        0.9658, 0.9681, 0.9681, 0.9672, 0.9543, 0.9456, 0.9645, 0.9617, 0.9596,\n",
      "        0.9685, 0.9625, 0.9740, 0.9681, 0.9841, 0.9685, 0.9655, 0.9687, 0.9746,\n",
      "        0.9671, 0.9717, 0.9749, 0.9581, 0.9653, 0.9714, 0.9763, 0.9657, 0.9660,\n",
      "        0.9645, 0.9734, 0.9638, 0.9665, 0.9655, 0.9673, 0.9846, 0.9644, 0.9676,\n",
      "        0.9677, 0.9646, 0.9739, 0.9565, 0.9771, 0.9593, 0.9905, 0.9735, 0.9692,\n",
      "        0.9796, 0.9621, 0.9712, 0.9697, 0.9690, 1.0005, 0.9775, 0.9676, 0.9676,\n",
      "        0.9668, 0.9681, 0.9660, 0.9738, 0.9682, 0.9667, 0.9694, 0.9727, 0.9651,\n",
      "        0.9654, 0.9631, 0.9867, 0.9780, 0.9564, 0.9685, 0.9587, 0.9676, 0.9699,\n",
      "        0.9657, 0.9668, 0.9730, 0.9684, 0.9782, 0.9682, 0.9712, 0.9756, 0.9695,\n",
      "        0.9665, 0.9664, 0.9736, 0.9670, 0.9709, 0.9758, 0.9495, 0.9859, 0.9713,\n",
      "        0.9771, 0.9745, 0.9515, 0.9669, 0.9920, 0.9779, 0.9642, 0.9678, 0.9727,\n",
      "        0.9699, 0.9871, 0.9662, 0.9651, 0.9653, 0.9694, 0.9574, 0.9729, 0.9919,\n",
      "        0.9690, 0.9660, 0.9544, 0.9632, 0.9839, 0.9650, 0.9767, 1.0184, 0.9673,\n",
      "        0.9673, 0.9677, 0.9817, 0.9702, 0.9737, 0.9699, 0.9843, 0.9678, 0.9860,\n",
      "        0.9700, 0.9676, 0.9598, 0.9714, 0.9683, 0.9725, 0.9728, 0.9847, 0.9708,\n",
      "        0.9681, 0.9138, 0.9654, 0.9599, 0.9710, 0.9629, 0.9717, 0.9712, 0.9700,\n",
      "        0.9729, 0.9980, 0.9700, 0.9762, 0.9673, 0.9543, 0.9641, 0.9720, 0.9713,\n",
      "        0.9643, 0.9754, 0.9704, 0.9703, 0.9684, 0.9824, 0.9758, 0.9752, 0.9752,\n",
      "        0.9705, 0.9729, 0.9725, 0.9684, 0.9912, 0.9649, 0.9721, 0.9648, 0.9721,\n",
      "        0.9714, 1.0164, 0.9679, 0.9392, 0.9636, 0.9631, 0.9667, 0.9608])\n",
      "Pruned 2 filters\n",
      "tensor([0.9672, 0.9711, 0.9808, 0.9684, 0.9666, 0.9691, 0.9709, 0.9676, 0.9659,\n",
      "        0.9683, 0.9658, 0.9763, 0.9689, 0.9714, 0.9685, 0.9709, 0.9706, 0.9742,\n",
      "        0.9692, 0.9689, 0.9700, 0.9682, 0.9720, 0.9625, 0.9496, 0.9656, 0.9786,\n",
      "        0.9676, 0.9723, 0.9647, 0.9738, 0.9660, 0.9645, 0.9675, 0.9712, 0.9670,\n",
      "        0.9658, 0.9693, 0.9718, 0.9648, 0.9653, 0.9727, 0.9717, 0.9680, 0.9677,\n",
      "        0.9644, 0.9673, 0.9717, 0.9897, 0.9707, 0.9680, 0.9776, 0.9801, 0.9704,\n",
      "        0.9662, 0.9741, 0.9677, 0.9638, 0.9708, 0.9709, 0.9752, 0.9689, 0.9717,\n",
      "        0.9744, 0.9702, 0.9833, 0.9626, 0.9730, 0.9774, 0.9708, 0.9794, 0.9747,\n",
      "        0.9671, 0.9740, 0.9673, 0.9665, 0.9633, 0.9703, 0.9795, 0.9729, 0.9668,\n",
      "        0.9730, 0.9697, 0.9686, 0.9709, 0.9733, 0.9721, 0.9696, 0.9702, 0.9642,\n",
      "        0.9670, 0.9697, 0.9733, 0.9730, 0.9521, 0.9728, 0.9705, 0.9618, 0.9651,\n",
      "        0.9712, 0.9710, 0.9669, 0.9671, 0.9616, 0.9689, 0.9686, 0.9689, 0.9697,\n",
      "        0.9695, 0.9699, 0.9698, 0.9714, 0.9678, 0.9714, 0.9735, 0.9697, 0.9615,\n",
      "        0.9711, 0.9682, 0.9789, 0.9743, 0.9624, 0.9739, 0.9772, 0.9755, 0.9692,\n",
      "        0.9736, 0.9815, 0.9676, 0.9742, 0.9815, 0.9659, 0.9809, 0.9702, 0.9656,\n",
      "        0.9741, 0.9740, 0.9689, 0.9635, 0.9651, 0.9784, 0.9639, 0.9688, 0.9685,\n",
      "        0.9722, 0.9690, 0.9751, 0.9815, 0.9747, 0.9693, 0.9689, 0.9678, 0.9685,\n",
      "        0.9806, 0.9686, 0.9697, 0.9803, 0.9679, 0.9694, 0.9667, 0.9707, 0.9655,\n",
      "        0.9761, 0.9703, 0.9634, 0.9692, 0.9704, 0.9675, 0.9586, 0.9688, 0.9678,\n",
      "        0.9572, 0.9817, 0.9658, 0.9676, 0.9692, 0.9706, 0.9682, 0.9676, 0.9754,\n",
      "        0.9724, 0.9798, 1.0098, 0.9659, 0.9634, 0.9715, 0.9717, 0.9658, 0.9636,\n",
      "        0.9761, 0.9712, 0.9784, 0.9709, 0.9768, 0.9766, 0.9665, 0.9759, 0.9700,\n",
      "        0.9642, 0.9805, 0.9712, 0.9644, 0.9674, 0.9793, 0.9695, 0.9727, 0.9858,\n",
      "        0.9836, 0.9763, 0.9824, 0.9735, 0.9673, 0.9763, 0.9716, 0.9702, 0.9711,\n",
      "        0.9675, 0.9831, 0.9576, 0.9719, 0.9672, 0.9640, 0.9953, 0.9679, 0.9665,\n",
      "        0.9760, 0.9678, 0.9698, 0.9692, 0.9708, 0.9718, 0.9679, 0.9692, 0.9789,\n",
      "        0.9696, 0.9702, 0.9692, 0.9720, 0.9683, 0.9660, 0.9710, 0.9541, 0.9733,\n",
      "        0.9656, 0.9773, 0.9694, 0.9724, 0.9646, 0.9516, 0.9694, 0.9701, 0.9711,\n",
      "        0.9637, 0.9699, 0.9739, 0.9711, 0.9748, 0.9677, 0.9678, 0.9751, 0.9644,\n",
      "        0.9730, 0.9648, 0.9684, 0.9723, 0.9548, 0.9696, 0.9710, 0.9683, 0.9843,\n",
      "        0.9607, 0.9862, 0.9752, 0.9688, 0.9790, 0.9736, 0.9701, 0.9703, 0.9629,\n",
      "        0.9749, 0.9690, 0.9758, 0.9629, 0.9695, 0.9715, 0.9656, 0.9691, 0.9659,\n",
      "        0.9649, 0.9734, 0.9770, 0.9746, 0.9671, 0.9726, 0.9629, 0.9738, 0.9720,\n",
      "        0.9749, 0.9735, 0.9724, 0.9751, 0.9649, 0.9870, 0.9708, 0.9604, 0.9798,\n",
      "        0.9730, 0.9721, 0.9720, 0.9730, 0.9667, 0.9705, 0.9709, 0.9745, 0.9717,\n",
      "        0.9675, 0.9801, 0.9728, 0.9664, 0.9694, 0.9669, 0.9932, 0.9539, 0.9698,\n",
      "        0.9721, 0.9685, 0.9680, 0.9803, 0.9676, 0.9800, 0.9645, 0.9673, 0.9740,\n",
      "        0.9670, 0.9714, 0.9693, 0.9549, 0.9690, 0.9680, 0.9702, 0.9709, 0.9811,\n",
      "        0.9773, 0.9615, 0.9741, 0.9781, 0.9673, 0.9773, 0.9683, 0.9759, 0.9669,\n",
      "        0.9593, 0.9827, 0.9586, 0.9620, 0.9688, 0.9761, 0.9635, 0.9689, 0.9717,\n",
      "        0.9803, 0.9667, 0.9661, 0.9687, 0.9682, 0.9684, 0.9696, 0.9763, 0.9681,\n",
      "        0.9686, 0.9733, 0.9755, 0.9676, 0.9671, 0.9828, 0.9674, 0.9664, 0.9714,\n",
      "        0.9795, 0.9686, 0.9660, 0.9678, 0.9681, 0.9665, 0.9581, 0.9713, 0.9747,\n",
      "        0.9636, 0.9705, 0.9753, 0.9793, 0.9698, 0.9685, 0.9742, 0.9779, 0.9692,\n",
      "        1.0002, 0.9731, 0.9706, 0.9902, 0.9706, 0.9682, 0.9754, 0.9689, 0.9682,\n",
      "        0.9657, 0.9710, 0.9701, 0.9733, 0.9764, 0.9668, 0.9693, 0.9731, 0.9739,\n",
      "        0.9752, 0.9587, 0.9736, 0.9672, 0.9721, 0.9712, 0.9836, 0.9764, 0.9676,\n",
      "        0.9717, 0.9721, 0.9794, 0.9678, 0.9802, 0.9718, 0.9686, 0.9711, 0.9658,\n",
      "        0.9730, 0.9672, 0.9635, 0.9748, 0.9692, 0.9680, 0.9739, 0.9687, 0.9734,\n",
      "        0.9641, 0.9686, 0.9629, 0.9710, 0.9676, 0.9639, 0.9760, 0.9676, 0.9848,\n",
      "        0.9689, 0.9695, 0.9698, 0.9730, 0.9632, 0.9840, 0.9732, 0.9649, 0.9684,\n",
      "        0.9767, 0.9706, 0.9689, 0.9683, 0.9689, 0.9744, 0.9663, 0.9699, 0.9642,\n",
      "        0.9643, 0.9684, 0.9707, 0.9710, 0.9721, 0.9705, 0.9712, 0.9696, 0.9676,\n",
      "        0.9714, 0.9853, 0.9701, 0.9700, 0.9710, 0.9693, 0.9743, 0.9666, 0.9684,\n",
      "        0.9716, 0.9669, 0.9731, 0.9627, 0.9700, 0.9635, 0.9714, 0.9706, 0.9569,\n",
      "        0.9743, 0.9660, 0.9728, 0.9692, 0.9863, 0.9723, 0.9596, 0.9703, 0.9668,\n",
      "        0.9636, 0.9727, 0.9757, 0.9769, 0.9659, 0.9711, 0.9746, 0.9139])\n",
      "Pruned 0 filters\n",
      "tensor([0.9695, 0.9707, 0.9717, 0.9698, 0.9691, 0.9727, 0.9671, 0.9715, 0.9720,\n",
      "        0.9716, 0.9738, 0.9693, 0.9726, 0.9770, 0.9780, 0.9702, 0.9636, 0.9694,\n",
      "        0.9698, 0.9757, 0.9710, 0.9703, 0.9711, 0.9685, 0.9716, 0.9689, 0.9756,\n",
      "        0.9753, 0.9691, 0.9705, 0.9696, 0.9696, 0.9695, 0.9661, 0.9686, 0.9690,\n",
      "        0.9715, 0.9708, 0.9731, 0.9733, 0.9681, 0.9683, 0.9689, 0.9703, 0.9759,\n",
      "        0.9652, 0.9646, 0.9719, 0.9697, 0.9688, 0.9677, 0.9768, 0.9698, 0.9644,\n",
      "        0.9685, 0.9724, 0.9677, 0.9700, 0.9687, 0.9676, 0.9713, 0.9732, 0.9688,\n",
      "        0.9699, 0.9727, 0.9735, 0.9737, 0.9695, 0.9693, 0.9715, 0.9701, 0.9722,\n",
      "        0.9677, 0.9727, 0.9716, 0.9704, 0.9711, 0.9723, 0.9686, 0.9707, 0.9735,\n",
      "        0.9691, 0.9733, 0.9689, 0.9698, 0.9746, 0.9714, 0.9699, 0.9698, 0.9694,\n",
      "        0.9738, 0.9684, 0.9683, 0.9776, 0.9733, 0.9724, 0.9755, 0.9740, 0.9738,\n",
      "        0.9640, 0.9721, 0.9721, 0.9675, 0.9715, 0.9683, 0.9750, 0.9693, 0.9683,\n",
      "        0.9683, 0.9742, 0.9714, 0.9649, 0.9650, 0.9697, 0.9695, 0.9676, 0.9725,\n",
      "        0.9741, 0.9709, 0.9727, 0.9724, 0.9785, 0.9695, 0.9690, 0.9684, 0.9725,\n",
      "        0.9731, 0.9702, 0.9677, 0.9711, 0.9682, 0.9715, 0.9699, 0.9712, 0.9753,\n",
      "        0.9719, 0.9711, 0.9676, 0.9697, 0.9741, 0.9701, 0.9716, 0.9679, 0.9695,\n",
      "        0.9692, 0.9696, 0.9725, 0.9694, 0.9732, 0.9711, 0.9698, 0.9700, 0.9689,\n",
      "        0.9679, 0.9701, 0.9724, 0.9678, 0.9722, 0.9745, 0.9703, 0.9711, 0.9694,\n",
      "        0.9741, 0.9704, 0.9697, 0.9694, 0.9685, 0.9710, 0.9703, 0.9654, 0.9702,\n",
      "        0.9705, 0.9736, 0.9732, 0.9725, 0.9707, 0.9695, 0.9694, 0.9720, 0.9695,\n",
      "        0.9681, 0.9718, 0.9723, 0.9710, 0.9740, 0.9717, 0.9697, 0.9768, 0.9707,\n",
      "        0.9702, 0.9725, 0.9705, 0.9690, 0.9715, 0.9648, 0.9686, 0.9717, 0.9680,\n",
      "        0.9682, 0.9714, 0.9716, 0.9715, 0.9702, 0.9687, 0.9686, 0.9703, 0.9835,\n",
      "        0.9673, 0.9691, 0.9779, 0.9721, 0.9672, 0.9747, 0.9694, 0.9690, 0.9697,\n",
      "        0.9791, 0.9697, 0.9755, 0.9643, 0.9716, 0.9713, 0.9706, 0.9685, 0.9699,\n",
      "        0.9710, 0.9676, 0.9691, 0.9709, 0.9688, 0.9783, 0.9701, 0.9695, 0.9683,\n",
      "        0.9696, 0.9702, 0.9701, 0.9896, 0.9702, 0.9685, 0.9739, 0.9700, 0.9677,\n",
      "        0.9695, 0.9700, 0.9633, 0.9720, 0.9711, 0.9750, 0.9746, 0.9684, 0.9699,\n",
      "        0.9744, 0.9683, 0.9697, 0.9734, 0.9679, 0.9724, 0.9712, 0.9712, 0.9676,\n",
      "        0.9688, 0.9732, 0.9708, 0.9719, 0.9686, 0.9693, 0.9722, 0.9704, 0.9599,\n",
      "        0.9701, 0.9688, 0.9734, 0.9694, 0.9711, 0.9697, 0.9711, 0.9687, 0.9683,\n",
      "        0.9700, 0.9706, 0.9746, 0.9728, 0.9727, 0.9695, 0.9705, 0.9659, 0.9702,\n",
      "        0.9725, 0.9683, 0.9753, 0.9727, 0.9689, 0.9775, 0.9701, 0.9705, 0.9648,\n",
      "        0.9708, 0.9720, 0.9675, 0.9683, 0.9723, 0.9694, 0.9706, 0.9645, 0.9738,\n",
      "        0.9713, 0.9682, 0.9694, 0.9713, 0.9710, 0.9676, 0.9693, 0.9707, 0.9665,\n",
      "        0.9738, 0.9711, 0.9742, 0.9700, 0.9717, 0.9698, 0.9660, 0.9758, 0.9712,\n",
      "        0.9722, 0.9699, 0.9721, 0.9683, 0.9717, 0.9699, 0.9705, 0.9677, 0.9828,\n",
      "        0.9718, 0.9738, 0.9727, 0.9698, 0.9660, 0.9705, 0.9696, 0.9679, 0.9720,\n",
      "        0.9692, 0.9684, 0.9706, 0.9682, 0.9713, 0.9707, 0.9703, 0.9670, 0.9692,\n",
      "        0.9688, 0.9697, 0.9726, 0.9736, 0.9691, 0.9722, 0.9694, 0.9733, 0.9689,\n",
      "        0.9795, 0.9693, 0.9683, 0.9729, 0.9692, 0.9766, 0.9676, 0.9668, 0.9740,\n",
      "        0.9699, 0.9700, 0.9688, 0.9713, 0.9692, 0.9689, 0.9696, 0.9733, 0.9687,\n",
      "        0.9686, 0.9721, 0.9715, 0.9695, 0.9705, 0.9726, 0.9680, 0.9651, 0.9705,\n",
      "        0.9676, 0.9697, 0.9691, 0.9696, 0.9713, 0.9741, 0.9688, 0.9713, 0.9715,\n",
      "        0.9713, 0.9709, 0.9693, 0.9764, 0.9711, 0.9708, 0.9785, 0.9732, 0.9695,\n",
      "        0.9695, 0.9697, 0.9673, 0.9700, 0.9693, 0.9689, 0.9681, 0.9704, 0.9753,\n",
      "        0.9723, 0.9727, 0.9673, 0.9698, 0.9693, 0.9703, 0.9699, 0.9752, 0.9698,\n",
      "        0.9695, 0.9683, 0.9693, 0.9707, 0.9700, 0.9696, 0.9705, 0.9702, 0.9717,\n",
      "        0.9709, 0.9718, 0.9696, 0.9705, 0.9704, 0.9700, 0.9711, 0.9711, 0.9730,\n",
      "        0.9687, 0.9710, 0.9716, 0.9746, 0.9711, 0.9669, 0.9693, 0.9689, 0.9739,\n",
      "        0.9665, 0.9742, 0.9722, 0.9682, 0.9688, 0.9712, 0.9696, 0.9834, 0.9697,\n",
      "        0.9723, 0.9688, 0.9706, 0.9728, 0.9707, 0.9683, 0.9699, 0.9653, 0.9696,\n",
      "        0.9745, 0.9688, 0.9709, 0.9699, 0.9733, 0.9700, 0.9729, 0.9686, 0.9685,\n",
      "        0.9689, 0.9699, 0.9718, 0.9695, 0.9730, 0.9720, 0.9702, 0.9725, 0.9763,\n",
      "        0.9682, 0.9691, 0.9706, 0.9714, 0.9757, 0.9706, 0.9679, 0.9708, 0.9732,\n",
      "        0.9697, 0.9719, 0.9676, 0.9738, 0.9672, 0.9682, 0.9613, 0.9689, 0.9698,\n",
      "        0.9705, 0.9721, 0.9726, 0.9719, 0.9683, 0.9685, 0.9772, 0.9734])\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 2.9915 Acc: 0.2921 Balanced Acc: 0.2922\n",
      "val Loss: 3.0874 Acc: 0.2705 Balanced Acc: 0.2751\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 2.6548 Acc: 0.3477 Balanced Acc: 0.3477\n",
      "val Loss: 2.9111 Acc: 0.3029 Balanced Acc: 0.3060\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 2.5103 Acc: 0.3839 Balanced Acc: 0.3839\n",
      "val Loss: 2.8809 Acc: 0.3098 Balanced Acc: 0.3121\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 2.4214 Acc: 0.4057 Balanced Acc: 0.4057\n",
      "val Loss: 2.9039 Acc: 0.3057 Balanced Acc: 0.3083\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 2.3166 Acc: 0.4269 Balanced Acc: 0.4269\n",
      "val Loss: 2.8571 Acc: 0.3184 Balanced Acc: 0.3213\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 2.2666 Acc: 0.4349 Balanced Acc: 0.4349\n",
      "val Loss: 2.8591 Acc: 0.3186 Balanced Acc: 0.3209\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 2.2543 Acc: 0.4349 Balanced Acc: 0.4349\n",
      "val Loss: 2.8034 Acc: 0.3298 Balanced Acc: 0.3334\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 2.2100 Acc: 0.4611 Balanced Acc: 0.4611\n",
      "val Loss: 2.7951 Acc: 0.3284 Balanced Acc: 0.3303\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 2.1870 Acc: 0.4513 Balanced Acc: 0.4513\n",
      "val Loss: 2.7697 Acc: 0.3367 Balanced Acc: 0.3381\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 2.1260 Acc: 0.4645 Balanced Acc: 0.4645\n",
      "val Loss: 2.8037 Acc: 0.3269 Balanced Acc: 0.3293\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 2.1462 Acc: 0.4661 Balanced Acc: 0.4662\n",
      "val Loss: 2.7382 Acc: 0.3362 Balanced Acc: 0.3397\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 2.0862 Acc: 0.4825 Balanced Acc: 0.4825\n",
      "val Loss: 2.7479 Acc: 0.3341 Balanced Acc: 0.3378\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 2.0610 Acc: 0.4830 Balanced Acc: 0.4830\n",
      "val Loss: 2.7609 Acc: 0.3274 Balanced Acc: 0.3305\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 2.0545 Acc: 0.4868 Balanced Acc: 0.4868\n",
      "val Loss: 2.7758 Acc: 0.3336 Balanced Acc: 0.3382\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 2.0178 Acc: 0.4985 Balanced Acc: 0.4985\n",
      "val Loss: 2.7060 Acc: 0.3426 Balanced Acc: 0.3461\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 2.0356 Acc: 0.4915 Balanced Acc: 0.4914\n",
      "val Loss: 2.7196 Acc: 0.3454 Balanced Acc: 0.3478\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 2.0469 Acc: 0.4887 Balanced Acc: 0.4886\n",
      "val Loss: 2.7212 Acc: 0.3450 Balanced Acc: 0.3465\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 2.0221 Acc: 0.4977 Balanced Acc: 0.4977\n",
      "val Loss: 2.7524 Acc: 0.3431 Balanced Acc: 0.3470\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.9950 Acc: 0.5048 Balanced Acc: 0.5048\n",
      "val Loss: 2.7244 Acc: 0.3459 Balanced Acc: 0.3481\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 2.0027 Acc: 0.5037 Balanced Acc: 0.5036\n",
      "val Loss: 2.7183 Acc: 0.3452 Balanced Acc: 0.3480\n",
      "\n",
      "Training complete in 90m 41s\n",
      "Best val Balanced Acc: 0.348083\n"
     ]
    }
   ],
   "source": [
    "\n",
    "betterAcc = True\n",
    "previousAcc = 0.0\n",
    "model = model.to('cpu')\n",
    "#Generate Wsf*\n",
    "for name, module in model.named_modules():\n",
    "    if type(module) == AlphaConv2d:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True\n",
    "        module.alpha.requires_grad = False\n",
    "\n",
    "while(betterAcc):\n",
    "  #Reset alpha to 1 \n",
    "  for name, module in model.named_modules():\n",
    "      if type(module) == AlphaConv2d:\n",
    "          module.alpha.data = torch.ones(module.alpha.data.shape)\n",
    "\n",
    "  # Train the factors alpha by Eq.[3]\n",
    "  for name, module in model.named_modules():\n",
    "    if type(module) == AlphaConv2d:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "        module.alpha.requires_grad = True\n",
    "  model = model.to(device)\n",
    "  model_ft,_ = train_model(model, criterion, optimizer, num_epochs=20, nclas =200) # Set to 40 in the paper\n",
    "  model_ft = model_ft.to('cpu')\n",
    "  #Transform based on beta \n",
    "  #Prune based on the beta = abs(1-alpha)\n",
    "  for name, module in model_ft.named_modules():\n",
    "        if type(module) == AlphaConv2d:\n",
    "          mask = torch.abs(module.alpha.data-1) < 0.05\n",
    "          print(f'Pruned {torch.sum(mask == 0)} filters' ) \n",
    "          print(module.alpha.data)\n",
    "          mask = mask.unsqueeze(1).unsqueeze(2).unsqueeze(3).expand_as(module.weight.data)\n",
    "          prune.custom_from_mask(module, 'weight', mask)\n",
    "  #Fine tune the model\n",
    "  for name, module in model_ft.named_modules():\n",
    "      if type(module) == AlphaConv2d:\n",
    "          for param in module.parameters():\n",
    "              param.requires_grad = True\n",
    "          module.alpha.requires_grad = False\n",
    "  model_ft = model_ft.to(device)\n",
    "  model_ft,current_acc = train_model(model_ft, criterion, optimizer, num_epochs=20, nclas =200) # Set to 40 in the paper\n",
    "  model_ft = model_ft.to('cpu')\n",
    "  if current_acc > previousAcc:\n",
    "      previousAcc = current_acc\n",
    "      model = model_ft\n",
    "  else:\n",
    "      betterAcc = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
