{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gW7H6FygFyzr"
   },
   "source": [
    "Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l5NI0wgQFkRD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vgg16\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.utils.prune as prune\n",
    "from heapq import nsmallest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yihMHI_GBUX"
   },
   "source": [
    "Activar acceleración por hardware -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WaQVjQOFya-",
    "outputId": "d72a12d8-584d-4566-fb85-ebe14e707f97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhYfK8f5F5aM",
    "outputId": "6466241f-85ec-4e65-cb2a-54461ab6b238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  3 16:09:21 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 522.06       Driver Version: 522.06       CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 45%   32C    P8    13W /  95W |   1842MiB /  2048MiB |     12%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla M40 24GB     TCC   | 00000000:2B:00.0 Off |           1488973049 |\n",
      "| N/A   58C    P8    17W / 250W |     11MiB / 23040MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1888    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A      3044    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      3900    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      5964    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A      7508    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      8948    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9960    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11292    C+G   ...s\\LibreWolf\\librewolf.exe    N/A      |\n",
      "|    0   N/A  N/A     12124    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     13944    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16488    C+G   ...gram Desktop\\Telegram.exe    N/A      |\n",
      "|    0   N/A  N/A     17032    C+G   ...s\\LibreWolf\\librewolf.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bhWM4ImbF7MQ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF0S6lUiGZYH"
   },
   "source": [
    "Función de carga del dataset CUB (El dataset se descarga automáticamente al ejecutar las siguientes celdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ux5xbkoEGEIJ"
   },
   "outputs": [],
   "source": [
    "class Cub2011(Dataset):\n",
    "    base_folder = 'CUB_200_2011/images'\n",
    "    url = 'https://data.caltech.edu/records/65de6-vp158/files/CUB_200_2011.tgz?download=1'\n",
    "    filename = 'CUB_200_2011.tgz'\n",
    "    tgz_md5 = '97eceeb196236b17998738112f37df78'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, loader=default_loader, download=True):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.loader = default_loader\n",
    "        self.train = train\n",
    "\n",
    "        if download:\n",
    "            self._download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        images = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'images.txt'), sep=' ',\n",
    "                             names=['img_id', 'filepath'])\n",
    "        image_class_labels = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'image_class_labels.txt'),\n",
    "                                         sep=' ', names=['img_id', 'target'])\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'train_test_split.txt'),\n",
    "                                       sep=' ', names=['img_id', 'is_training_img'])\n",
    "\n",
    "        data = images.merge(image_class_labels, on='img_id')\n",
    "        self.data = data.merge(train_test_split, on='img_id')\n",
    "\n",
    "        if self.train:\n",
    "            self.data = self.data[self.data.is_training_img == 1]\n",
    "        else:\n",
    "            self.data = self.data[self.data.is_training_img == 0]\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        try:\n",
    "            self._load_metadata()\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "        for index, row in self.data.iterrows():\n",
    "            filepath = os.path.join(self.root, self.base_folder, row.filepath)\n",
    "            if not os.path.isfile(filepath):\n",
    "                print(filepath)\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        download_url(self.url, self.root, self.filename, self.tgz_md5)\n",
    "\n",
    "        with tarfile.open(os.path.join(self.root, self.filename), \"r:gz\") as tar:\n",
    "            tar.extractall(path=self.root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        path = os.path.join(self.root, self.base_folder, sample.filepath)\n",
    "        target = sample.target - 1 \n",
    "        img = self.loader(path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23qqQFV1GjWS"
   },
   "source": [
    "Preprocesado de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "15JoU_PQGjAO"
   },
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxz6ldGoG0bE"
   },
   "source": [
    "Carga del dataset (Colab no soporta un batch_size muy alto así que lo dejo en 64 para la prueba)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xb6IhrWfGtih",
    "outputId": "d6dced00-85f3-49b8-a68f-300439360fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_ds = Cub2011('.', train=True, transform = transform)\n",
    "val_ds = Cub2011('.s', train=False, transform = transform)\n",
    "\n",
    "ds = {'train': DataLoader(train_ds, batch_size = 64, shuffle=True),\n",
    "      'val': DataLoader(val_ds, batch_size = 64, shuffle=False)}\n",
    "\n",
    "\n",
    "ds_sizes = {'train': len(train_ds),\n",
    "      'val': len(val_ds)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8At2Z94CHCPL"
   },
   "source": [
    "Función de entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uD5xkrWCG_op"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=40, nclas=200, patience=8):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    #best_acc = 0.0\n",
    "    best_bal_acc = 0.0\n",
    "\n",
    "    #early stopping\n",
    "    best_epoch = 0\n",
    "    \n",
    "    epochs_bal_acc = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            CF = np.zeros((nclas,nclas)) # Confusion matrix\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in ds[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                for i in range(len(labels.data)):\n",
    "                    CF[labels.data[i]][preds[i]] +=1\n",
    "                \n",
    "            #if phase == 'train':\n",
    "            #    scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / ds_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / ds_sizes[phase]\n",
    "            recalli = 0\n",
    "            for i in range(nclas):\n",
    "                TP = CF[i][i]\n",
    "                FN = 0\n",
    "                for j in range(nclas):\n",
    "                    if i!=j:\n",
    "                        FN+=CF[i][j]\n",
    "                if (TP+FN) !=0:\n",
    "                    recalli+= TP/(TP+FN)\n",
    "            epoch_bal_acc = recalli/nclas\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Balanced Acc: {epoch_bal_acc:.4f}')\n",
    "            if phase == 'val':\n",
    "                epochs_bal_acc.append(epoch_bal_acc)\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_bal_acc > best_bal_acc:\n",
    "                best_bal_acc = epoch_bal_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "            \n",
    "            if phase == 'val' and epoch - best_epoch > patience:\n",
    "                print('Early stopping')\n",
    "                break\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Balanced Acc: {best_bal_acc:4f}')\n",
    "    print(epochs_bal_acc)\n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    return model, best_bal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2jOfrDdgHtT3"
   },
   "outputs": [],
   "source": [
    "class AlphaConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(AlphaConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
    "        #One alpha per filter\n",
    "        #self.alpha = nn.Parameter(torch.ones(out_channels, 1, 1, 1))\n",
    "        self.alpha = nn.Parameter(torch.ones(out_channels))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #return super(AlphaConv2d, self).forward(x) * self.alpha\n",
    "        return super(AlphaConv2d, self).forward(x) * self.alpha.unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zGK0VmaH9pF"
   },
   "source": [
    "Función para mostrar los parámetros de la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D9zPfuPHIJwO"
   },
   "outputs": [],
   "source": [
    "def check_weights(m):\n",
    "    if type(m) == AlphaConv2d:\n",
    "        for module in m.named_parameters():\n",
    "            print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FCSNfOOIT-K"
   },
   "source": [
    "Carga el modelo preentrenado (He utilizado una VGG16 para simplificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f1WkQ3ujHP9y"
   },
   "outputs": [],
   "source": [
    "model = vgg16(weights='IMAGENET1K_V1')\n",
    "model.classifier[6] = nn.Linear(4096, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2CcrU51nm7sK"
   },
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "  if type(module) == nn.Conv2d:\n",
    "    new_module = AlphaConv2d(module.in_channels, module.out_channels, module.kernel_size, module.stride, module.padding, module.dilation, module.groups, True)\n",
    "    new_module.weight = module.weight\n",
    "    new_module.bias = module.bias\n",
    "    model.features[int(name.split('.')[1])] = new_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "V2uu3kh6tXXH"
   },
   "outputs": [],
   "source": [
    "conv = [] #Conv layers\n",
    "fc = [] #FC layers\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if type(module) == AlphaConv2d:\n",
    "        conv.append(module.alpha)\n",
    "    elif type(module) == nn.Linear:\n",
    "        fc.append(module.weight)\n",
    "        fc.append(module.bias)\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "                {'params': conv},\n",
    "                {'params': fc, 'lr': 0.005}\n",
    "          ], weight_decay  = 0.005, momentum = 0.9, lr = 0.0005)\n",
    "\n",
    "adam_optimizer = torch.optim.Adam([\n",
    "                {'params': conv},\n",
    "                {'params': fc, 'lr': 0.01}\n",
    "            ], weight_decay  = 0.005, lr = 0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQtMDUeOWmsG",
    "outputId": "a8babb51-005f-452e-b5d4-af8f9f6d49fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 4.0674 Acc: 0.1461 Balanced Acc: 0.1461\n",
      "val Loss: 2.9069 Acc: 0.3407 Balanced Acc: 0.3452\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 2.7207 Acc: 0.3458 Balanced Acc: 0.3458\n",
      "val Loss: 2.4438 Acc: 0.4068 Balanced Acc: 0.4120\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 2.4293 Acc: 0.4002 Balanced Acc: 0.4002\n",
      "val Loss: 2.2485 Acc: 0.4474 Balanced Acc: 0.4524\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 2.2676 Acc: 0.4369 Balanced Acc: 0.4370\n",
      "val Loss: 2.1705 Acc: 0.4512 Balanced Acc: 0.4553\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 2.1809 Acc: 0.4543 Balanced Acc: 0.4542\n",
      "val Loss: 2.1448 Acc: 0.4569 Balanced Acc: 0.4599\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 2.0794 Acc: 0.4623 Balanced Acc: 0.4623\n",
      "val Loss: 2.0311 Acc: 0.4824 Balanced Acc: 0.4873\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 2.0231 Acc: 0.4795 Balanced Acc: 0.4795\n",
      "val Loss: 2.0778 Acc: 0.4700 Balanced Acc: 0.4735\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.9775 Acc: 0.4887 Balanced Acc: 0.4886\n",
      "val Loss: 2.0324 Acc: 0.4860 Balanced Acc: 0.4880\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.9290 Acc: 0.5040 Balanced Acc: 0.5040\n",
      "val Loss: 2.0400 Acc: 0.4774 Balanced Acc: 0.4809\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.9067 Acc: 0.5023 Balanced Acc: 0.5024\n",
      "val Loss: 2.0208 Acc: 0.4858 Balanced Acc: 0.4895\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.8783 Acc: 0.5128 Balanced Acc: 0.5129\n",
      "val Loss: 1.9810 Acc: 0.4891 Balanced Acc: 0.4934\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.8375 Acc: 0.5174 Balanced Acc: 0.5174\n",
      "val Loss: 1.9400 Acc: 0.5041 Balanced Acc: 0.5086\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.8173 Acc: 0.5229 Balanced Acc: 0.5229\n",
      "val Loss: 1.9464 Acc: 0.4983 Balanced Acc: 0.5019\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.8136 Acc: 0.5319 Balanced Acc: 0.5319\n",
      "val Loss: 1.9513 Acc: 0.5019 Balanced Acc: 0.5063\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.8105 Acc: 0.5280 Balanced Acc: 0.5280\n",
      "val Loss: 1.9448 Acc: 0.4990 Balanced Acc: 0.5020\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.7460 Acc: 0.5460 Balanced Acc: 0.5460\n",
      "val Loss: 1.9320 Acc: 0.5076 Balanced Acc: 0.5112\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.7853 Acc: 0.5379 Balanced Acc: 0.5379\n",
      "val Loss: 1.9466 Acc: 0.5024 Balanced Acc: 0.5074\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.7674 Acc: 0.5395 Balanced Acc: 0.5395\n",
      "val Loss: 1.9178 Acc: 0.4986 Balanced Acc: 0.5029\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.7408 Acc: 0.5449 Balanced Acc: 0.5449\n",
      "val Loss: 1.9542 Acc: 0.5074 Balanced Acc: 0.5131\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.7551 Acc: 0.5422 Balanced Acc: 0.5422\n",
      "val Loss: 1.9523 Acc: 0.4912 Balanced Acc: 0.4957\n",
      "\n",
      "Training complete in 90m 27s\n",
      "Best val Balanced Acc: 0.513063\n",
      "[0.34517137541113707, 0.412016083295378, 0.4524120211248753, 0.4553313202618419, 0.4598869056994598, 0.4872790188928239, 0.47346555036200333, 0.4879833650389753, 0.4808917079863185, 0.4894962712112752, 0.49341882265893927, 0.5085637670018242, 0.5018790724846314, 0.5063131575595672, 0.5019753718470876, 0.5112105186489313, 0.5073711528388205, 0.5029387770616569, 0.5130629191497573, 0.49571415667618235]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer_last = torch.optim.SGD(model.classifier[6].parameters(), lr=0.005, momentum=0.9, weight_decay=0.005)\n",
    "adam_optimizer_last = torch.optim.Adam(model.classifier[6].parameters(), lr=0.01, weight_decay=0.005)\n",
    "model = model.to(device)\n",
    "model, _ = train_model(model, criterion, optimizer_last, num_epochs=20, nclas=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQi_lUyJtJPF",
    "outputId": "575340b0-381c-477e-9081-2e0f41878c64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.7326 Acc: 0.5464 Balanced Acc: 0.5465\n",
      "val Loss: 1.9868 Acc: 0.4953 Balanced Acc: 0.4989\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.6641 Acc: 0.5689 Balanced Acc: 0.5690\n",
      "val Loss: 1.9479 Acc: 0.5071 Balanced Acc: 0.5109\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.6862 Acc: 0.5701 Balanced Acc: 0.5701\n",
      "val Loss: 1.9867 Acc: 0.5038 Balanced Acc: 0.5076\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.7058 Acc: 0.5697 Balanced Acc: 0.5699\n",
      "val Loss: 2.0289 Acc: 0.4950 Balanced Acc: 0.4998\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.7204 Acc: 0.5697 Balanced Acc: 0.5699\n",
      "val Loss: 2.0282 Acc: 0.4986 Balanced Acc: 0.5037\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.7580 Acc: 0.5714 Balanced Acc: 0.5715\n",
      "val Loss: 2.0414 Acc: 0.5002 Balanced Acc: 0.5048\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.7827 Acc: 0.5696 Balanced Acc: 0.5697\n",
      "val Loss: 2.0689 Acc: 0.5050 Balanced Acc: 0.5077\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.8077 Acc: 0.5657 Balanced Acc: 0.5659\n",
      "val Loss: 2.0865 Acc: 0.5036 Balanced Acc: 0.5090\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.8011 Acc: 0.5719 Balanced Acc: 0.5720\n",
      "val Loss: 2.1144 Acc: 0.5010 Balanced Acc: 0.5065\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.8593 Acc: 0.5604 Balanced Acc: 0.5605\n",
      "val Loss: 2.1668 Acc: 0.4929 Balanced Acc: 0.4970\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.8839 Acc: 0.5617 Balanced Acc: 0.5618\n",
      "val Loss: 2.1680 Acc: 0.4991 Balanced Acc: 0.5032\n",
      "Early stopping\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.9155 Acc: 0.5627 Balanced Acc: 0.5628\n",
      "val Loss: 2.1940 Acc: 0.4928 Balanced Acc: 0.4971\n",
      "Early stopping\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.9388 Acc: 0.5542 Balanced Acc: 0.5543\n",
      "val Loss: 2.2221 Acc: 0.4978 Balanced Acc: 0.5020\n",
      "Early stopping\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.9734 Acc: 0.5554 Balanced Acc: 0.5555\n",
      "val Loss: 2.2330 Acc: 0.4933 Balanced Acc: 0.4982\n",
      "Early stopping\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.9881 Acc: 0.5524 Balanced Acc: 0.5525\n",
      "val Loss: 2.2717 Acc: 0.4914 Balanced Acc: 0.4971\n",
      "Early stopping\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 2.0158 Acc: 0.5532 Balanced Acc: 0.5533\n",
      "val Loss: 2.3000 Acc: 0.4822 Balanced Acc: 0.4868\n",
      "Early stopping\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 2.0635 Acc: 0.5389 Balanced Acc: 0.5389\n",
      "val Loss: 2.3014 Acc: 0.4838 Balanced Acc: 0.4878\n",
      "Early stopping\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 2.1048 Acc: 0.5370 Balanced Acc: 0.5371\n",
      "val Loss: 2.3472 Acc: 0.4798 Balanced Acc: 0.4845\n",
      "Early stopping\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 2.1059 Acc: 0.5367 Balanced Acc: 0.5368\n",
      "val Loss: 2.3562 Acc: 0.4772 Balanced Acc: 0.4812\n",
      "Early stopping\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 2.1399 Acc: 0.5274 Balanced Acc: 0.5274\n",
      "val Loss: 2.3655 Acc: 0.4745 Balanced Acc: 0.4783\n",
      "Early stopping\n",
      "\n",
      "Training complete in 72m 43s\n",
      "Best val Balanced Acc: 0.510870\n",
      "[0.4989150497507437, 0.510869722904028, 0.5076267584714281, 0.4998094309379129, 0.5037258291601578, 0.5047768775649505, 0.5077153490128122, 0.5089530999196233, 0.5064905367040616, 0.49698757022616774, 0.5032173105446796, 0.4970717498050608, 0.5019591684161834, 0.49821382220875243, 0.49708664671467423, 0.4868267054086516, 0.4877731594101234, 0.48448364564497326, 0.48118291507175365, 0.478276331898343]\n",
      "Betas length:\n",
      "4224\n",
      "Pruned 1 filters\n",
      "Pruned 1 filters\n",
      "Pruned 9 filters\n",
      "Pruned 2 filters\n",
      "Pruned 15 filters\n",
      "Pruned 19 filters\n",
      "Pruned 16 filters\n",
      "Pruned 55 filters\n",
      "Pruned 54 filters\n",
      "Pruned 56 filters\n",
      "Pruned 54 filters\n",
      "Pruned 49 filters\n",
      "Pruned 91 filters\n",
      "Epoch 0/39\n",
      "----------\n",
      "train Loss: 395.8940 Acc: 0.0055 Balanced Acc: 0.0055\n",
      "val Loss: 303.6867 Acc: 0.0041 Balanced Acc: 0.0040\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "train Loss: 358.7238 Acc: 0.0048 Balanced Acc: 0.0048\n",
      "val Loss: 274.7621 Acc: 0.0052 Balanced Acc: 0.0050\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "train Loss: 324.1354 Acc: 0.0050 Balanced Acc: 0.0050\n",
      "val Loss: 247.2381 Acc: 0.0054 Balanced Acc: 0.0052\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "train Loss: 291.7633 Acc: 0.0053 Balanced Acc: 0.0053\n",
      "val Loss: 223.8352 Acc: 0.0059 Balanced Acc: 0.0057\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "train Loss: 263.0593 Acc: 0.0047 Balanced Acc: 0.0047\n",
      "val Loss: 202.7447 Acc: 0.0054 Balanced Acc: 0.0052\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "train Loss: 238.8435 Acc: 0.0055 Balanced Acc: 0.0055\n",
      "val Loss: 182.9944 Acc: 0.0048 Balanced Acc: 0.0047\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "train Loss: 214.2753 Acc: 0.0042 Balanced Acc: 0.0042\n",
      "val Loss: 166.0931 Acc: 0.0043 Balanced Acc: 0.0042\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "train Loss: 194.2785 Acc: 0.0042 Balanced Acc: 0.0042\n",
      "val Loss: 149.2661 Acc: 0.0043 Balanced Acc: 0.0042\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "train Loss: 176.4052 Acc: 0.0033 Balanced Acc: 0.0033\n",
      "val Loss: 135.5773 Acc: 0.0045 Balanced Acc: 0.0043\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "train Loss: 159.2444 Acc: 0.0052 Balanced Acc: 0.0052\n",
      "val Loss: 122.2393 Acc: 0.0043 Balanced Acc: 0.0042\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "train Loss: 144.0009 Acc: 0.0053 Balanced Acc: 0.0053\n",
      "val Loss: 110.8964 Acc: 0.0045 Balanced Acc: 0.0043\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "train Loss: 130.2795 Acc: 0.0055 Balanced Acc: 0.0055\n",
      "val Loss: 100.0115 Acc: 0.0048 Balanced Acc: 0.0047\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "train Loss: 117.8864 Acc: 0.0053 Balanced Acc: 0.0053\n",
      "val Loss: 90.4872 Acc: 0.0045 Balanced Acc: 0.0043\n",
      "Early stopping\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "train Loss: 106.4212 Acc: 0.0050 Balanced Acc: 0.0050\n",
      "val Loss: 81.8684 Acc: 0.0055 Balanced Acc: 0.0053\n",
      "Early stopping\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "train Loss: 96.2627 Acc: 0.0047 Balanced Acc: 0.0047\n",
      "val Loss: 74.0374 Acc: 0.0047 Balanced Acc: 0.0045\n",
      "Early stopping\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "train Loss: 87.4827 Acc: 0.0052 Balanced Acc: 0.0052\n",
      "val Loss: 66.9017 Acc: 0.0041 Balanced Acc: 0.0040\n",
      "Early stopping\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "train Loss: 78.6151 Acc: 0.0062 Balanced Acc: 0.0062\n",
      "val Loss: 60.4724 Acc: 0.0048 Balanced Acc: 0.0047\n",
      "Early stopping\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "train Loss: 70.7442 Acc: 0.0047 Balanced Acc: 0.0047\n",
      "val Loss: 54.9995 Acc: 0.0047 Balanced Acc: 0.0045\n",
      "Early stopping\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "train Loss: 64.5763 Acc: 0.0052 Balanced Acc: 0.0052\n",
      "val Loss: 49.6478 Acc: 0.0057 Balanced Acc: 0.0055\n",
      "Early stopping\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "train Loss: 58.3755 Acc: 0.0045 Balanced Acc: 0.0045\n",
      "val Loss: 44.8877 Acc: 0.0057 Balanced Acc: 0.0055\n",
      "Early stopping\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "train Loss: 52.4438 Acc: 0.0052 Balanced Acc: 0.0052\n",
      "val Loss: 40.7276 Acc: 0.0045 Balanced Acc: 0.0043\n",
      "Early stopping\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n",
      "train Loss: 47.8465 Acc: 0.0037 Balanced Acc: 0.0037\n",
      "val Loss: 36.8752 Acc: 0.0050 Balanced Acc: 0.0048\n",
      "Early stopping\n",
      "\n",
      "Epoch 22/39\n",
      "----------\n",
      "train Loss: 42.8762 Acc: 0.0055 Balanced Acc: 0.0055\n",
      "val Loss: 33.3182 Acc: 0.0047 Balanced Acc: 0.0045\n",
      "Early stopping\n",
      "\n",
      "Epoch 23/39\n",
      "----------\n",
      "train Loss: 38.8067 Acc: 0.0048 Balanced Acc: 0.0048\n",
      "val Loss: 30.2337 Acc: 0.0050 Balanced Acc: 0.0048\n",
      "Early stopping\n",
      "\n",
      "Epoch 24/39\n",
      "----------\n",
      "train Loss: 35.4223 Acc: 0.0038 Balanced Acc: 0.0038\n",
      "val Loss: 27.4514 Acc: 0.0048 Balanced Acc: 0.0047\n",
      "Early stopping\n",
      "\n",
      "Epoch 25/39\n",
      "----------\n",
      "train Loss: 32.0694 Acc: 0.0040 Balanced Acc: 0.0040\n",
      "val Loss: 24.9027 Acc: 0.0047 Balanced Acc: 0.0045\n",
      "Early stopping\n",
      "\n",
      "Epoch 26/39\n",
      "----------\n",
      "train Loss: 29.0100 Acc: 0.0052 Balanced Acc: 0.0052\n",
      "val Loss: 22.6147 Acc: 0.0048 Balanced Acc: 0.0047\n",
      "Early stopping\n",
      "\n",
      "Epoch 27/39\n",
      "----------\n",
      "train Loss: 26.4150 Acc: 0.0047 Balanced Acc: 0.0047\n",
      "val Loss: 20.5982 Acc: 0.0048 Balanced Acc: 0.0047\n",
      "Early stopping\n",
      "\n",
      "Epoch 28/39\n",
      "----------\n",
      "train Loss: 23.7879 Acc: 0.0040 Balanced Acc: 0.0040\n",
      "val Loss: 18.7173 Acc: 0.0059 Balanced Acc: 0.0057\n",
      "Early stopping\n",
      "\n",
      "Epoch 29/39\n",
      "----------\n",
      "train Loss: 21.6766 Acc: 0.0055 Balanced Acc: 0.0055\n",
      "val Loss: 17.0449 Acc: 0.0047 Balanced Acc: 0.0045\n",
      "Early stopping\n",
      "\n",
      "Epoch 30/39\n",
      "----------\n",
      "train Loss: 19.7336 Acc: 0.0060 Balanced Acc: 0.0060\n",
      "val Loss: 15.5315 Acc: 0.0055 Balanced Acc: 0.0053\n",
      "Early stopping\n",
      "\n",
      "Epoch 31/39\n",
      "----------\n",
      "train Loss: 17.8946 Acc: 0.0053 Balanced Acc: 0.0053\n",
      "val Loss: 14.2001 Acc: 0.0055 Balanced Acc: 0.0053\n",
      "Early stopping\n",
      "\n",
      "Epoch 32/39\n",
      "----------\n",
      "train Loss: 16.3025 Acc: 0.0045 Balanced Acc: 0.0045\n",
      "val Loss: 13.0029 Acc: 0.0048 Balanced Acc: 0.0047\n",
      "Early stopping\n",
      "\n",
      "Epoch 33/39\n",
      "----------\n",
      "train Loss: 14.8603 Acc: 0.0060 Balanced Acc: 0.0060\n",
      "val Loss: 11.9955 Acc: 0.0055 Balanced Acc: 0.0053\n",
      "Early stopping\n",
      "\n",
      "Epoch 34/39\n",
      "----------\n",
      "train Loss: 13.5525 Acc: 0.0038 Balanced Acc: 0.0038\n",
      "val Loss: 11.0379 Acc: 0.0057 Balanced Acc: 0.0055\n",
      "Early stopping\n",
      "\n",
      "Epoch 35/39\n",
      "----------\n",
      "train Loss: 12.4149 Acc: 0.0038 Balanced Acc: 0.0038\n",
      "val Loss: 10.2228 Acc: 0.0055 Balanced Acc: 0.0053\n",
      "Early stopping\n",
      "\n",
      "Epoch 36/39\n",
      "----------\n",
      "train Loss: 11.4109 Acc: 0.0040 Balanced Acc: 0.0040\n",
      "val Loss: 9.5097 Acc: 0.0050 Balanced Acc: 0.0048\n",
      "Early stopping\n",
      "\n",
      "Epoch 37/39\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 72\u001b[0m\n\u001b[0;32m     68\u001b[0m             param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         module\u001b[38;5;241m.\u001b[39malpha\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m model_ft,current_acc \u001b[38;5;241m=\u001b[39m train_model(model_ft, criterion, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, nclas \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m) \u001b[38;5;66;03m# Set to 40 in the paper\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_acc\u001b[38;5;241m-\u001b[39mpreviousAcc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.3\u001b[39m: \u001b[38;5;66;03m#tau = 0.3\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     previousAcc \u001b[38;5;241m=\u001b[39m current_acc\n",
      "Cell \u001b[1;32mIn [8], line 30\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, num_epochs, nclas, patience)\u001b[0m\n\u001b[0;32m     27\u001b[0m CF \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((nclas,nclas)) \u001b[38;5;66;03m# Confusion matrix\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m ds[phase]:\n\u001b[0;32m     31\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     32\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn [5], line 68\u001b[0m, in \u001b[0;36mCub2011.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     66\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_folder, sample\u001b[38;5;241m.\u001b[39mfilepath)\n\u001b[0;32m     67\u001b[0m target \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m---> 68\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py:269\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py:249\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    248\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:901\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m    858\u001b[0m ):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    903\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m         )\n\u001b[0;32m    256\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 257\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "betterAcc = True\n",
    "previousAcc = 0.0\n",
    "\n",
    "#Lock non alphaconv2d modules grad\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "  if type(module) != AlphaConv2d:\n",
    "      for param in module.parameters():\n",
    "            if(param.requires_grad):\n",
    "                param.requires_grad = False\n",
    "        \n",
    "\n",
    "while betterAcc:\n",
    "    # Train the factors alpha by Eq.[3]\n",
    "   \n",
    "    for name, module in model.named_modules():\n",
    "      if type(module) == AlphaConv2d:\n",
    "          for param in module.parameters():\n",
    "              param.requires_grad = False\n",
    "          module.alpha.requires_grad = True\n",
    "\n",
    "\n",
    "    model_ft,_ = train_model(model, criterion, optimizer, num_epochs=20, nclas =200) # Set to 40 in the paper\n",
    "    \n",
    "    #Calculo del gradiente de los parámetros alpha\n",
    "    \n",
    "    alpha_grad = {}\n",
    "    for inputs, labels in ds['train']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        #Get the gradient of all alpha parameters in the vgg16 model\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'alpha' in name:\n",
    "                if name.split('.')[0]+'.'+name.split('.')[1] not in alpha_grad:\n",
    "                    alpha_grad[name.split('.')[0]+'.'+name.split('.')[1]] = (param.grad/len(ds['train']))\n",
    "                else:\n",
    "                    alpha_grad[name.split('.')[0]+'.'+name.split('.')[1]] += (param.grad/len(ds['train']))\n",
    "    \n",
    "    betas = []\n",
    "    \n",
    "    for name, module in model_ft.named_modules():\n",
    "        if type(module) == AlphaConv2d:\n",
    "            module.alpha.data = torch.abs(alpha_grad[name] * module.alpha.data) #Transform to beta\n",
    "            betas.extend(module.alpha)\n",
    "    \n",
    "    PERC = 0.10\n",
    "    pruneVal = max(nsmallest(int(len(betas)*PERC),betas))\n",
    "    print(\"Betas length:\")\n",
    "    print(len(betas))\n",
    "    \n",
    "    for name, module in model_ft.named_modules():\n",
    "        if type(module) == AlphaConv2d:\n",
    "            mask = module.alpha > pruneVal\n",
    "            print(f'Pruned {torch.sum((mask) == 0)} filters' ) \n",
    "            #ToDo: poner las betas podadas a 0\n",
    "            mask=mask.unsqueeze(1).unsqueeze(2).unsqueeze(3).expand_as(module.weight.data)\n",
    "            prune.custom_from_mask(module, 'weight', mask)\n",
    "            \n",
    "            \n",
    "\n",
    "    #Fine tune the model\n",
    "    for name, module in model_ft.named_modules():\n",
    "        if type(module) == AlphaConv2d:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = True\n",
    "            module.alpha.requires_grad = False\n",
    "\n",
    "            \n",
    "    model_ft,current_acc = train_model(model_ft, criterion, optimizer, num_epochs=40, nclas =200) # Set to 40 in the paper\n",
    "    if current_acc-previousAcc > 0.3: #tau = 0.3\n",
    "        previousAcc = current_acc\n",
    "        model = model_ft\n",
    "    else:\n",
    "        betterAcc = False\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
